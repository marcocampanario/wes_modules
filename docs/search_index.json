[["index.html", "Human Genome Variation Lab 1 Homepage", " Human Genome Variation Lab 1 Homepage This is the course homepage and digital textbook for Human Genome Variation with Computational Lab (AS.020.321). 1.0.0.1 Instructor Rajiv McCoy, rajiv.mccoy[at]jhu.edu 1.0.0.2 Schedule &amp; Logistics Session Content Session 1: The reference genome &amp; genome browsers Session 2: De novo mutations Session 3: Linkage disequilibrium Session 4: Simulating evolution Session 5: Population structure – part I Session 6: Population structure – part II Session 7: Genome-wide association studies – part I Session 8: Genome-wide association studies – part II Session 9: Scans for selection – part I Session 10: Scans for selection – part II Session 11: Archaic admixture Session 12: Gene expression Session 13: Coronavirus phylogenetics "],["genome-browsers.html", "2 Genome browsers", " 2 Genome browsers In this module, we’ll learn how to use the UC Santa Cruz (UCSC) Genome Browser and the Integrative Genomics Viewer (IGV), two extremely popular tools for visualizing genomic data. 2.0.0.1 Learning objectives After completing this chapter, you’ll be able to: Explain why a reference genome is an important resource for genomics research. Use the UCSC genome browser to find genomic features in a region of interest. Describe the data contained in a file of sequencing reads. Load and interpret sequencing data in IGV. "],["dna-sequencing-data.html", "2.1 DNA sequencing data", " 2.1 DNA sequencing data These days, the vast majority of genomic data is generated through high-throughput Illumina short-read sequencing. The broad steps of this sequencing process are: Extract DNA Fragment DNA Prepare for sequencer (add adapters, etc.) Amplify DNA Sequencing (add fluorescently labeled nucleotides that are read by a digital camera) Fig. 1 (source). Schematic of Illumina short-read sequencing. This sequencing approach is fast and cost efficient, but introduces two main limitations. Because of the fragmentation step, the resulting sequencing reads are extremely short (~150 bp). We don’t know where in the genome the sequencing reads came from. (This is a limitation common to nearly every sequencing experiment.) "],["assembling-a-genome.html", "2.2 Assembling a genome", " 2.2 Assembling a genome When the human genome is 3 billion base pairs long, assembling short sequencing reads into a full genome is a major computational challenge. How is genome assembly performed? We can combine sequencing reads that partially overlap with each other into longer sequences. Fig. 2. Using overlapping sequencing reads to assemble a genome. Which regions of the genome are hardest to assemble? Ideally, with enough sequencing data, we would be able to reconstruct an entire genome from overlapping reads. In practice, genome assembly is complicated by repetitive DNA – sequences in different regions of the genome that are completely or nearly identical. These repeats make it difficult (or impossible) to determine the order of the sequences around them, or how many copies of the repeat there are. Fig. 3. How repetitive sequences affect genome assembly. Resolving repetitive regions requires sequencing reads that are longer than the repeat itself, which allow us to determine the flanking sequences on the sides of the repeat. Using such long-read sequencing technology (i.e., PacBio and Nanopore sequencing), the Telomere-to-Telomere consortium was able to create a complete, ungapped assembly of the human genome in 2021. "],["the-human-reference-genome.html", "2.3 The human reference genome", " 2.3 The human reference genome Having to assemble an entire genome every time you sequence a new individual is a hassle (and often infeasible, if you don’t have enough sequencing data). Instead, we typically align sequencing reads to a reference genome – a high-quality genome assembly for that species, which we use to guide our analysis. The human reference genome was initially assembled in 2000 by the Human Genome Project, and has undergone decades of refinement since. The current version of this reference, which we’ll be using, is hg38. Whose DNA was sequenced for the human reference genome? DNA from multiple individuals was sequenced to construct the reference genome. Its sequence is a mosaic of these individuals’ DNA. You can classify the ancestry of different parts of hg38 by comparing its sequence to DNA from different populations. From this, we know that around 70% of hg38 comes from one individual, called RP11, who likely had African American ancestry. Fig. 4. Sample composition of the human reference genome. "],["ucsc-genome-browser.html", "2.4 UCSC genome browser", " 2.4 UCSC genome browser What does the human reference genome actually look like? We can view it in the UC Santa Cruz (UCSC) genome browser, an interactive website for viewing genomes – both the human reference and reference genomes for several other species. The browser also displays genome annotations, such as the locations of genes and clinically relevant genetic variants. Go to the UCSC genome browser. 2.4.1 Homepage There are a few key areas of this page: Browse/Select Species – choose the species Human Assembly – choose the version of the human reference genome Position/Search Term – type in a specific position (ex: chr2:25160915), region (ex: chr1:100000-200000), or gene name (ex: HLA-A) Fig. 5. UCSC genome browser homepage. In Position/Search Term, type in a gene you’re interested in and hit enter. Why are there different versions of the reference genome? You may have noticed that the name of the reference genome we’re using is GRCh38 or hg38, which stands for Genome Reference Consortium Human Build 38 – version 38 of the reference genome. Over time, the Genome Reference Consortium makes improvements to the reference genome by closing gaps, fixing problems, and resolving repetitive regions. hg38, the most recent version, was released in 2013. "],["viewing-one-region-of-the-genome.html", "2.5 Viewing one region of the genome", " 2.5 Viewing one region of the genome Once you hit enter, you should end up on a page like this: Fig. 6. Viewing one genomic region in the UCSC genome browser. The default display includes these broad groups of annotations: Navigation: Buttons for zooming and moving around (you can also move by clicking the display, holding, and moving your mouse); current region; search bar Position: Current position on the chromosome; current base pair position Genes: Gene annotations; gene expression by tissue; gene regulatory elements (CREs) Species comparison: DNA sequence conservation across vertebrates; regions that align with the genomes of other vertebrates Variation: Genetic variants in the dbSNP database; repeat elements Inspecting a specific track If you’re interested in more information about a specific track – for example, the POMC gene annotation – you can click on that element to go to a webpage with more details. Fig. 7. Clicking on the POMC gene track. (Note that if you click on whitespace instead of an annotation element, it will change the track’s display density instead.) Fig. 8. Clicking on whitespace to expand the RefSeq genes track. Customizing the display tracks The tracks that are automatically displayed are just a small subset of what’s available. You can select which tracks you want to see, and set their display density, by scrolling down on the page. To add a new track to your browser view, click the drop-down menu below that track and select any of the options besides hide. Here we’re viewing the “Clone Ends” track, which shows the different individuals that were sequenced to create this section of the reference genome. Fig. 9. Adding the “clone ends” track to the browser. Click the refresh button in the upper right to reload the genome view. You should see something like this, showing that this region of the reference genome was sequenced in three individuals (CH17, CTD, and RP11): Fig. 10. Viewing the “clone ends” track. "],["igv.html", "2.6 IGV", " 2.6 IGV While the UCSC genome browser lets you view the reference genome itself, we’re often interested in looking at sequencing data – sequencing reads that are aligned to the reference genome. For this we use the Integrative Genomics Viewer (IGV). Go to the IGV web app. 2.6.1 Homepage The IGV homepage is fairly empty because we haven’t loaded any sequencing reads to look at, and also because we’re zoomed too far out to see anything. The Genome tab in the upper right lets you choose which reference genome to work in. The default is hg38 A drop-down menu and search bar below the header allow you to pick a chromosome and genomic position Fig. 11. The IGV homepage. We haven’t chosen a chromosome yet, so all of them are displayed below the drop-down menu. Click on one to go to a zoomed-in view of that particular chromosome. "],["navigating-igv.html", "2.7 Navigating IGV", " 2.7 Navigating IGV Once you’ve clicked on a chromosome, zoom in until you can see colors on the top track. This track displays the DNA sequence, colored by nucleotide. The track below the DNA sequence has gene annotations from RefSeq. Fig. 12. Viewing a gene in IGV. "],["loading-sequencing-data.html", "2.8 Loading sequencing data", " 2.8 Loading sequencing data Click on the Genome drop-down menu and switch to the Human (hg38 1kg/GATK) reference genome. This version of the hg38 reference has sequencing data already loaded into the IGV web app. Once you’ve switched references, click Tracks -&gt; 1KG Low Coverage Alignments. This gives you a list of sample to load sequencing data from. Click any sample and then OK. Fig. 13. Loading reads from a 1000 Genomes sample. "],["the-1000-genomes-project.html", "2.9 The 1000 Genomes Project", " 2.9 The 1000 Genomes Project Where did this sequencing data come from? In 2015, a study called the 1000 Genomes Project (1KG or 1KGP) sequenced 3,202 individuals from 26 globally diverse populations. Because this data is publicly available, it’s become one of the most widely used datasets in human genetics. Notably, 1KGP still excludes key regions of the world – such as Oceania, the Middle East, native American populations in North America, and many populations within Africa. Fig. 14. Regions sampled by the 1000 Genomes Project. Go to the 1000 Genomes Project website and click the Data tab. Then click the link to the data portal. Fig. 15. The data portal includes information about the samples in this dataset. Choose any individual and copy their sample ID (ex: HG00138). We can use this sample ID to find this individual’s raw sequencing data in the Sequence Read Archive (SRA). "],["sra.html", "2.10 SRA", " 2.10 SRA Search for the sample ID you chose in SRA. You should see something like this, where every item is a sequencing dataset generated for this sample. Fig. 16. Finding sequencing data in SRA. 2.10.1 Previewing sequencing data Choose any sequencing dataset, and then click on any item in the Run table at the bottom. This takes you to a page that displays a specific sequencing run (i.e., one use of a sequencing machine). Go to the Reads tab. Fig. 17. The Reads tab in SRA. The right-hand panel shows one sequencing read from this run. Note that the sequence of this read is around 100bp long – the average length for short-read Illumina sequencing. All sequencing data looks like this! It’s just a text file filled with the IDs and DNA/RNA sequences of your reads. "],["viewing-sequencing-reads-in-igv.html", "2.11 Viewing sequencing reads in IGV", " 2.11 Viewing sequencing reads in IGV Now that we’ve seen what raw sequencing data looks like, let’s look at it in IGV. Return to your IGV tab, where you should have one sample’s DNA sequencing data loaded. Make sure you’re zoomed in enough for the data to display. Fig. 18. The Reads tab in SRA. The top track is a histogram of sequencing coverage (i.e., how many reads there are at that position in the genome). The bottom track shows the reads themselves. How do we know where in the genome each read belongs? We match the sequence of the read to the sequence of the reference genome (called alignment). With 100bp reads, the probability that a match occurs by chance is \\(\\frac{1}{4^{100}}\\), or \\(6.2 * 10^{-61}\\). Extracting alignment information in IGV If you click on a specific read, IGV will display additional information about it, including: The exact position it aligns to The mapping quality (a score indicating how uniquely it aligns to this position) If you’re working with paired-end sequencing data, where its paired read is Fig. 19. Viewing additional info for one sequencing read. "],["interpreting-igv-alignments.html", "2.12 Interpreting IGV alignments", " 2.12 Interpreting IGV alignments Sequencing reads in IGV are colored at bases where they differ from the reference genome. These differences can be caused by either real genetic variation or sequencing error. How would you distinguish these two? Fig. 20. Two of these colored bases are probably real SNPs, and two are probably errors. The sequencing coverage track also colors the positions that it thinks are real variants. In the screenshot above, which spans about 2kb, there are two SNPsin the coverage track. This pattern holds more broadly through the genome – humans carry about one SNP every 1,000 bases. Is one SNP every 1,000bp a lot or a little? Humans actually have much lower amounts of genetic variation than many species, including many of the great apes. This is mostly the result of human evolutionary history. Because the effective size of human populations has historically been low, with only very recent expansion, the gene pool is still fairly homogenous, with many rare variants and few common ones. "],["conclusion.html", "2.13 Conclusion", " 2.13 Conclusion In this lab, we explored several of the most commonly used websites in genomics: 2.13.0.1 Genome browsers UCSC genome browser: Used to explore features of the human genome If you discover an interesting SNP in your research, you might look it up in the UCSC browser to see which genes it’s in/near, if it overlaps with any repetitive elements, etc. IGV: Used to visualize sequencing data It’s common practice to look at your sequencing reads in IGV to check alignment quality, verify that SNPs look like real variants and not errors, etc. 2.13.0.2 Data repositories 1000 Genomes Project: One of the largest and most diverse datasets of human sequencing data Data from 1000 Genomes is frequently used in human genetics studies SRA: A repository for publicly available sequencing data Genetics studies deposit their data in SRA if it can be made publicly available (i.e., if it has no identifiable information) "],["homework.html", "2.14 Homework", " 2.14 Homework 2.14.0.1 Assignment Create an account on Posit Cloud. "],["discovering-mutations.html", "3 Discovering mutations", " 3 Discovering mutations In this module, we’ll use DNA sequencing data from human families to explore the relationship between parental age and de novo mutations in their children. 3.0.0.1 Learning objectives After completing this chapter, you’ll be able to: Create plots to visualize the relationship between two variables. Interpret the results of a linear model. Compare the impact of maternal vs. paternal age on de novo mutation counts. Explain what a confidence interval is and why it’s useful. "],["de-novo-mutations.html", "3.1 De novo mutations", " 3.1 De novo mutations Mutation and recombination are two biological processes that generate genetic variation. When these phenomena occur during gametogenesis, the changes that they make to DNA are passed down to the next generation through germline cells (i.e., sperm and oocyte). De novo mutations (DNMs) arise from errors in DNA replication or repair. These mutations can be single-nucleotide polymorphisms (SNPs) or insertions and deletions of DNA. Every individual typically carries around 70 de novo SNPs that were not present in either of their parents. Fig. 1. Sources of DNMs in gametogenesis. "],["recombination.html", "3.2 Recombination", " 3.2 Recombination Crossovers, or meiotic recombination, occur during prophase of meiosis I, when homologous chromosomes pair with each other. Double-strand breaks are deliberately generated in the DNA, and are then cut back and repaired based on the sequence of the homologous chromosome. These repairs can sometimes resolve in a crossover event, where sections of DNA are swapped between chromosomes. Because the sequences of homologous chromosomes differ at sites where they carry different alleles, recombination generates genetic diversity by creating new haplotypes, or combinations of alleles. Crossovers are required for meiosis in most organisms because they ensure proper homologous chromosome pairing and segregation. Humans experience 1-4 crossover events per chromosome, with longer chromosomes having more crossovers. Fig. 2. Possible outcomes for double-strand breaks generated during meiosis I. Adapted from Molecular Biology of the Cell, 6th Edition (Alberts et al.) "],["setup.html", "3.3 Setup", " 3.3 Setup In this module, we’ll use sequencing data from families to look at the relationship between DNMs, crossovers, and parental age. 3.3.1 R packages We’re using R’s tidyverse library to analyze our data. You can load this R package by running: library(tidyverse) 3.3.2 Data Our data comes from the supplementary tables of this paper by Halldorsson et al., which performed whole-genome sequencing on “trios” (two parents and one child) in Iceland. We’ve pre-processed the data to make it easier to work with. Load the pre-processed data by running the code chunk below. # read data dnm_by_age &lt;- read.table(&quot;dnm_by_age_tidy_Halldorsson.tsv&quot;, sep = &quot;\\t&quot;, header = TRUE) # preview data head(dnm_by_age) ## Proband_id n_paternal_dnm n_maternal_dnm n_na_dnm Father_age Mother_age ## 1 675 51 19 0 31 36 ## 2 1097 26 12 1 19 19 ## 3 1230 42 12 3 30 28 ## 4 1481 53 14 1 32 20 ## 5 1806 61 11 6 38 34 ## 6 2280 63 9 3 38 20 The columns in this table are: Proband_id: ID of the child (i.e., “proband”) n_paternal_dnm: Number of DNMs (carried by the child) that came from the father n_maternal_dnm: Number of DNMs that came from the mother n_na_dnm: Number of DNMs whose parental origin can’t be determined Father_age: Father’s age at proband’s birth Mother_age: Mother’s age at proband’s birth "],["visualizing-the-data.html", "3.4 Visualizing the data", " 3.4 Visualizing the data We can use our tidied data to ask questions about the de novo mutation rate in these Icelandic individuals. How does parental age affect the number of DNMs for males and females? Use the dnm_by_age data to plot this relationship for males. ggplot(data = dnm_by_age, # specify where ggplot should be getting the x location for each data point aes(x = Father_age, # specify where ggplot should be getting the y location for each data point y = n_paternal_dnm)) + # specify that the data should be plotted as points geom_point() Based on your plot, would you say that there’s an association between paternal age and number of DNMs? It looks like there’s a pretty strong association between paternal age and number of DNMs, where older males have more DNMs. Modify your code to plot the relationship between age and number of DNMs for females. Does there seem to be an association between maternal age and number of DNMs? ggplot(data = dnm_by_age, aes(x = Mother_age, y = n_maternal_dnm)) + geom_point() There’s also a strong positive association between maternal age and number of DNMs, although the slope (i.e., the increase in number of DNMs per year) is shallower. "],["linear-models.html", "3.5 Linear models", " 3.5 Linear models We can visually observe that age seems associated with number of DNMs in both males and females, but we need a way to ask if that this is a statistically meaningful association. We can do this with a linear model. This model fits a line to the plots that we just made, and asks if the slope is significantly different from 0 (i.e., if there’s a significant increase in DNM count as age increases). If this is a statistical test, what’s the null hypothesis? The null hypothesis for this linear model is that the slope is 0 – i.e., that there’s no association between parental age and the number of DNMs from that parent. If the slope is significantly different from 0, we can reject the null hypothesis. We’ll fit a linear model using R’s lm function. Run the following code block to open a manual describing the function. ?lm lm requires two arguments: The formula or equation it’s evaluating A table of data The formula must be in the format response variable ~ predictor variable(s), where each variable is the name of a column in our data table. Is our predictor variable the parental age or the number of DNMs? The predictor variable is parental age. We expect the number of DNMs to change as a consequence of parental age. "],["fitting-a-linear-model-for-dnms.html", "3.6 Fitting a linear model for DNMs", " 3.6 Fitting a linear model for DNMs Run the following code to fit a model for the effect of age on paternal DNMs. # fit linear model for paternal DNMs fit_pat &lt;- lm(formula = n_paternal_dnm ~ Father_age, data = dnm_by_age) # print results of model summary(fit_pat) ## ## Call: ## lm(formula = n_paternal_dnm ~ Father_age, data = dnm_by_age) ## ## Residuals: ## Min 1Q Median 3Q Max ## -32.785 -5.683 -0.581 5.071 31.639 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.58819 1.70402 6.214 1.34e-09 *** ## Father_age 1.34849 0.05359 25.161 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8.426 on 388 degrees of freedom ## Multiple R-squared: 0.62, Adjusted R-squared: 0.619 ## F-statistic: 633.1 on 1 and 388 DF, p-value: &lt; 2.2e-16 How do you interpret results from a linear model? For our purposes, the only part of the results you need to look at is the line under (Intercept) in the Coefficients section: Estimate Std. Error t value Pr(&gt;|t|) Father_age 1.34849 0.05359 25.161 &lt; 2e-16 *** The fourth columm, Pr(&gt;|t|), is the p-value. Because this p-value is &lt; 2e-16, we can reject the null hypothesis and say that there is association between paternal age and the number of paternal DNMs. The first column, Estimate, is the slope, or coefficient. Linear regression fits a line to our plot of paternal age vs. number of DNMs. The coefficient estimate is the slope of that line. The slope for paternal age given by this linear model is 1.34849. We can interpret this number this way: For every additional year of paternal age, we expect 1.35 additional paternal DNMs in the child. Modify your code to assess the relationship between maternal age and number of maternal DNMs. Is this relationship significant? How many maternal DNMs do we expect for every additional year of maternal age? # fit linear model for maternal DNMs fit_mat &lt;- lm(formula = n_maternal_dnm ~ Mother_age, data = dnm_by_age) # print results of model summary(fit_mat) ## ## Call: ## lm(formula = n_maternal_dnm ~ Mother_age, data = dnm_by_age) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.8683 -3.1044 -0.2329 2.2394 17.5379 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.51442 0.98193 2.561 0.0108 * ## Mother_age 0.37846 0.03509 10.785 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.503 on 388 degrees of freedom ## Multiple R-squared: 0.2307, Adjusted R-squared: 0.2287 ## F-statistic: 116.3 on 1 and 388 DF, p-value: &lt; 2.2e-16 The p-value is &lt;2e-16 and the Mother_age slope is 0.37846. This relationship is significant, and we expect 0.38 more maternal DNMs for every additional year of maternal age. "],["confidence-intervals.html", "3.7 Confidence intervals", " 3.7 Confidence intervals Our models predict that there are 1.35 more DNMs for additional every year of paternal age, and 0.38 more DNMs for every additional year of maternal age. Does this mean that sperm and oocytes accumulate DNMs at different rates? The maternal and paternal slopes look different, but we need statistical evidence that they actually are. (For example, what if there’s a lot of variability in the maternal DNM data, and the true maternal coefficient could be anywhere between -1 and 10?) To do this, we compare the confidence intervals of our slope estimates. What is a confidence interval? We use confidence intervals when estimating a value – in this case, the Mother_age and Father_age slope parameters. A confidence interval (CI) is a random interval that has a 95% probability of falling on the parameter we are estimating. So, a 95% CI contains the true value of the slope 95% of the time. Keep in mind that the definition above (95% of random intervals fall on the true value) is not the same as saying there is a 95% chance that the true value falls within our interval. This latter statement is not accurate. In R, we get the confidence interval of a parameter from a linear model with the confint function. ?confint confint requires three arguments: A fitted linear model (our fit_pat variable) The parameter we want a CI for (Father_age) The CI’s probability (typically 95%) "],["calculate-95-cis.html", "3.8 Calculate 95% CIs", " 3.8 Calculate 95% CIs Run the following code to calculate the 95% confidence interval for the Father_age slope parameter. confint(fit_pat, &#39;Father_age&#39;, level = 0.95) ## 2.5 % 97.5 % ## Father_age 1.243118 1.45386 So, 95% of the time, the number of additional DNMs per year of paternal age is between 1.24 and 1.45. Modify your code to get the 95% CI for the Mother_age slope. What’s the interpretation of this confidence interval? confint(fit_mat, &#39;Mother_age&#39;, level = 0.95) ## 2.5 % 97.5 % ## Mother_age 0.3094713 0.4474528 95% of the time, the number of additional DNMs per year of maternal age is between 0.31 and 0.45. Now that we have the confidence intervals for both slope parameters, we can finally compare them. Our two CI ranges are non-overlapping. The paternal range is [1.24, 1.45] and the maternal range is [0.31, 0.45]. If the 95% CIs for two parameters don’t overlap, this strongly supports that the parameters are significantly different from one another. So, it seems likely that paternal and maternal gametes experience different rates of de novo mutation. If the CIs for two parameters overlap, are they not significantly different? Not necessarily. More analysis, like a hypothesis test, is needed to make a final decision. "],["conclusion-1.html", "3.9 Conclusion", " 3.9 Conclusion In this lab, we explored the relationship between parental age and the number of de novo mutations in their gametes. We plotted the relationship between maternal/paternal age and DNM count. This visualization suggested that DNM count increases with age for both groups. We confirmed this hypothesis by using a linear model, which tests if additional years of age have a non-zero effect on the number of DNMs. The number of paternal DNMs seemed to increase more quickly with age than maternal DNMs. We confirmed this by comparing the 95% confidence intervals of the slopes of the two models. One final question – let’s assume that there really is a difference between the effect of age on DNMs in male and female gametes. What biological reasons might be causing this difference? "],["homework-1.html", "3.10 Homework", " 3.10 Homework So far, we’ve only looked at the de novo mutation data from the Halldorsson et al. paper. Now we’ll use their data on the number of maternal and paternal origin crossovers (i.e., how many crossovers occurred across all chromosomes in the maternal and paternal gametes). 3.10.0.1 Learning Objectives Practice visualizing data with ggplot2 Interpret p-values and effect sizes from linear models "],["required-homework.html", "3.11 Required homework", " 3.11 Required homework The data from the paper has been pre-filtered for you. Run this code block to read it in: # read data crossovers &lt;- read.table(&quot;crossovers.tsv&quot;, header = TRUE) # preview data head(crossovers) ## Proband_id n_pat_xover n_mat_xover Father_age Mother_age ## 1 3 22 51 29 28 ## 2 10 26 50 26 26 ## 3 11 25 38 25 22 ## 4 15 24 50 31 26 ## 5 20 27 35 26 24 ## 6 22 28 40 39 31 The columns in this table are: Proband_id: ID of the child n_pat_xover: Number of crossovers (carried by the child) that occurred in the paternal gametes n_mat_xover: Number of crossovers that occurred in the maternal gametes Father_age: Father’s age at proband’s birth Mother_age: Mother’s age at proband’s birth Assignment: Using the ggplot code from this module, plot the relationship between parental age and number of crossovers. As with the DNM data, make one plot for the maternal crossovers and one plot for the paternal. Do you think parental age impacts crossover number? Solution Plot paternal crossovers: ggplot(data = crossovers, # x axis is paternal age aes(x = Father_age, # y axis is number of crossovers y = n_pat_xover)) + geom_point() Plot maternal crossovers: ggplot(data = crossovers, # x axis is maternal age aes(x = Mother_age, # y axis is number of crossovers y = n_mat_xover)) + geom_point() Just by eye, it doesn’t really seem that age affects number of crossovers for either mothers or fathers. "],["optional-homework.html", "3.12 Optional homework", " 3.12 Optional homework Assignment: Fit two linear models (one paternal, one maternal) to ask if there is an association between the number of parental crossovers and parental age. If there is an association, how is the number of crossovers predicted to change with every year of maternal/paternal age? Solution # fit the model with paternal age fit_pat &lt;- lm(data = crossovers, formula = n_pat_xover ~ Father_age) summary(fit_pat) ## ## Call: ## lm(formula = n_pat_xover ~ Father_age, data = crossovers) ## ## Residuals: ## Min 1Q Median 3Q Max ## -15.2173 -3.1880 -0.1997 2.8061 24.7652 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 26.369432 0.102736 256.67 &lt;2e-16 *** ## Father_age -0.005852 0.003462 -1.69 0.091 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.388 on 41090 degrees of freedom ## Multiple R-squared: 6.953e-05, Adjusted R-squared: 4.519e-05 ## F-statistic: 2.857 on 1 and 41090 DF, p-value: 0.09098 There isn’t a significant association between paternal age and the number of paternal crossovers (p = 0.091). # fit the model with maternal age fit_mat &lt;- lm(data = crossovers, formula = n_mat_xover ~ Mother_age) summary(fit_mat) ## ## Call: ## lm(formula = n_mat_xover ~ Mother_age, data = crossovers) ## ## Residuals: ## Min 1Q Median 3Q Max ## -27.161 -6.095 -0.425 5.641 45.905 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 41.709271 0.206238 202.24 &lt;2e-16 *** ## Mother_age 0.065989 0.007576 8.71 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8.685 on 41090 degrees of freedom ## Multiple R-squared: 0.001843, Adjusted R-squared: 0.001819 ## F-statistic: 75.87 on 1 and 41090 DF, p-value: &lt; 2.2e-16 Surprisingly, there is a significant association between maternal age and the number of maternal crossovers (p &lt; 2e-16). For every year of maternal age, we expect the child to carry 0.07 additional maternal origin crossovers. Although the maternal crossovers plot doesn’t look that impressive, our estimated slope is 0.07, which is probably too small to distinguish visually. "],["linkage-disequilibrium.html", "4 Linkage disequilibrium", " 4 Linkage disequilibrium In this module, we’ll use DNA sequencing data from human populations to assess linkage disequilibrium between two genetic variants. 4.0.0.1 Learning objectives After completing this chapter, you’ll be able to: Define linkage disequilibrium. Manually calculate \\(D\\), \\(D&#39;\\), and \\(r^2\\) from genotype data. Understand the differences in interpretation for different LD statistics. Explain how LD both benefits and limits genetics studies. "],["what-is-linkage-disequilibrium.html", "4.1 What is linkage disequilibrium?", " 4.1 What is linkage disequilibrium? Linkage disequlibrium (LD) refers to correlation among genotypes at multiple sites in the genome. This is a consequence of the fact that chromosomes are transmitted in “chunks” through the generations. When mutations arise, they arise on a single chromosome with a given set of alleles. The new mutation will continue to be associated with this genetic background until it is shuffled during the process of meiotic recombination. Together, a set of alleles that tend to occur together because of linkage disequilibrium is called a haplotype. Fig. 1. After a new mutation arises, recombination over the course of many generations reduces the number of variants in LD with it. "],["why-do-we-care-about-ld.html", "4.2 Why do we care about LD?", " 4.2 Why do we care about LD? As a result of linkage disequilibrium, knowledge of a genotype at one site in the genome can provide information about the genotype at another site, even if the second site was not actually genotyped. Using prior knowledge of LD to “fill in” missing genotype information is a process called imputation. Linkage disequilibrium also means that correlation between a genotype at a particular site and phenotype (e.g., disease outcome) does not imply causation. Even ignoring other possible confounders, any variant on the same haplotype could be driving the association. Beyond mutation and recombination, other evolutionary forces such as gene flow, genetic drift, and natural selection can also influence patterns of LD observed in population genetic data. Measuring linkage disequilibrium is therefore important for both medical and evolutionary studies. Fig. 2. LD can be used to impute missing genotypes, but also complicates genetic association studies (such as finding variants that cause disease). Non-causal variants in LD will perfectly co-occur with the causal variant, making it difficult to determine which one is truly causal. "],["setup-1.html", "4.3 Setup", " 4.3 Setup We’ll measure LD between two SNPs called in the 1000 Genomes Project dataset: rs28574812 (chr21:15012619) rs2251399 (chr21:15013185) We’ve preprocessed the original 1000 Genomes data such that every line in the table below represents one haplotype in the 1000 Genomes database. Load the pre-processed data by running the code below. # read data haplotypes &lt;- read.table(&quot;snp_haplotypes.txt&quot;, header = TRUE) # preview data head(haplotypes) ## sample haplotype snp1_allele snp2_allele ## 1 HG00096 hap_1 A C ## 2 HG00096 hap_2 A C ## 3 HG00097 hap_1 A C ## 4 HG00097 hap_2 A C ## 5 HG00099 hap_1 A C ## 6 HG00099 hap_2 A C The columns in this table are: sample: Name of the individual who was sequenced haplotype: Haplotype (i.e., the maternal or paternal chromosome) that the SNP is on snp1_allele: Genotype at SNP1 on this haplotype snp2_allele: Genotype at SNP2 on this haplotype Note that there are 2,504 samples in the 1000 Genomes Project but 5,008 total lines in the table. This is because there are two lines per individual – one for each of their maternal and paternal haplotypes. Fig. 3. Our reformatted VCF shows the combinations of alleles at two SNPs of interest, for all haplotypes in the 1000 Genomes dataset. "],["are-these-snps-in-ld.html", "4.4 Are these SNPs in LD?", " 4.4 Are these SNPs in LD? If we run table on each SNP column, we can see which alleles exist at SNP1 and SNP2. SNP1 can be A or G SNP2 can be C or T table(haplotypes$snp1_allele) ## ## A G ## 3456 1552 table(haplotypes$snp2_allele) ## ## C T ## 2825 2183 If these two SNPs were in perfect LD, we’d expect to see only two haplotypes in our data (Fig. 4A). A C: If someone carries an A at SNP1, they will always carry a C at SNP2. G T: If they carry a G at SNP1, they will always carry a T at SNP2. If these two SNPs were in linkage equilibrium, the allele at SNP1 would give us no information about SNP2. We would expect to see all four possible haplotypes, in amounts proportional to the component allele frequencies (Fig. 4B). A C A T G C G T Fig. 4. When two SNPs are in perfect LD, seeing an allele on one haplotype perfectly predicts which allele is on the other haplotype. "],["counting-haplotypes-with-table.html", "4.5 Counting haplotypes with table", " 4.5 Counting haplotypes with table We can use the table function to count the occurrence of the four possible haplotypes. table(haplotypes$snp1_allele, haplotypes$snp2_allele) ## ## C T ## A 2655 801 ## G 170 1382 The table tells us that there are 2655 A C haplotypes (A at SNP1 and C at SNP2), 170 G C haplotypes, etc. Do these SNPs look like they’re in LD? It looks like there are some haplotypes (A C and G T) that are overrepresented. However, it’s hard to tell whether that’s just because an A allele at SNP1 is much more common than T is. "],["fishers-exact-test.html", "4.6 Fisher’s exact test", " 4.6 Fisher’s exact test We can wrap our table in the fisher.test function to perform a Fisher’s exact test. This test tells us whether there is a non-random association between any of the SNP alleles, while accounting for the relative proportions of each allele. fisher.test(table(haplotypes$snp1_allele, haplotypes$snp2_allele)) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: table(haplotypes$snp1_allele, haplotypes$snp2_allele) ## p-value &lt; 2.2e-16 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 22.49760 32.33934 ## sample estimates: ## odds ratio ## 26.9124 The p-value is very small (&lt; 2.2e-16), so we can reject the null hypothesis that the two SNPs are associating independently of each other. How do we interpret the odds ratio from the Fisher’s exact test? In addition to the p-value, Fisher’s Exact Test also gives us an odds ratio of 26.9, with a 95% confidence interval of [22.5, 32.3]. In this context, the odds ratio reflects how much more likely you are to see an A at SNP1 if you also see an C at SNP2. We can observe that the 95% confidence interval doesn’t overlap with 1. An odds ratio of 1 would mean that seeing C at SNP2 doesn’t influence the probability of seeing an A at SNP1. This is a somewhat non-canonical usage of Fisher’s exact test, and in our case the odds ratio applies to whatever haplotype is in the top left corner of our 4x4 table. We could rearrange the table to calculate the odds ratio for any of the three other combinations of alleles. Together, the p-value and 95% confidence interval tell us that there is strong evidence of LD between these SNPs. Perhaps this isn’t surprising, since our two SNPs are common and close to one another on chromosome 21. "],["measuring-ld-with-d.html", "4.7 Measuring LD with \\(D\\)", " 4.7 Measuring LD with \\(D\\) If SNP1 and SNP2 are in linkage equilibrium, the probability of seeing an A C haplotype should be equal to the product of the allele frequencies of A and C. This is simply the probablity of observing two events together if the events are independent. Otherwise, for SNPs that are not independent of each other, we should see A C either more or less often than expected from the allele frequencies. This intuition is summarized in \\(\\mathbf{D}\\), a population genetics statistic for measuring LD between two SNPs. \\[ D = h_{12} - p_1*p_2 \\] \\(\\mathbf{h_{12}}\\) is the frequency of our haplotype of interest (A C). \\(\\mathbf{p_1*p_2}\\) is the product of the frequencies of the two alleles on this haplotype (A at SNP1 and C at SNP2) How do we interpret \\(D\\)? If two SNPs are in linkage equilibrium, \\(h_{12}\\) and \\(p_1*p_2\\) should be the same, and we should get \\(D = 0\\). If two SNPs are in linkage disequilibrium, \\(p_1*p_2\\) should be different from \\(h_{12}\\), so that \\(D \\neq 0\\). "],["calculating-d.html", "4.8 Calculating \\(D\\)", " 4.8 Calculating \\(D\\) We can re-run our table code to find the probabilities we need for calculating \\(D\\). table(haplotypes$snp1_allele, haplotypes$snp2_allele) ## ## C T ## A 2655 801 ## G 170 1382 \\[ D = h_{12} - p_1*p_2 \\] What are \\(h_{12}\\), \\(p_1\\), and \\(p_2\\)? \\(h_{12}\\) is the probability of seeing the A C haplotype. This is equal to the number of A C haplotypes over the number of total haplotypes: \\[\\frac{2655}{2655 + 170 + 801 + 1382} = \\frac{2655}{5008}\\] \\(p_1\\) is the probability that SNP1 is A. We can get this by adding across the first row of the table (i.e., adding the number of A C and A T haplotypes): \\[\\frac{2655 + 801}{5008}\\] \\(p_2\\) is the probability that SNP2 is C. We can get this by adding across the first column of the table (i.e., adding the number of A C and G G haplotypes): \\[\\frac{2655 + 170}{5008}\\] (Note that the denominator is always 5008 – the total number of haplotypes in our dataframe.) Now we can plug in the corresponding probabilities to calculate D: # define our probabilities of interest h &lt;- 2655 / 5008 p1 &lt;- (2655 + 801) / 5008 p2 &lt;- (2655 + 170) / 5008 # calculate D D &lt;- h - (p1 * p2) D ## [1] 0.1408705 \\(D = 0.14\\), which is non-zero, suggesting that these SNPs are in LD. "],["measuring-ld-with-d-1.html", "4.9 Measuring LD with \\(D&#39;\\)", " 4.9 Measuring LD with \\(D&#39;\\) Aside from being nonzero, what does the value of \\(D\\) mean? This is surprisingly hard to interpret because the minimum and maximum value of \\(D\\) is different for every pair of SNPs. Why does the range of \\(D\\) change? The possible values of \\(D\\) depend on the frequencies of the alleles at each SNP. For example: If \\(p_1 = 0.5\\) and \\(p_2 = 0.5\\), then \\(D\\) is between \\([-0.25, 0.25]\\) If \\(p_1 = 0.1\\) and \\(p_2 = 0.7\\), then \\(D\\) is between \\([-0.07, 0.03]\\) The \\(\\mathbf{D&#39;}\\) statistic fixes this issue by dividing \\(D\\) by its theoretical maximum. \\(D&#39;\\) is constrained between \\([-1, 1]\\), where more extreme values denote stronger LD. \\[ D&#39; = \\frac{D}{\\mathrm{max}(-p_1 p_2, -(1-p_1)(1-p_2))}, \\mathrm{\\:for\\:} D &lt; 0 \\\\ D&#39; = \\frac{D}{\\mathrm{min}(p_1 (1-p_2), p_2(1-p_1) )}, \\mathrm{\\:for\\:} D &gt; 0 \\] \\(p_1\\) and \\(p_2\\) are the frequencies of the alleles at SNP1 and SNP2. Use this formula to calculate \\(D&#39;\\) for our two SNPs of interest. Because \\(D\\) is positive, we use the second formula for \\(D&#39;\\). First, we need to find the denominator, which is the minimum of \\(p_1 (1-p_2)\\) and \\(p_2 (1-p_1)\\). p1 * (1-p2) ## [1] 0.3008145 p2 * (1-p1) ## [1] 0.1748161 p2 * (1-p1) is smaller, so we plug that into our \\(D&#39;\\) formula: Dprime &lt;- D / (p2 * (1-p1)) Dprime ## [1] 0.8058206 This tells us that LD between these two SNPs is 80.6% of its theoretical maximum. "],["measuring-ld-with-r2.html", "4.10 Measuring LD with \\(r^2\\)", " 4.10 Measuring LD with \\(r^2\\) \\(\\mathbf{r^2}\\) is the most common statistic for measuring LD. Its value ranges from [0, 1], where 1 indicates maximum LD. \\[ r^2 = \\frac{D^2}{p_1 (1-p_1) p_2 (1-p_2)} \\] Although it looks similar to the formulas for \\(D\\) and \\(D&#39;\\), \\(r^2\\) is actually derived from the correlation coefficient of the frequencies of SNP1 and SNP2, and has a slightly different interpretation: \\(D\\) and \\(D&#39;\\) measure whether recombination has occurred between two alleles \\(r^2\\) measures how well we can predict the allele at one locus if given the allele at the other locus Calculate \\(r^2\\) for our two SNPs of interest. r2 &lt;- D^2 / (p1*(1-p1)*p2*(1-p2)) r2 ## [1] 0.3773631 \\(r^2 = 0.38\\), indicating that these SNPs are in moderate LD. "],["ldlink.html", "4.11 LDlink", " 4.11 LDlink LDlink is a web application that allows you to compute and visualize linkage disequilibrium using data from the 1000 Genomes Project (the same dataset we’ve been using for this module). Go to LDlink’s LDpair tool, which computes \\(D&#39;\\) and \\(r^2\\) between pairs of SNPs. Using either the rsIDs or the chromosome and position of the two SNPs we looked at today, check our calculations for \\(D&#39;\\) and \\(r^2\\). Make sure you: Select All Populations, since we didn’t subset our data by population. If using SNP position, note that our data was aligned to the GRCh38 reference genome. Fig. 5. LDpair results for the two SNPs from this class. We can see that these \\(D&#39;\\) and \\(r^2\\) statistics, as well as the 4x4 table, are very similar to what we calculated by hand! (The values aren’t identical because we’re using a slightly different genotyping dataset.) "],["visualizing-ld-blocks.html", "4.12 Visualizing LD blocks", " 4.12 Visualizing LD blocks LDproxy, another LDlink tool, finds all SNPs in strong LD with a SNP of interest. Open LDproxy and use it to search for one of the SNPs from today (it may take the webpage a minute to load the results). Fig. 6. LDproxy results for rs28574812. To generate this plot, LDproxy calculated \\(r^2\\) between our SNP of interest and all other SNPs in a 500kb window. As expected, we can see that LD is strongest for variants that are closest to the SNP. LDproxy also provides even more information than just LD – it also includes regulatory annotations for all the variants in this region (the numbers within each dot), as well as gene annotations and a list of nearby variants (below the plot). "],["ld-in-association-studies.html", "4.13 LD in association studies", " 4.13 LD in association studies The figure below is a locuszoom plot – a common visualization of data from genome-wide association studies (GWAS). This particular study was a GWAS for genetic variants that impact mean corpuscular hemoglobin concentration. The left y-axis is the p-value for the association with mean corpuscular hemoglobin concentration Each variant is colored by its \\(\\mathbf{r^2}\\) with the top hit variant (in purple) The heatmap on the bottom shows pairwise LD between variants The right y-axis and dark blue line show the frequency of recombination events. Peaks are recombination hotspots (note how they line up with the boundaries of LD blocks in the heatmap) We can observe a block of red/orange variants with almost the same p-value as the top hit. All of these variants are in strong LD with each other: all of them except the leftmost cluster fall within the same LD block in the heatmap on the bottom. As a result, any of them could be causal – i.e., the one that actually affects corpuscular hemoglobin. This is a problem that affects all association studies. Two common ways of working around LD to identify causal variants are: Statistical fine mapping: Uses patterns of LD and statistical models to narrow down casual variant sets Experimental screening: Tests candidate variants in vitro (ex: massively parallel reporter assays, CRISPR screens) to determine which have functional effects Fig. 7. GWAS associations with mean corpuscular hemoglobin concentration, from this paper. "],["conclusion-2.html", "4.14 Conclusion", " 4.14 Conclusion In this lab, we used genotype data from the 1000 Genomes Project to ask whether there is linkage disequilibrium between two SNPs on chr21. Using data from the VCF, we used table to count how often we observe combinations of alleles at these SNPs. We used the data in the table to calculate three LD statistics: \\(\\mathbf{D}\\): the deviation of the observed haplotype frequency from the expected haplotype frequency \\(\\mathbf{D&#39;}\\): a normalization of \\(D\\) that ranges from \\([-1, 1]\\) \\(\\mathbf{r^2}\\): how well the allele at one locus predicts the allele at another locus We used LDlink to visualize how blocks of LD define haplotypes. "],["homework-2.html", "4.15 Homework", " 4.15 Homework 4.15.0.1 Learning Objectives Calculate and interpret LD statistics 4.15.0.2 Assignment We’ve subset the VCF from class to show haplotypes for two different pair of SNPs: chr21:15005329 and chr21:15007704 chr21:15336586 and chr21:15336794 # read data for first set of SNPs hw1 &lt;- read.table(&quot;snp_haplotypes_hw1.txt&quot;, header = TRUE) # read data for second set of SNPs hw2 &lt;- read.table(&quot;snp_haplotypes_hw2.txt&quot;, header = TRUE) Assignment: Using the code from class, calculate \\(D\\), \\(D&#39;\\), and \\(r^2\\) for these sets of SNPs. Which alleles are segregating together? What does each LD statistic indicate? (Feel free to check your work on LDpair.) Solution for first set of SNPs First use table to count the occurences of the four haplotypes. table(hw1$snp1_allele, hw1$snp2_allele) ## ## A G ## C 747 2508 ## T 2 1751 All four possible haplotypes exist in this population. \\(\\mathbf{D = h_{12} - p_1*p_2}\\) h &lt;- 747 / 5008 p1 &lt;- (747 + 2508)/5008 p2 &lt;- (747 + 2)/5008 D &lt;- h - p1 * p2 D ## [1] 0.05195286 \\(D\\) is non-zero, which suggests that these SNPs might be in LD. \\(\\mathbf{D&#39; = \\frac{D}{\\mathrm{min}(p_1 (1-p_2), p_2(1-p_1))}}\\) (because \\(D &gt; 0\\)) First we determine the denominator by calculating which of \\(p_1 (1-p_2)\\) and \\(p_2(1-p_1)\\) is smaller: p1 * (1-p2) ## [1] 0.5527516 p2 * (1-p1) ## [1] 0.05235222 \\(p_2(1-p_1)\\) is smaller, so we use it for the denominator. \\(D&#39;\\) is: Dprime &lt;- D / ((1-p1) * p2) Dprime ## [1] 0.9923717 \\(D&#39; = 0.99\\), which indicates very high LD (almost no recombination has occurred between alleles on this haplotype). \\(\\mathbf{r^2 = \\frac{D^2}{p_1 (1-p_1) q_1 (1-q_1)}}\\) r2 &lt;- D^2 / (p1 * (1-p1) * p2 * (1-p2)) r2 ## [1] 0.09327254 However, \\(r^2 = 0.09\\) (linkage equilibrium)! This is because one of the haplotypes, A T, is very rare – there are only two copies in the population. \\(r^2\\) tells us that the counts of the A T haplotype are so low that an A at SNP1 doesn’t do a great job of predicting when SNP2 is T. Solution for second set of SNPs First use table to count the occurences of the four haplotypes. table(hw2$snp1_allele, hw2$snp2_allele) ## ## A G ## A 3522 0 ## G 0 1486 The only haplotypes that exist in this population are A C and G G. \\(\\mathbf{D = h_{12} - p_1*p_2}\\) h &lt;- 3522 / 5008 p1 &lt;- (3522 + 0)/5008 p2 &lt;- (3522 + 0)/5008 D &lt;- h - p1 * p2 D ## [1] 0.2086794 \\(D\\) is non-zero, which suggests that these SNPs might be in LD. \\(\\mathbf{D&#39; = \\frac{D}{\\mathrm{min}(p_1 (1-q_1), (1-p_1)q_1 )}}\\) (because \\(D &gt; 0\\)) First we determine the denominator by calculating which of \\(p_1 (1-p_1)\\) and \\(p_2 (1-p_2)\\) is smaller: p1 * (1-p2) ## [1] 0.2086794 p2 * (1-p1) ## [1] 0.2086794 The two values are exactly the same, so we can use either for the denominator. \\(D&#39;\\) is: Dprime &lt;- D / (p1 * (1-p2)) Dprime ## [1] 1 \\(D&#39; = 1\\)! These SNPs are in maximum LD (no recombination has occured between them). \\(\\mathbf{r^2 = \\frac{D^2}{p_1 (1-p_1) p_2 (1-p_2)}}\\) r2 &lt;- D^2 / (p1 * (1-p1) * p2 * (1-p2)) r2 ## [1] 1 \\(r^2 = 1\\)! These SNPs are in maximum LD (everyone who carries an A at SNP1 has an A at SNP2, and everyone with a G at SNP1 has a G at SNP2). "],["simulating-evolution.html", "5 Simulating evolution", " 5 Simulating evolution In this lab, we’ll build a simulation to explore genetic drift using the Wright-Fisher model. 5.0.0.1 Learning objectives After completing this chapter, you’ll be able to: Describe the phenomenon of genetic drift. Explain why random draws from a binomial distribution are a good way to mimic the effect of drift. Interpret allele frequency patterns that occur as a result of drift. Write a for loop in R. Write a function to run code multiple times with different parameters. "],["genetic-drift.html", "5.1 Genetic drift", " 5.1 Genetic drift In all populations, genetic drift acts to change allele frequencies over time. Drift refers to random changes in an allele’s frequency between generations. These random changes occur because individuals carrying different alleles will have different numbers of offspring due to chance. Fig. 1. An allele’s frequency “drifts” between generations due to random chance. Drift differs from selection, which is a deterministic (non-random) change in an allele’s frequency. If an allele is under selection, it’s more likely to increase or decrease in frequency depending on whether it is beneficial or deleterious. Genetic drift, on the other hand, cannot consistently cause an allele’s frequency to increase or decrease. "],["the-wright-fisher-model.html", "5.2 The Wright-Fisher model", " 5.2 The Wright-Fisher model The Wright-Fisher model is one of the most commonly used models of genetic drift. In this model, we assume that a population: Mates randomly Number of individuals remains constant between generations Today, we’ll also assume that the population is haploid Populations in the real world don’t behave like an ideal Wright-Fisher population, so their effective population size Ne is usually much smaller than their actual population size. The effective population size of the human population is only 12,800–14,400 individuals, even though its actual size is around 8 billion. "],["allele-frequency-fixation-and-loss.html", "5.3 Allele frequency, fixation, and loss", " 5.3 Allele frequency, fixation, and loss The Wright-Fisher model describes the behavior of a single allele, which can be at any variable site in a population (a SNP, insertion/deletion, version of a gene, etc.). The allele of interest begins the simulation at some initial allele frequency (AF). This allele frequency is the proportion of individuals in the population who carry that allele, and is always between 0 and 1. An allele becomes fixed in a population if it reaches an allele frequency of 1, and is lost if it reaches a frequency of 0. At either of these points, it is no longer considered a variable site because either everyone or no one in the population carries it. Fig. 2 (source). Trajectories of alleles at two loci fixing, at AF = 0 and AF = 1. "],["modeling-allele-frequencies.html", "5.4 Modeling allele frequencies", " 5.4 Modeling allele frequencies In the Wright-Fisher model, we track a population over the course of many generations. Within each generation: For every individual, we perform a coin flip to determine whether or not they have the allele. Unlike a coin, the probability of receiving an allele is equal to its allele frequency in the current generation. The more common an allele is in this generation, the more likely it is that someone in the next generation will also carry it. After flipping these coins, we know the number of people in the next generation who carry the allele. Fig. 3. Every individual flips a weighted coin to determine whether they will carry the blue allele in the next generation. The probability of carrying the allele is equal to the allele’s frequency in the current generation. "],["the-binomial-distribution.html", "5.5 The binomial distribution", " 5.5 The binomial distribution Instead of having to actually simulate all the coin flips, we can get the number of allele carriers by performing a single draw from a binomial distribution with size N (# of individual) and success probability p = AF. This distribution tells you how many successes you expect to see from a set of N independent coin flips. If we try to draw 100,000 times from a binomial distribution with population size 100 and success probability (AF) 0.5, it will look something like this: Figure 5.1: 100,000 draws from a binomial distribution. The majority of the distribution lies between 48 and 52. Just as we expect based on the allele frequency, the next generation will most likely have around 48-52 individuals with the A allele. But because this is a random draw, there’s a small chance that we might end up with many more or many fewer than that number. "],["setup-2.html", "5.6 Setup", " 5.6 Setup 5.6.1 R packages library(tidyverse) 5.6.2 Data We’ll simulate all of our own data for this lab! "],["the-rbinom-function.html", "5.7 The rbinom function", " 5.7 The rbinom function The basis of our simulation is R’s rbinom function, which allows us to sample from a binomial distribution. rbinom takes three arguments: n: how many times we’re drawing from the distribution size: the size of the population we’re sampling from (i.e. N) p: the success probability (i.e. allele frequency) Every generation, we’ll draw once to produce the number of individuals carrying the A allele in the next generation. Let’s once again look at a population of size 100, and an A allele currently at AF = 0.5. We use rbinom to get the number of individuals in the next generation who will have A: rbinom(n = 1, size = 100, prob = 0.5) ## [1] 45 Change the rbinom code so that it returns the allele frequency (instead of the number of individuals). # divide by the population size to get AF rbinom(n = 1, size = 100, prob = 0.5) / 100 ## [1] 0.51 Why do we get a different number every time we run rbinom? rbinom generates a random number between 0 and 100. Because it’s random, the number it draws will be different every time we run it. "],["increasing-population-size.html", "5.8 Increasing population size", " 5.8 Increasing population size Currently, we’re drawing from a population of 100 individuals. Now let’s see what happens when we increase the population size. (Feel free to run this code block multiple times!) rbinom(n = 1, size = 10000, prob = 0.5) / 10000 ## [1] 0.4934 If you run the code block above multiple times, you’ll observe that the AF is much closer to 0.5 than it was with a population of size 100. This lends to our intuition that an allele’s frequency fluctuates much more when a population is small, and is more stable when the population size is large. How does population size affect an allele’s time to fixation? As population size gets larger, the allele will take longer to fix. "],["simulating-multiple-generations.html", "5.9 Simulating multiple generations", " 5.9 Simulating multiple generations Currently, we draw once from a binomial distribution to get the number of individuals in one generation who carry the allele of interest. How do we adapt this to simulate multiple generations? Increasing n (ex: rbinom(n = 10, size = 100, prob = 0.5)) Increasing n only gives you multiple replicate draws from the same distribution. This doesn’t reflect multiple generations, because the allele frequency doesn’t update between generations based on the new number of alleles – it uses prob = 0.5 every time. "],["for-loops.html", "5.10 For loops", " 5.10 For loops Instead of drawing multiple times from the same distribution, we can write a for loop to repeatedly generate and update the number of individuals with the A allele. A for loop allows you to run some code X number of times. For example: for (i in 1:3) { print(i) } ## [1] 1 ## [1] 2 ## [1] 3 This for loop goes through all the values between 1 and 3, and prints each of them out. Modify the for loop to instead run our rbinom command. for (i in 1:3) { print(rbinom(n = 1, size = 100, prob = 0.5) / 100) } ## [1] 0.49 ## [1] 0.45 ## [1] 0.43 "],["updating-variables-within-a-for-loop.html", "5.11 Updating variables within a for loop", " 5.11 Updating variables within a for loop We also need to update the allele frequency in every iteration of the for loop. We do this by adding a freq variable that keeps track of the current AF: # start an initial AF of 0.5 freq &lt;- 0.5 for (i in 1:3) { # run rbinom to generate the AF for the next generation new_freq &lt;- rbinom(n = 1, size = 100, prob = freq) / 100 # print new AF print(new_freq) # update `freq` in each iteration of the loop freq &lt;- new_freq } ## [1] 0.53 ## [1] 0.51 ## [1] 0.52 "],["adding-a-population-size-variable.html", "5.12 Adding a population size variable", " 5.12 Adding a population size variable Using the freq variable also gives us more flexibility than hard-coding an allele frequency into the rbinom command. Add to your code so that we also provide Ne (effective population size) as a variable (without updating it in the for loop). # set effective population size outside of for loop Ne &lt;- 100 # start an initial AF of 0.5 freq &lt;- 0.5 for (i in 1:3) { # run rbinom to generate the AF for the next generation new_freq &lt;- rbinom(n = 1, size = Ne, prob = freq) / Ne # print new AF print(new_freq) # update `freq` in each iteration of the loop freq &lt;- new_freq } ## [1] 0.53 ## [1] 0.47 ## [1] 0.43 "],["changes-in-af-over-generations.html", "5.13 Changes in AF over generations", " 5.13 Changes in AF over generations Try increasing the number of generations we run the simulation for. What patterns of change do you observe in the allele frequencies? Ne &lt;- 100 freq &lt;- 0.5 for (i in 1:20) { new_freq &lt;- rbinom(n = 1, size = Ne, prob = freq) / Ne print(new_freq) freq &lt;- new_freq } ## [1] 0.53 ## [1] 0.44 ## [1] 0.41 ## [1] 0.48 ## [1] 0.55 ## [1] 0.49 ## [1] 0.5 ## [1] 0.5 ## [1] 0.44 ## [1] 0.48 ## [1] 0.51 ## [1] 0.46 ## [1] 0.45 ## [1] 0.48 ## [1] 0.46 ## [1] 0.51 ## [1] 0.55 ## [1] 0.58 ## [1] 0.54 ## [1] 0.56 The allele frequency starts approaching either 0 or 1. "],["storing-afs-in-a-vector.html", "5.14 Storing AFs in a vector", " 5.14 Storing AFs in a vector To plot how the AF changes over time, we can store the AF at each generation in a vector. Vectors R’s version of a list, and are formed with the c() function, which stands for “combine”: my_vec &lt;- c(0.5, 0.6) my_vec ## [1] 0.5 0.6 You can append elements to a vector called my_vec by running: my_vec &lt;- c(my_vec, new_element). Modify the code block with our for loop to create a vector for storing allele frequencies, and then append the updated AF to it every generation. We need to create the vector before the for loop, and then append to the vector within the for loop. Ne &lt;- 100 freq &lt;- 0.5 # create vector to store AFs in freq_vector &lt;- freq for (i in 1:20) { new_freq &lt;- rbinom(n = 1, size = Ne, prob = freq) / Ne # add new freq to the AF vector freq_vector &lt;- c(freq_vector, new_freq) freq &lt;- new_freq } freq_vector ## [1] 0.50 0.52 0.64 0.63 0.65 0.63 0.61 0.68 0.68 0.65 0.63 0.63 0.64 0.62 0.57 ## [16] 0.60 0.61 0.63 0.64 0.65 0.68 "],["reformatting-afs-for-plotting.html", "5.15 Reformatting AFs for plotting", " 5.15 Reformatting AFs for plotting Because ggplot requires its input data to be formatted as a table, we have to convert freq_vector into some form of table (ex: a tibble or dataframe). sim_results &lt;- tibble(af = freq_vector) head(sim_results) ## # A tibble: 6 × 1 ## af ## &lt;dbl&gt; ## 1 0.5 ## 2 0.52 ## 3 0.64 ## 4 0.63 ## 5 0.65 ## 6 0.63 This table contains the information that we want on the plot’s y axis. We can now add in a column containing the plot’s x axis data, which is the generation that each AF value corresponds to. sim_results &lt;- tibble(af = freq_vector, gen = 1:21) head(sim_results) ## # A tibble: 6 × 2 ## af gen ## &lt;dbl&gt; &lt;int&gt; ## 1 0.5 1 ## 2 0.52 2 ## 3 0.64 3 ## 4 0.63 4 ## 5 0.65 5 ## 6 0.63 6 Why does the gens column range from 1 to 21 (instead of 1 to 20)? We add our starting allele frequency to freq_vector, and then simulate for 20 generations. This means that we end up with 21 AFs in our vector. "],["plotting-af-trajectory.html", "5.16 Plotting AF trajectory", " 5.16 Plotting AF trajectory Plot the trajectory of AFs over time with ggplot. ggplot(data = sim_results, aes(x = gen, y = af)) + geom_line() "],["simulating-different-parameters-with-a-function.html", "5.17 Simulating different parameters with a function", " 5.17 Simulating different parameters with a function It would be nice to be able to run our Wright-Fisher simulation with different parameters – like different starting allele frequencies, population sizes, etc. – without having to edit the for loop code every time. We can use a function to generalize the code above so we can easily re-run it. The structure of an R function You’ve already encountered many functions in R, even if you didn’t realize it at the time - rbinom, ggplot, and print are all examples of functions. An R function has four parts: &lt;Name&gt; &lt;- function(&lt;Argument(s)&gt;) { &lt;Body&gt; &lt;return()&gt; } Name − The function is stored in your R environment as an object with this name, and you use the name to call it Argument(s) − Optional; input values that the function performs operations on Body − The code that describes what the function does Return − Optional; a return statement allows the function to return a value to the user. Without a return statement, you won’t be able to access the function’s output Here’s an example function that takes in three parameters for running rbinom, and returns the output of rbinom. binom_sim &lt;- function(myN, mySize, myProb) { output &lt;- rbinom(myN, mySize, myProb) return(output) } How do I know when to use a function? Functions are useful whenever you have code that you want to run multiple times with slightly different parameters. If you find yourself copying over code several times and changing just a few things, you should consider writing a function instead. "],["creating-a-wright-fisher-function.html", "5.18 Creating a Wright-Fisher function", " 5.18 Creating a Wright-Fisher function We want our function to take in parameters for the starting allele frequency, population size, and number of generations to simulate. It should return the sim_results dataframe so that we can plot the allele frequency trajectory. To write a function, we can put the code that we just wrote into the function body: run_sim &lt;- function(Ne, freq, generations) { # note how we don&#39;t define our initial parameters for Ne, freq, etc. # because we&#39;re passing in those parameters as arguments freq_vector &lt;- freq for (i in 1:generations) { new_freq &lt;- rbinom(n = 1, size = Ne, prob = freq) / Ne freq_vector &lt;- c(freq_vector, new_freq) freq &lt;- new_freq } # convert vector of AFs into a tibble for plotting sim_results &lt;- tibble(afs = freq_vector, gen = 1:(generations+1)) # return the tibble of AFs, so that we can access the results return(sim_results) } "],["running-a-function.html", "5.19 Running a function", " 5.19 Running a function The code block we just wrote defines the function (i.e., tells R what it should do). Now we can run the function with parameters of our choosing and plot the output: # run function results &lt;- run_sim(Ne = 1000, freq = 0.5, generations = 10000) # plot output ggplot(data = results, aes(x = gen, y = afs)) + geom_line() Run your run_sim function a few times with different input population sizes and AFs. How does changing these inputs affect the AF trajectories that you see? # simulate a very large population results &lt;- run_sim(Ne = 100000, freq = 0.5, generations = 1000) # plot output ggplot(data = results, aes(x = gen, y = afs)) + geom_line() # simulate a population with AF closer to 0 results &lt;- run_sim(Ne = 1000, freq = 0.1, generations = 1000) # plot output ggplot(data = results, aes(x = gen, y = afs)) + geom_line() In general, decreasing the population size or shifting the starting AF away from 0.5 will decrease the time to fixation for an allele. "],["conclusion-3.html", "5.20 Conclusion", " 5.20 Conclusion In this lab, we built a Wright-Fisher simulation for one allele, allowing us to track how we expect its frequency to change over time under the principles of genetic drift. Within each simulated generation, we drew the number of allele carriers in the next generation from a binomial distribution. We performed these AF draws within a for loop, allowing us to update the current AF with each new generation. Finally, we wrapped our Wright-Fisher simulation code into a function, allowing us to easily re-run our simulation with different parameters for the starting AF, population size, and number of generations to simulate for. We observed that smaller population sizes and more extreme AFs (closer to 0 or 1) generally decrease an allele’s time to fixation. This simple simulation forms the core of most models used in evolutionary genetics research, which often extend this model to simulate more complex phenomena (such as different forms of selection). "],["homework-3.html", "5.21 Homework", " 5.21 Homework One way to extend our simple Wright-Fisher model is to add in selection as a parameter. Selection affects our model by altering the probability of sampling our allele of interest each generation (e.g., positive selection increases the probability, and negative selection decreases it). Previously, we assumed that this probability was equivalent to the allele’s frequency, or \\(p = \\frac{i}{N_e}\\), where \\(N_e\\) is the population size and \\(i\\) is the number of individuals who carry the allele. For the purposes of this homework, we assume that in a model with selection, this probability is instead: \\[ p = \\frac{i(1 + s)}{N_e - i + i(1+s)} \\] where \\(s\\) is the selection coefficient, and ranges from -1 to 1. What does this probability become in the absence of selection (i.e., when \\(s = 0\\))? The probability becomes \\(\\frac{i}{N_e}\\), which is the same as the allele frequency. 5.21.0.1 Learning Objectives Practice writing functions in R Interpret allele frequency trajectories under selection and drift 5.21.0.2 Assignment In the code block below, modify your run_sim function so that it takes in a selection coefficient s as a parameter. Run the simulation a few times with and without (s = 0) selection, but keeping other parameters the same (Ne = 10000, freq = 0.5, generations = 10000). What do you notice about the allele frequency trajectories? Note that most selection coefficients are thought to be extremely small – the largest known selection coefficients in humans are around 0.05. Solution # simulation function with selection run_sim_selection &lt;- function(Ne, freq, generations, s) { freq_vector &lt;- freq for (i in 1:generations) { # calculate p, the probability of sampling the allele, based on s i &lt;- freq * Ne # number of individuals who currently carry the allele p &lt;- i*(1+s) / (Ne - i + i*(1+s)) # prob is now `p`, rather than `freq` new_freq &lt;- rbinom(n = 1, size = Ne, prob = p) / Ne freq_vector &lt;- c(freq_vector, new_freq) freq &lt;- new_freq } # convert vector of AFs into a tibble for plotting sim_results &lt;- tibble(afs = freq_vector, gen = 1:(generations+1)) # return the tibble of AFs, so that we can access the results return(sim_results) } Run and plot the simulation with selection: results &lt;- run_sim_selection(Ne = 10000, freq = 0.5, generations = 10000, s = -0.001) ggplot() + geom_line(data = results, aes(x = gen, y = afs)) + ylim(0, 1) + ylab(&quot;Allele frequency&quot;) + xlab(&quot;Generation&quot;) + ggtitle(&quot;Simulation with selection&quot;) + theme(plot.title = element_text(hjust = 0.5)) # to center the title Run and plot the simulation without selection: results &lt;- run_sim_selection(Ne = 10000, freq = 0.5, generations = 10000, s = 0) ggplot() + geom_line(data = results, aes(x = gen, y = afs)) + ylim(0, 1) + ylab(&quot;Allele frequency&quot;) + xlab(&quot;Generation&quot;) + ggtitle(&quot;Simulation without selection&quot;) + theme(plot.title = element_text(hjust = 0.5)) # to center the title We observe that selection tends to decrease the time it takes for an allele to either fix or go extinct, because it directionally biases the probability of sampling that allele. Decreasing the absolute value of the selection coefficient will make the simulation behave more like drift. "],["population-structure.html", "6 Population structure", " 6 Population structure In this lab, we’ll perform principal component analysis (PCA) to visualize how genetic variation segregates between populations. 6.0.0.1 Learning objectives After completing this chapter, you’ll be able to: Describe the data stored in a Variant Call Format (VCF) file. Plot and interpret an allele frequency spectrum. Perform and visualize the results of a principal component analysis. "],["what-is-a-population.html", "6.1 What is a population?", " 6.1 What is a population? In population genetics, the term population refers to a group of interbreeding individuals. Determining whether a group of individuals is a “population” is subjective. Groups exchange migrants at different rates (a process called gene flow), and there is no definitive boundary for when they constitute separate populations. "],["population-structure-1.html", "6.2 Population structure", " 6.2 Population structure Population structure is a consequence of the fact that when two groups of individuals do not freely interbreed, the two populations typically develop different patterns of genetic variation. Individuals within a population tend to be share greater genetic similarity with each other than with individuals in other populations. These differences manifest through differences in allele frequencies among populations, and result from genetic drift, natural selection, and other evolutionary forces. We can measure such allele frequency differences to reveal evolutionary relationships among populations, as well as evidence of historical natural selection. Fig. 1. Two populations polymorphic for alleles A and a. The frequency of A in Population 1 is \\(0.83\\), while its frequency in Population 2 is \\(0.15\\). "],["geography-of-genetic-variants.html", "6.3 Geography of Genetic Variants", " 6.3 Geography of Genetic Variants One quick way to visualize population structure in humans is to look at the allele frequencies of genetic variants in different regions of the world. The Geography of Genetic Variants (GGV) browser is a website that plots allele frequencies from the 1000 Genomes dataset. For a given variant, GGV plots piecharts of its frequency in the 26 populations in 1000 Genomes, superimposed over the population’s geographical location. While some variants have very similar frequencies across populations, others are much more common in specific populations – usually suggesting that these populations are more closely related to each other. Fig. 2. GGV visualization of the allele frequencies for a SNP at chr1:222087833. "],["setup-3.html", "6.4 Setup", " 6.4 Setup We’ll use the 1000 Genomes data to visualize genetic differentiation between its populations. 6.4.1 R packages library(tidyverse) "],["genotype-data.html", "6.5 Genotype data", " 6.5 Genotype data We’ve summarized genotype data from the 1000 Genomes Project into two files: all_variants.txt.gz, which contains a random selection of variants on chr21 common_variants.txt, which contains only those variants in all_variants that are common across populations # all variants all &lt;- read.table(&quot;all_variants.txt.gz&quot;) # only common variants common &lt;- read.table(&quot;common_variants.txt.gz&quot;) # preview first 10 columns of `all` dataframe head(all[, 1:10]) ## AF AFR_AF AMR_AF EAS_AF EUR_AF SAS_AF HG00096 HG00097 HG00099 ## chr21_10005999 0.02 0.06 0.00 0 0.00 0.00 0 0 0 ## chr21_10325486 0.02 0.00 0.01 0 0.03 0.04 0 0 0 ## chr21_10336823 0.00 0.00 0.00 0 0.00 0.00 0 0 0 ## chr21_10337236 0.00 0.00 0.00 0 0.00 0.00 0 0 0 ## chr21_10339129 0.00 0.00 0.00 0 0.00 0.00 0 0 0 ## chr21_10339141 0.00 0.00 0.00 0 0.00 0.00 0 0 0 ## HG00100 ## chr21_10005999 0 ## chr21_10325486 0 ## chr21_10336823 0 ## chr21_10337236 0 ## chr21_10339129 0 ## chr21_10339141 0 The index of the dataframe is the variant ID. * The first column (AF) contains the variant’s allele frequency (AF) dataset-wide. * The next five columns contain the variant’s AF in each of the five 1000 Genomes superpopulations. * The rest of the columns provide variant genotypes for each individual in 1000 Genomes, where: * 0 is homozygous reference * 1 is heterozygous * 2 is homozygous for variant "],["metadata.html", "6.6 Metadata", " 6.6 Metadata We’ll also read in a metadata file, which tells us which population each individual is from. metadata &lt;- read.table(&quot;integrated_call_samples.txt&quot;, header = TRUE) head(metadata) ## sample pop superpop sex ## 1 HG00096 GBR EUR male ## 2 HG00097 GBR EUR female ## 3 HG00099 GBR EUR female ## 4 HG00100 GBR EUR female ## 5 HG00101 GBR EUR male ## 6 HG00102 GBR EUR female "],["the-allele-frequency-spectrum.html", "6.7 The allele frequency spectrum", " 6.7 The allele frequency spectrum One common visualization of genotype data is the allele frequency spectrum (AFS), which is the distribution of the allele frequencies of the variants. Plot the AFS of all variants, using the data in the AF column. ggplot(data = all, aes(x = AF)) + geom_histogram(bins = 100) Interpreting the AFS The allele frequencies in this dataset range from 0 to 1, with an exponential decay from zero, indicating that the majority of variants are rare. This is the expected shape of an AFS, since all variants arise in one individual and are unlikely to spread widely through the population just by chance. This distribution is exacerbated in human populations, where recent population expansions have resulted in an excess of rare variation. "],["theoretical-afs.html", "6.8 Theoretical AFS", " 6.8 Theoretical AFS Population geneticists have estimated that under neutral demographic expectations, each bin of the AFS should have a height that is equal to 1 over its bin number. We can use this to plot the expected AFS: # make dataframe with theoretical AFS bins # create `af_bin` column with the bin number ideal_pop &lt;- tibble(af_bin = 1:100) %&gt;% # create `prop` column with the expected proportion of variants mutate(., prop = 1 / af_bin) head(ideal_pop) ## # A tibble: 6 × 2 ## af_bin prop ## &lt;int&gt; &lt;dbl&gt; ## 1 1 1 ## 2 2 0.5 ## 3 3 0.333 ## 4 4 0.25 ## 5 5 0.2 ## 6 6 0.167 # plot expected AFS ggplot(ideal_pop, aes(x = af_bin, y = prop)) + geom_bar(stat = &quot;identity&quot;) How does this compare to the AFS we see from human data? The human AFS has many more rare variants, which manifests as a higher peak on the left side of the AFS. This is due to recent population expansion in humans, which results in more human individuals and an accumulation of excess new rare variation. How would you expect the AFS to look for a contracting population (ex: endangered species)? A contracting population would result in the extinction of many alleles, resulting in more variants that drift to high frequency or go extinct. The AFS for this type of population would look more flat than the neutral expectation (fewer rare alleles, more common ones). "],["af-correlations-between-populations.html", "6.9 AF correlations between populations", " 6.9 AF correlations between populations What if we compare AFs between populations? Do we expect the same variant to have the same AFs in, for example, Africa and Europe? Plot African vs. European AF on a scatterplot. ggplot(all, aes(x = AFR_AF, y = EUR_AF)) + geom_point() Most of the variants lie near the x = y line, showing that there’s a lot of correlated AFs between African and European populations. This is due to these populations’ recent common ancestry. Outlier variants, with very different frequencies in different populations, may have reached these different AFs due to the effects of selection – which we’ll discuss in a later module. Plot AF correlations for some other population pairs. Do you notice any differences in the distributions? # east asian vs. european ggplot(all, aes(x = EAS_AF, y = EUR_AF)) + geom_point() # east asian vs. south asian ggplot(all, aes(x = EAS_AF, y = SAS_AF)) + geom_point() There’s less spread away from the y = x line for the EAS-SAS comparison. Because these populations share a common ancestor more recently than EAS-AFR, there has been less time for drift to change AFs between the populations. "],["common-variation.html", "6.10 Common variation", " 6.10 Common variation For the rest of this lab, we’ll use the common dataframe, which includes only variants where \\(0.05 &lt; \\textrm{AF} &lt; 0.95\\). We can look at where this set of common variants lies on the full AFS by adding vertical lines at the cutoff allele frequencies: ggplot(data = all, aes(x = AF)) + geom_histogram(bins = 100) + geom_vline(xintercept = 0.05, linetype = &quot;dashed&quot;, color = &quot;blue&quot;) + geom_vline(xintercept = 0.95, linetype = &quot;dashed&quot;, color = &quot;brown&quot;) Plot the AFS of the common dataframe, including the dashed lines we used above. ggplot(data = common, aes(x = AF)) + geom_histogram() + geom_vline(xintercept = 0.05, linetype = &quot;dashed&quot;, color = &quot;blue&quot;) + geom_vline(xintercept = 0.95, linetype = &quot;dashed&quot;, color = &quot;brown&quot;) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. All of these variants lie within the dashed lines. Even with just common variation, we still observe an exponential decay of the allele frequencies. Also note that there are only 960 variants in the common dataframe – substantially less than the 10,000 in the all dataframe. Why only work with common variants? Rare variants are more likely to show fine-grained population structure – for example, a variant may be carried by just one individual, or just one family. Because there are so many rare variants, including them causes differences between individuals to be more pronounced than differences between populations. While this is a biologically true statement, it makes it harder to visualize population structure, which is why we subset to common variation for PCA. "],["principal-component-analysis.html", "6.11 Principal component analysis", " 6.11 Principal component analysis Principal component analysis (PCA) is a method for representing high-dimensional data (i.e., data with many variables) within a smaller number of dimensions. In our case, every individual in the VCF has genotype measurements for hundreds of variants. You can think of PCA as a projection all the individuals in our dataset into a cloud, where their position is determined by their combination of genotypes. The first principal component (PC) is the vector through the cloud of data points that captures the greatest possible variance. The second PC is the vector that captures the second greatest possible variance, and must also be perpendicular to the first vector. The same idea applies to the third, fourth, fifth, etc. PCs. Fig. 3. A PCA plot that simplifies three-dimensional data into two dimensions. For an in-depth visual walkthrough of PCA, you can go to this website. "],["reformatting-data-for-pca.html", "6.12 Reformatting data for PCA", " 6.12 Reformatting data for PCA We’re using R’s prcomp function to perform PCA on our genotype data. This function takes a matrix where the rows are the data objects (i.e., individuals) and the columns are the associated measurements (i.e., variants). First, run the code below to subset our data to just the genotypes: # subset to just genotype columns gt_matrix &lt;- common[, 7:2510] %&gt;% as.matrix() # view first 10 columns of matrix head(gt_matrix[, 1:10]) ## HG00096 HG00097 HG00099 HG00100 HG00101 HG00102 HG00103 HG00104 ## chr21_10467583 0 0 1 0 0 1 0 0 ## chr21_10605468 1 0 0 0 1 0 0 0 ## chr21_10616824 1 0 0 0 1 0 0 0 ## chr21_10666513 0 0 0 0 0 0 0 0 ## chr21_10700275 0 0 0 0 0 0 0 0 ## chr21_10728655 1 0 0 0 0 0 0 0 ## HG00105 HG00106 ## chr21_10467583 1 0 ## chr21_10605468 0 0 ## chr21_10616824 0 0 ## chr21_10666513 0 0 ## chr21_10700275 1 0 ## chr21_10728655 0 0 We then transpose the matrix with prcomp’s t function so that the rows are individuals and the columns are variants: # transpose (i.e., rotate) gt_matrix_T &lt;- t(gt_matrix) # view first 10 columns of transposed matrix head(gt_matrix_T[, 1:10]) ## chr21_10467583 chr21_10605468 chr21_10616824 chr21_10666513 ## HG00096 0 1 1 0 ## HG00097 0 0 0 0 ## HG00099 1 0 0 0 ## HG00100 0 0 0 0 ## HG00101 0 1 1 0 ## HG00102 1 0 0 0 ## chr21_10700275 chr21_10728655 chr21_10732526 chr21_12976114 ## HG00096 0 1 0 0 ## HG00097 0 0 0 0 ## HG00099 0 0 0 0 ## HG00100 0 0 0 0 ## HG00101 0 0 1 0 ## HG00102 0 0 0 0 ## chr21_12977074 chr21_13065545 ## HG00096 0 0 ## HG00097 0 0 ## HG00099 0 0 ## HG00100 0 0 ## HG00101 0 0 ## HG00102 0 0 "],["performing-pca.html", "6.13 Performing PCA", " 6.13 Performing PCA We perform PCA on our genotype matrix with prcomp. pca &lt;- prcomp(gt_matrix_T) Our output is a prcomp object. This object comprises several tables, which you can preview by typing pca$ into the console and seeing what R suggests: sdev: standard deviations of the principle components rotation, center, scale: tables we won’t use in this lab x: coordinates of the data objects (the 1000 Genomes individuals) on each PC "],["reformatting-pca-output.html", "6.14 Reformatting PCA output", " 6.14 Reformatting PCA output We can plot our PCA output using the information in pca$x. # extract `x` table x &lt;- pca$x # preview first 10 columns head(x[, 1:10]) Every row of x is an individual, every column is a PC (going up to 960 PCs!), and the value in each cell represents the sample’s coordinate on each PC axis. Run the code below to create a dataframe of the first three PCs to plot: # create column of sample names pca_results &lt;- data.frame(sample = rownames(x), PC1 = x[, 1], # PC1 values PC2 = x[, 2], # PC2 values PC3 = x[, 3]) # PC3 values head(pca_results) ## sample PC1 PC2 PC3 ## HG00096 HG00096 3.060014 -5.822356 -1.2683268 ## HG00097 HG00097 2.839200 -6.278675 0.8609691 ## HG00099 HG00099 1.803619 -5.171999 0.4033319 ## HG00100 HG00100 3.160473 -4.504760 1.8926507 ## HG00101 HG00101 4.035908 -4.545304 0.9407191 ## HG00102 HG00102 3.608347 -4.668695 0.7327117 "],["annotate-with-population-labels.html", "6.15 Annotate with population labels", " 6.15 Annotate with population labels Our last step is adding a column to our PCA dataframe with information about each individual’s population. To do this, we merge pca_results with our metadata table. The merge function combines two tables, merging them by matching a column of your choice (specified with by =). # merge pca_results and metadata pca_results &lt;- merge(pca_results, metadata, # specify columns to merge on by.x = &quot;sample&quot;, by.y = &quot;sample&quot;) head(pca_results) ## sample PC1 PC2 PC3 pop superpop sex ## 1 HG00096 3.060014 -5.822356 -1.2683268 GBR EUR male ## 2 HG00097 2.839200 -6.278675 0.8609691 GBR EUR female ## 3 HG00099 1.803619 -5.171999 0.4033319 GBR EUR female ## 4 HG00100 3.160473 -4.504760 1.8926507 GBR EUR female ## 5 HG00101 4.035908 -4.545304 0.9407191 GBR EUR male ## 6 HG00102 3.608347 -4.668695 0.7327117 GBR EUR female "],["pca-plot.html", "6.16 PCA plot", " 6.16 PCA plot Create a scatterplot of PC1 vs. PC2, coloring by the superpop column. ggplot(data = pca_results, aes(x = PC1, y = PC2, color = superpop)) + geom_point() PC1 separates out the African populations from other populations. This is in line with our knowledge that all non-African populations descend from historical migrations out of Africa – African populations contain significant genetic diversity that is not represented outside of Africa. PC2 seems to separate the East Asian and European populations from the other three superpopulations. Repeat the plot with PC2 vs. PC3. Which superpopulations do you observe separating on PC3? ggplot(data = pca_results, aes(x = PC2, y = PC3, color = superpop)) + geom_point() PC3 separates out the Admixed American and South Asian populations, which were collapsed into one group in the first PCA plot. "],["proportion-of-variance-explained.html", "6.17 Proportion of variance explained", " 6.17 Proportion of variance explained It’s hard to tell from the PCA plot whether the separation of populations we see is meaningful, or if the plot is just exaggerating extremely minor differences between groups. We quantify this by calculating the proportion of variance explained for each PC. This tells us how much of the variation in our data is being captured by PC1, PC2, etc. Variance is the square of the standard deviation, so we can calculate proportion of variance explained from the sdev item in our pca object. Each value corresponds to the standard deviation for one PC. sd &lt;- pca$sdev head(sd) ## [1] 5.692102 3.818282 2.122236 1.954976 1.476041 1.450018 The proportion of variance explained by a PC is its variance, divided by the sum of the variances across all PCs. Conveniently, you can calculate this for every PC at once in R: # divide variance of each PC by sum of all variances var_explained &lt;- sd^2 / sum(sd^2) # proportion of variance explained for: var_explained[1] # PC1 ## [1] 0.09645901 var_explained[2] # PC2 ## [1] 0.04340437 var_explained[3] # PC3 ## [1] 0.01340864 So, PC1 explains only 9.65% of the variance in our data, PC2 explains 4.34%, and PC3 explains 1.34%. Add x and y axis labels to your plots with the proportion of variance explained by each PC. This is common practice for PCA. ggplot(data = pca_results, aes(x = PC1, y = PC2, color = superpop)) + geom_point() + xlab(&quot;PC1 (9.65%)&quot;) + ylab(&quot;PC2 (4.34%)&quot;) ggplot(data = pca_results, aes(x = PC2, y = PC3, color = superpop)) + geom_point() + xlab(&quot;PC2 (4.34%)&quot;) + ylab(&quot;PC3 (1.34%)&quot;) "],["conclusion-4.html", "6.18 Conclusion", " 6.18 Conclusion In this lab, we used genotype data from the 1000 Genomes Project to calculate two measures of population structure. We explored the Geography of Genetic Variants browser, a useful resource for visualizing allele frequency differences between human populations. Using genotype data from the 1000 Genomes Project, we plotted the allele frequency spectrum of variants in human populations. We saw that humans carry an excess of rare variation due to recent population expansion. Finally, we used principal component analysis to cluster individuals in our dataset by their genotype information. Plotting individuals in PCA space allowed us to distinguish the five superpopulations of 1000 Genomes. "],["homework-4.html", "6.19 Homework", " 6.19 Homework We’ll now perform PCA using all SNPs in the initial VCF – not just those that were common in 1000 Genomes individuals. In the optional homework, you’ll also use your newly generated PCA plot to predict the ancestry of an unknown sample. 6.19.0.1 Learning Objectives Perform and interpret the results of a PCA Become familiar with understanding and reusing code "],["required-homework-1.html", "6.20 Required homework", " 6.20 Required homework Assignment: Re-run the steps we used to generate our PCA plot, this time using the all dataframe. Do these plots look any different from our plots with just common variants? Solution # extract genotypes and convert to matrix gt_matrix_all &lt;- all[, 7:2510] %&gt;% as.matrix() # transpose gt_matrix_T_all &lt;- t(gt_matrix_all) # perform PCA pca_all &lt;- prcomp(gt_matrix_T_all) # extract coordinates from PCA object x_all &lt;- pca_all$x # create dataframe for plotting pca_results_all &lt;- data.frame(sample = rownames(x_all), PC1 = x_all[, 1], PC2 = x_all[, 2], PC3 = x_all[, 3]) # merge with metadata pca_results_all &lt;- merge(pca_results_all, metadata, # specify columns to merge on by.x = &quot;sample&quot;, by.y = &quot;sample&quot;) # calculate variance explained by each PC var_explained_all &lt;- pca_all$sdev^2 / sum(pca_all$sdev^2) # print for PC1-PC3 var_explained_all[1:3] ## [1] 0.09154081 0.03824824 0.01207284 # PC1 vs. PC2 plot ggplot(data = pca_results_all, aes(x = PC1, y = PC2, color = superpop)) + geom_point() + xlab(&quot;PC1 (9.15%)&quot;) + ylab(&quot;PC2 (3.82%)&quot;) # PC2 vs. PC3 plot ggplot(data = pca_results_all, aes(x = PC2, y = PC3, color = superpop)) + geom_point() + xlab(&quot;PC2 (3.82%)&quot;) + ylab(&quot;PC3 (1.21%)&quot;) The PCA plots actually look pretty similar to the plots with just common variants! "],["optional-homework-1.html", "6.21 Optional homework", " 6.21 Optional homework We can think of our PCA as a model of human individuals. If we have a mystery individual but we know their genotypes for the variants in our PCA, we can predict where they should lie in PCA space and thus guess their ancestry. We’ve prepared a file, unknown.txt, which contains genotypes for one mystery sample (NA21121). We’ll compare it to the PCA model that you created for the required homework. Follow the instructions to predict NA21121’s placement on your PCA plot. 6.21.0.1 Prepare unknown sample for PCA Assignment: Read in unknown.txt, convert it to a matrix, and transpose. Solution # read VCF unknown &lt;- read.table(&quot;unknown.txt&quot;) %&gt;% as.matrix() # transpose matrix unknown_T &lt;- t(unknown) 6.21.0.2 Predict PCA placement of unknown sample Assignment: Run the code block below to predict and plot NA21121 on top of your PCA plot from the required homework. If necessary, plot PC2 vs. PC3 as well. What superpopulation do you think NA21121 is from? Solution # predict pca placement of unknown data unknown_pca &lt;- predict(pca_all, unknown_T) # create dataframe from predicted PCA unknown_results &lt;- data.frame(&quot;PC1&quot; = unknown_pca[, &quot;PC1&quot;], &quot;PC2&quot; = unknown_pca[, &quot;PC2&quot;], &quot;PC3&quot; = unknown_pca[, &quot;PC3&quot;], &quot;sample&quot; = &quot;NA21121&quot;) # plot PC1 vs. PC2 and then predicted sample ggplot() + # PCA plot from required homework geom_point(data = pca_results_all, aes(x = PC1, y = PC2, color = superpop)) + # plots the unknown sample&#39;s location on the PCs geom_label(data = unknown_results, aes(x = PC1, y = PC2, label = sample)) + xlab(&quot;PC1 (9.15%)&quot;) + ylab(&quot;PC2 (3.82%)&quot;) # plot PC2 vs. PC3 ggplot() + geom_point(data = pca_results_all, aes(x = PC2, y = PC3, color = superpop)) + geom_label(data = unknown_results, aes(x = PC2, y = PC3, label = sample)) + xlab(&quot;PC2 (3.82%)&quot;) + ylab(&quot;PC3 (1.21%)&quot;) NA21121 seems to be part of the SAS (South Asian) superpopulation. If we look up the sample ID in the 1000 Genomes database, we can confirm that it’s part of the Gujarati Indians in Houston, TX. "],["genome-wide-association-studies-i.html", "7 Genome-wide association studies I", " 7 Genome-wide association studies I In this lab, we’ll introduce and discuss the limitations of genome-wide association studies (GWAS). 7.0.0.1 Learning objectives After completing this chapter, you’ll be able to: Explain the statistical method that underlies GWAS. Describe the statistical challenges of GWAS. Understand how linkage disequilibrium helps and hinders GWAS. Interpret common GWAS plots and summary statistics. "],["association-studies.html", "7.1 Association studies", " 7.1 Association studies One of the central goals of human genetics is understanding the relationship between genotype and phenotype. Genome-wide association studies (GWAS) emerged ~20 years ago as a useful approach for discovering genetic variation that underlies variation in human traits. To conduct GWAS, you: Go through every variant in the genome Ask if its allele frequency differs between individuals who have or don’t have a phenotype of interest For most variants (Fig. 1, SNP 1), there will be very little difference Identify the variants with the largest association between genotype and phenotype (Fig. 1, SNP 2) Fig. 1. In this GWAS cohort, SNP 2 is significantly associated with the phenotype. The phenotype can be any measurable trait, whether it’s binary (ex: if someone has a disease) or continuous (ex: height). "],["gwas-is-just-linear-regression.html", "7.2 GWAS is just linear regression", " 7.2 GWAS is just linear regression At their core, GWAS involve fitting linear models to test for relationships between variants and phenotypes using data from large samples of individuals. As with the linear models we covered in the DNM module, GWAS fits a line to a set of points. In this case, each point is one individual in the dataset, stratified by their genotype for a variant of interest. Fig. 2 (source). GWAS fits a linear model for every variant, where the x axis is genotype and the y axis is a phenotype. Because there are so many variants in the genome and we perform a separate statistical test for each one, we often end up fitting millions of linear models for a GWAS. "],["multiple-testing.html", "7.3 Multiple testing", " 7.3 Multiple testing What are statistical challenges of performing a test multiple times? When we perform any test multiple times, we increase the risk that a “significant” result is only significant by chance. Under the null hypothesis, we assume that p-values follow a uniform distribution (i.e., a flat distribution from 0 to 1). We can plot this null distribution in R: # generate 1,000,000 &quot;p-values&quot; from a uniform distribution pvalues &lt;- runif(1000000) # histogram with R&#39;s base plotting function hist(pvalues) If we use the typical p-value threshold of \\(0.05\\), 5% of our tests will have \\(p &lt; 0.05\\), even though these p-values were simulated from a null distribution (i.e., no real association). How do we correct for multiple testing? One common multiple testing correction method, Bonferroni correction, sets a stricter p-value threshold. With Bonferroni, you divide your desired p-value by the number of independent tests you conducted. Are GWAS tests (variants) statistically independent? How does this affect our p-value threshold? As we learned in the LD module, the genotypes of nearby variants are correlated. This non-independence means that we can be less strict with multiple testing correction, because we aren’t performing as many independent tests as we think we are. Researchers have calculated that \\(\\mathbf{5*10^{-8}}\\) is an appropriate p-value threshold for GWAS in humans, given the amount of LD in human genomes. "],["ld-and-gwas.html", "7.4 LD and GWAS", " 7.4 LD and GWAS LD is both a blessing and a curse for GWAS. On one hand, LD means that we need not genotype every SNP to discover associations. We merely need to genotype “tag SNPs”, which are in LD with variants that causally influence the phenotype. On the other hand, this also means that even when we find a signficant association, it is often challenging to disentangle the causal gene and/or variant that drives the association from all the other variants on the same haplotype. Fig. 3 (source). Even without finding the causal variant, we can still discover the causal haplotype through genotyping variants in LD . "],["imputation.html", "7.5 Imputation", " 7.5 Imputation LD also means that we can perform imputation to improve our GWAS discovery power. If we know which variants tend to occur together on the same haplotype, we can infer the presence of variants in an individual even if those SNPs were never sequenced. In imputation, you: Genotype individuals using the sequencing data you have (Fig. 4A) Use a reference panel of haplotypes to fill in variants you didn’t genotype (Fig. 4B) Perform GWAS Imputation can discover GWAS signals that were hidden in the original variant set (Fig. 4B vs. Fig. 4F), or further support signals you already found. Fig. 4 (source). Imputing variants that were not actually sequenced. "],["qq-plots.html", "7.6 QQ plots", " 7.6 QQ plots One common visualization for GWAS results is a QQ plot, which compares the distribution of p-values in our results to a null distribution (i.e., the uniform distribution that we plotted earlier). How do you make a QQ plot? Generate simulated p-values from a uniform distribution – the number of simulated p-values should equal the number of actual p-values Sort both your real and simulated p-values in descending order Plot the first, second, third, etc. p-values, where x-axis is the simulated value y-axis is the actual value Fig. 5 (source). QQ plots visualize the distriution of p-values compared to a null distribution. There are three areas of this plot where points can fall: On the \\(\\mathbf{x = y}\\) line: No association signal Above the \\(\\mathbf{x = y}\\) line: Some association signal Below the \\(\\mathbf{x = y}\\) line: Issue with our statistical test (ex: not appropriately adjusting for covariates) "],["manhattan-plots.html", "7.7 Manhattan plots", " 7.7 Manhattan plots Manhattan plots show the distribution of GWAS hits across the genome, where the y-axis is p-value. &lt;/br. Fig. 6. Manhattan plot of GWAS results. The red line is the \\(5*10^{-8}\\) genome-wide significance threshold. Why are there peaks in the Manhattan plot? Each peak is composed of variants from the same haplotype, which all have a strong association with the phenotype because of LD. "],["sample-size.html", "7.8 Sample size", " 7.8 Sample size As GWAS sample size has increased over the years, each larger study is able to discover more variants. Fig. 7 (source). Increase in GWAS discovery power with sample size. Why do we find more associations with larger studies? A larger dataset captures more rare variation A larger dataset provides more statistical power – we can more confidently say whether allele frequencies are different between individuals with and without a phenotype "],["interpreting-gwas-results.html", "7.9 Interpreting GWAS results", " 7.9 Interpreting GWAS results Let’s look at a browser of GWAS results, generated by a study that used genotype and phenotype data from the UK Biobank. UK Biobank UK Biobank is one of the largest cohorts of genotype and phenotype data available. This study has data from ~500,000 individuals across the UK, including health records and responses to surveys, all of which are publicly available for research. As an example, let’s look up associations with standing height. Fig. 8. GWAS results for standing height. For each phenotype, the browser shows a Manhattan plot of associated variants The top p-values for this trait look extremely significant Bottom of the page also has a QQ plot Although these p-values are huge, keep in mind that for the vast majority of extremely strong associations, the total proportion of variance explained is very small (&lt; 10%). (i.e., most of the natural variation in the phenotype is not explained by that variant.) "],["conclusion-5.html", "7.10 Conclusion", " 7.10 Conclusion In this lab, we gave a conceptual overview of genome-wide association studies. GWAS are an attempt to answer one of the oldest questions in genetics: How does genotype impact phenotype? In GWAS, you go through every variant in the genome and fit a linear model to ask if genotype at that variant is associated with a phenotype of interest. Multiple testing correction accounts for the statistical burden of these tests. Linkage disequilibrium helps us discover more GWAS hits, but also limits our ability to identify causal variants/genes. QQ plots and Manhattan plots are common visualizations of GWAS results. "],["homework-5.html", "7.11 Homework", " 7.11 Homework 7.11.0.1 Learning Objectives Interpret the summary statistics typically reported in GWAS studies Understand the limitations and biases of GWAS 7.11.0.2 Assignment Find any GWAS paper. Read it and report: Phenotype being studied Sample size Population being studied (homogeneous? Multi-ethnic? If it’s multi-ethnic, how do they correct for the effect of ancestry?) For the top asssociation: p-value (would you call it significant genome wide?) Effect size Did the authors replicate the result in an independent cohort? Haplotype structure, nearby genes, causal variant Example solution Example GWAS: Genome-wide analysis identifies genetic effects on reproductive success and ongoing natural selection at the FADS locus. Phenotype: Number of children ever born Sample size:: 785,604 Population: European; no population structure correction (but did control for family structure) Top asssociation: rs201815280, chr3:85546181, A-&gt;ACACC (from Supp. Table 7) p-value: 5.25e-26, seems genome-wide significant Effect size: 0.0249 (with every copy of the ACACC allele, individuals have one more child born) Replication: Did not replicate in a cohort of 34,367 women from the FinnGen study (p = 0.177) Haplotype structure, nearby genes, causal variant: In an intron of CADM2; no causal variant or LD analysis "],["genome-wide-association-studies-ii.html", "8 Genome-wide association studies II", " 8 Genome-wide association studies II In this lab, we’ll perform a GWAS. The data and exercises for this module were adapted from a GWAS workshop created by Heather Wheeler from Loyola University Chicago. 8.0.0.1 Learning objectives After completing this chapter, you’ll be able to: Perform GWAS of a single SNP using linear regression. Use PLINK to perform GWAS on all SNPs in a VCF. Create and interpret common GWAS visualization plots. "],["setup-4.html", "8.1 Setup", " 8.1 Setup The premise for this exercise is that you’re part of a company developing a cancer drug called . Today, we’ll perform a GWAS on resistance to two drugs (GS451 and CB1908) in 1000 Genomes lymphblastoid cell lines. The phenotype we’re interested in is \\(\\mathbf{IC_{50}}\\), defined as the concentration of the drug at which the cells experience 50% viability. 8.1.1 R packages In addition to tidyverse, we’ll use vcfR to read in genotype data and qqman to create Manhattan and QQ plots. library(tidyverse) library(vcfR) library(qqman) "],["data-2.html", "8.2 Data", " 8.2 Data GWAS requires information on both genotype and phenotype in the same individuals. The genotype data we’re using are real data from the Yoruba population in the 1000 Genomes Project, but the phenotype data is simulated. Why can’t we use real phenotype data? The combination of genotype and phenotype data poses a privacy risk, so real genotype and phenotype data are often stored in controlled-access databases such as dbGaP. Although these data are still available to researchers who want to work with it, access usually requires submitting an application to explain what your intend to do with it. "],["variant-call-format-vcf.html", "8.3 Variant Call Format (VCF)", " 8.3 Variant Call Format (VCF) Our genotype data is stored in a Variant Call Format (VCF) file. VCF files contain genotype data for variants of interest in a genome. Click on genotypes_subset.vcf in the Posit Files pane to view it. This file is a subset of a much larger VCF that we’ll use later to run a genome-wide GWAS. "],["vcf-header.html", "8.4 VCF header", " 8.4 VCF header The first section of a VCF is a multi-line header – marked by the ## character – which contains metadata and descriptions of some of the columns (like INFO and FORMAT). ##fileformat=VCFv4.2 ##fileDate=20200327 ##source=PLINKv1.90 ##contig=&lt;ID=1,length=247169191&gt; ##contig=&lt;ID=2,length=242739671&gt; ##contig=&lt;ID=3,length=199318156&gt; ##contig=&lt;ID=4,length=191166588&gt; ##contig=&lt;ID=5,length=180617248&gt; ##contig=&lt;ID=6,length=170727838&gt; ##contig=&lt;ID=7,length=158798775&gt; ##contig=&lt;ID=8,length=146266471&gt; ##contig=&lt;ID=9,length=140174583&gt; ##contig=&lt;ID=10,length=135279752&gt; ##contig=&lt;ID=11,length=134426071&gt; ##contig=&lt;ID=12,length=132256834&gt; ##contig=&lt;ID=13,length=114114508&gt; ##contig=&lt;ID=14,length=106354055&gt; ##contig=&lt;ID=15,length=100209453&gt; ##contig=&lt;ID=16,length=88670345&gt; ##contig=&lt;ID=17,length=78634628&gt; ##contig=&lt;ID=18,length=76098044&gt; ##contig=&lt;ID=19,length=63771070&gt; ##contig=&lt;ID=20,length=62382908&gt; ##contig=&lt;ID=21,length=46924584&gt; ##contig=&lt;ID=22,length=49503800&gt; ##INFO=&lt;ID=PR,Number=0,Type=Flag,Description=&quot;Provisional reference allele, may not be based on real reference genome&quot;&gt; ##FORMAT=&lt;ID=GT,Number=1,Type=String,Description=&quot;Genotype&quot;&gt; The final line of the header (marked with just one #) gives the names of the data columns. Note that there are over a hundred columns because each individual (1001, 1002, etc.) has their own column. #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 "],["vcf-data.html", "8.5 VCF data", " 8.5 VCF data The data section of a VCF describes genetic variants. The first 9 columns give information about the variant itself – its position, the reference/alternative alleles, etc. The rest of the columns are sample-specific, and contain the individual’s genotype at that variant. 1 558185 rs9699599 A G . . PR GT 0/0 0/0 0/0 0/1 0/0 0/1 ./. 0/0 0/0 0/0 0/1 0/0 0/0 0/0 0/0 0/1 0/0 0/1 0/0 0/0 0/0 0/0 0/0 0/0 0/0 ./. 0/0 0/0 0/0 0/0 0/1 0/0 0/1 0/1 0/0 0/1 ./. 0/1 0/1 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/0 0/1 0/0 0/1 0/0 0/0 0/0 0/1 0/0 0/1 0/0 0/0 0/0 ./. 0/0 0/0 0/0 0/1 0/0 0/1 0/0 0/1 0/0 0/1 0/0 0/0 0/1 0/0 ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. ./. How do you interpret VCF genotypes? 0/0: homozygous reference (does not carry the variant) 0/1 or 1|0: heterozygous 1/1: homozygous alternate (both chromosomes have the variant) ./.: Missing genotype (could not be confidently called) The sample-specific columns often include additional genotype information, like the number of sequencing reads from the individual that support the reference vs. alternative alleles. The included fields are specified column 9 (FORMAT) (which in this case just reads GT, for “genotype”). "],["reading-in-genotype-data.html", "8.6 Reading in genotype data", " 8.6 Reading in genotype data Because VCF format can be hard to work with, we’ll use the vcfR package to manipulate our genotype data. # load the VCF with vcfR vcf &lt;- read.vcfR(&quot;genotypes_subset.vcf&quot;) ## Scanning file to determine attributes. ## File attributes: ## meta lines: 27 ## header_line: 28 ## variant count: 72 ## column count: 185 ## Meta line 27 read in. ## All meta lines processed. ## gt matrix initialized. ## Character matrix gt created. ## Character matrix gt rows: 72 ## Character matrix gt cols: 185 ## skip: 0 ## nrows: 72 ## row_num: 0 ## Processed variant: 72 ## All variants processed "],["tidying-vcf.html", "8.7 Tidying VCF", " 8.7 Tidying VCF We’ll first work with just the first SNP in the dataset, using the vcfR2tidy function to isolate the SNP of interest and extract its genotypes. # extract first SNP, convert to tidy df, and get genotypes test_snp_gt &lt;- vcfR2tidy(vcf[1, ])$gt ## Extracting gt element GT head(test_snp_gt) ## # A tibble: 6 × 5 ## ChromKey POS Indiv gt_GT gt_GT_alleles ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 558185 1001 0/0 A/A ## 2 1 558185 1002 0/0 A/A ## 3 1 558185 1003 0/0 A/A ## 4 1 558185 1004 0/1 A/G ## 5 1 558185 1005 0/0 A/A ## 6 1 558185 1006 0/1 A/G Every row in the test_snp_gt dataframe is a different individual in the VCF. "],["counting-allele-dosage.html", "8.8 Counting allele dosage", " 8.8 Counting allele dosage We’re often interested in encoding genotypes as a 0, 1, or 2, which you can think of as the dosage of the minor allele. This is an additive model, and assumes that the phenotype of the heterozygote is intermediate between those of the two homozygotes. We can use the table function on the gt_GT_alleles column to quickly check how many individuals have each genotype. # tabulate genotype counts table(test_snp_gt$gt_GT_alleles) ## ## A/A A/G ## 66 20 Now we’ll use the mutate function to create a new column of the dataframe that counts the dosage of the minor allele (i.e., how many G’s each person has at that SNP): # convert genotypes to counts (i.e., dosage) of minor allele test_snp_gt &lt;- test_snp_gt %&gt;% # count number of Gs mutate(dosage = str_count(gt_GT_alleles, &quot;G&quot;)) %&gt;% drop_na() head(test_snp_gt) ## # A tibble: 6 × 6 ## ChromKey POS Indiv gt_GT gt_GT_alleles dosage ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 1 558185 1001 0/0 A/A 0 ## 2 1 558185 1002 0/0 A/A 0 ## 3 1 558185 1003 0/0 A/A 0 ## 4 1 558185 1004 0/1 A/G 1 ## 5 1 558185 1005 0/0 A/A 0 ## 6 1 558185 1006 0/1 A/G 1 Checking our work with table If we run table on the dosage column, we should get the same breakdown of genotypes as we got from the gt_GT_alleles columns. # make sure we get the same genotype counts table(test_snp_gt$dosage) ## ## 0 1 ## 66 20 "],["phenotype-data.html", "8.9 Phenotype data", " 8.9 Phenotype data Our phenotype for this GWAS is the \\(\\mathbf{IC_{50}}\\) – the concentration of the GS451 drug that at which we observe 50% viability in cell culture. # read in phenotypes phenotypes &lt;- read.table(&quot;GS451_IC50.txt&quot;, header = TRUE) head(phenotypes) ## FID IID GS451_IC50 ## 1 1001 1001 5.594256 ## 2 1002 1002 8.525633 ## 3 1003 1003 12.736739 ## 4 1004 1004 12.175201 ## 5 1005 1005 9.936742 ## 6 1006 1006 9.163483 The columns of this table are: FID &amp; IID: Family and individual IDs of the individual GS451_IC50: Measured \\(\\mathrm{IC_{50}}\\) for the drug of interest Plot the distribution of the phenotype. ggplot(data = phenotypes, aes(x = GS451_IC50)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 1 row containing non-finite outside the scale range ## (`stat_bin()`). This data looks approximately normally distributed. This is important to check because this is one of the assumptions of linear regression, which we’ll be using to perform the GWAS. "],["merging-genotype-and-phenotype-data.html", "8.10 Merging genotype and phenotype data", " 8.10 Merging genotype and phenotype data To perform a GWAS, we need to combine genotype and phenotype information for the same individuals. This means merging these two data for our SNP of interest, which we do with the merge function: # merge genotype and phenotype info for test SNP gwas_data &lt;- merge(test_snp_gt, phenotypes, by.x = &quot;Indiv&quot;, by.y = &quot;IID&quot;) head(gwas_data) ## Indiv ChromKey POS gt_GT gt_GT_alleles dosage FID GS451_IC50 ## 1 1001 1 558185 0/0 A/A 0 1001 5.594256 ## 2 1002 1 558185 0/0 A/A 0 1002 8.525633 ## 3 1003 1 558185 0/0 A/A 0 1003 12.736739 ## 4 1004 1 558185 0/1 A/G 1 1004 12.175201 ## 5 1005 1 558185 0/0 A/A 0 1005 9.936742 ## 6 1006 1 558185 0/1 A/G 1 1006 9.163483 "],["gwas-for-one-variant.html", "8.11 GWAS for one variant", " 8.11 GWAS for one variant Under the hood, GWAS is just linear regression – simple statistical models to assess evidence of a relationship between two variables. We can perform this linear regression by hand, using data from the first SNP in the VCF. In our model, we’ll be asking whether there’s a relationship between an individual’s genotype (their dosage of the SNP) and phenotype (their \\(\\mathrm{IC_{50}}\\) for GS451). Why did we merge our genotype and phenotype data? When we fit linear models in the DNM module, we needed our variables (age and # of DNMs) to be separate columns of the same table. Similarly, now that our variables are genotype and phenotype, they need to be in the same dataframe. "],["genotype-phenotype-boxplots.html", "8.12 Genotype-phenotype boxplots", " 8.12 Genotype-phenotype boxplots First, let’s plot the relationship between genotype and phenotype to see if it looks interesting. Create boxplots of the phenotype, stratified by genotype of the test SNP. ggplot(data = gwas_data) + geom_boxplot(aes(x = gt_GT_alleles, y = GS451_IC50)) ## Warning: Removed 1 row containing non-finite outside the scale range ## (`stat_boxplot()`). It’s unclear whether there’s a relationship here, because the phenotype distributions for these two genotypes are mostly overlapping. To be certain, we’ll now test this with linear regression. "],["linear-regression.html", "8.13 Linear regression", " 8.13 Linear regression The function to perform linear regression in R is lm(). It takes as arguments a data frame (gwas_data) and a model formula of the form outcome ~ predictors. In the case of GWAS, our outcome is the phenotype, and our predictor is the SNP genotype. We may also include covariates such as sex, age, or ancestry as additional predictors (called covariates) to control for their potential confounding effects. No such data are available here, so we just run the simple genotype vs. phenotype test. # test for association between genotype and phenotype lm(data = gwas_data, formula = GS451_IC50 ~ dosage) %&gt;% # directly pipe (%&gt;%) model results to the `summary()` function summary() ## ## Call: ## lm(formula = GS451_IC50 ~ dosage, data = gwas_data) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.0247 -1.9643 -0.3867 2.1967 6.6201 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.5712 0.3299 19.921 &lt;2e-16 *** ## dosage 1.3846 0.6800 2.036 0.0449 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.659 on 83 degrees of freedom ## (1 observation deleted due to missingness) ## Multiple R-squared: 0.04757, Adjusted R-squared: 0.0361 ## F-statistic: 4.146 on 1 and 83 DF, p-value: 0.04493 How do we interpret the results of the linear model? The coefficient for dosage indicates that on average, each copy of the “G” allele increases \\(\\mathrm{IC_{50}}\\) by \\(1.38\\). The p-value indicates that this slope of \\(1.38\\) is significantly greater than 0 (\\(p = 0.0449\\)). Do you think this SNP would reach genome-wide significance? This p-value is borderline, sitting very close to the arbitrary cutoff of \\(0.05\\) which is generally used to determine statistical significance. If this was the only SNP that we were investigating, we might find this result promising. However, this SNP is just one of hundreds of thousands of SNPs that we will test for association, so the burden of proof will need to be much higher. Recall that the genome-wide significance threshold for GWAS in humans is \\(5 * 10^{-8}\\). "],["gwas-for-multiple-snps.html", "8.14 GWAS for multiple SNPs", " 8.14 GWAS for multiple SNPs A GWAS performs the linear regression we just did, for every SNP in the dataset. We could write a for loop to do this in R ourselves, but it would be slow because there are 256,896 variants in the full VCF. Because GWAS is such a common approach, researchers have developed software to standardize this process and make it extremely efficient. The most popular software package for GWAS is called PLINK, which is preloaded into your Cloud session. PLINK is a “command line” tool, so we could either use it by working from the Terminal tab in Posit Cloud, or using the system() command within R. For this class we’ll use the latter approach. The system() command The command line is a text interface that takes in commands for your computer’s operating system to run. RStudio and Posit Cloud are a more interactive interface for writing code that you’d normally have to run on the command line. The system() command tells RStudio to run a snippet of command line code for you, without you having to leave the R environment. "],["gwas-of-one-snp-with-plink.html", "8.15 GWAS of one SNP with PLINK", " 8.15 GWAS of one SNP with PLINK First, we’ll replicate the GWAS that we did in R with just the first SNP of the VCF, rs9699599. # replicate first SNP association with PLINK system(command = &quot;./plink --file genotypes --linear --allow-no-sex --snp rs9699599 --pheno GS451_IC50.txt --pheno-name GS451_IC50&quot;) Breakdown of the PLINK command ./plink: Use the PLINK software --file genotypes: Genotype data files (genotypes.map, genotypes.ped) begin with the string “genotypes” --linear: Run a linear additive association test for each SNP --allow-no-sex: Include samples we don’t have sex metadata for --snp rs9699599: Only run the analysis for a single SNP (rs9699599) --pheno GS451_IC50.txt: Phenotype data is located in a file called GS451_IC50.txt --pheno-name GS451_IC50: The column heading of the phenotype to use in the phenotype file is GS451_IC50 After running PLINK, we get an output file called plink.assoc.linear. Now look at the output of the plink.assoc.linear output file that PLINK produced. snp1 &lt;- read.table(&quot;plink.assoc.linear&quot;, header = TRUE) head(snp1) ## CHR SNP BP A1 TEST NMISS BETA STAT P ## 1 1 rs9699599 558185 G ADD 85 1.385 2.036 0.04493 How do these results compare to performing the GWAS by hand? Notice that the beta (i.e., the “slope” or coefficient) and p-value perfectly matches the results we obtained previously with R. "],["gwas-of-all-snps-with-plink.html", "8.16 GWAS of all SNPs with PLINK", " 8.16 GWAS of all SNPs with PLINK Now let’s allow PLINK to run the statistical tests for all SNPs by removing the --snp flag. system(command = &quot;./plink --file genotypes --linear --allow-no-sex --pheno GS451_IC50.txt --pheno-name GS451_IC50&quot;) The plink.assoc.linear file should now have ~260,000 lines. Load the file into R to look at the results: results &lt;- read.table(file = &quot;plink.assoc.linear&quot;, header = TRUE) %&gt;% # order table by lowest pvalue arrange(P) head(results) ## CHR SNP BP A1 TEST NMISS BETA STAT P ## 1 19 rs7257475 20372113 T ADD 88 -3.008 -6.876 9.311e-10 ## 2 19 rs10413538 20370690 T ADD 86 -3.026 -6.805 1.395e-09 ## 3 21 rs2826383 20844081 A ADD 166 3.031 5.866 2.392e-08 ## 4 19 rs12972967 20358400 T ADD 89 -2.421 -5.939 5.760e-08 ## 5 2 rs1358578 51626897 A ADD 166 2.111 5.307 3.571e-07 ## 6 17 rs3094508 33137048 C ADD 89 3.532 5.230 1.156e-06 "],["plotting-gwas-results.html", "8.17 Plotting GWAS results", " 8.17 Plotting GWAS results The qq() and manhattan() functions in the qqman package let us easily create QQ and Manhattan plots to visualize our GWAS results. # qq plot using the P (pvalues) column qq(results$P) # manhattan plot manhattan(results) SNPs with low p-values occur in peaks of multiple variants. These are not independent associations, but rather groups of variants in LD. "],["top-gwas-snp.html", "8.18 Top GWAS SNP", " 8.18 Top GWAS SNP One common future direction for GWAS studies is following up on the top SNP(s). Read in top_snp.vcf, a VCF of just the top SNP in the dataset, so that we can plot boxplots of the top SNP genotype stratified by phenotype: # extract genotypes of the top SNP top_snp &lt;- vcfR2tidy(read.vcfR(&quot;top_snp.vcf&quot;)) ## Scanning file to determine attributes. ## File attributes: ## meta lines: 27 ## header_line: 28 ## variant count: 1 ## column count: 185 ## Meta line 27 read in. ## All meta lines processed. ## gt matrix initialized. ## Character matrix gt created. ## Character matrix gt rows: 1 ## Character matrix gt cols: 185 ## skip: 0 ## nrows: 1 ## row_num: 0 ## Processed variant: 1 ## All variants processed ## Extracting gt element GT top_snp_gt &lt;- top_snp$gt %&gt;% drop_na() # merge with phenotype data gwas_data &lt;- merge(top_snp_gt, phenotypes, by.x = &quot;Indiv&quot;, by.y = &quot;IID&quot;) # plot boxplots ggplot(data = gwas_data) + geom_boxplot(aes(x = gt_GT_alleles, y = GS451_IC50)) ## Warning: Removed 1 row containing non-finite outside the scale range ## (`stat_boxplot()`). Other potential follow-up directions include: Investigating the genomic environment in the UCSC Genome Browser Looking at nearby haplotype structure with LDproxy Note that the genotype data we’re using come from the Yoruba population Using the Geography of Genetic Variants browser to find the global allele frequencies of the variant Search for SNP in a phenotype database to see if there are other associations with it "],["conclusion-6.html", "8.19 Conclusion", " 8.19 Conclusion We used genotype and simulated phenotype data from the 1000 Genomes Project to perform a genome-wide association study for variants associated with drug \\(\\mathrm{IC_{50}}\\). Using linear regression, we first did GWAS “by hand” on just one variant in the VCF. We fit a linear model to ask whether there’s a significant relationship between genotype and phenotype. We then used PLINK to perform this test on every SNP in the genome. We followed up on the top SNP from our GWAS by plotting boxplots of phenotype stratified by genotype. "],["homework-6.html", "8.20 Homework", " 8.20 Homework 8.20.0.1 Learning Objectives Interpret results of a GWAS Practice manipulating tabular data 8.20.0.2 Assignment Run a GWAS of \\(\\mathrm{IC_{50}}\\) for the drug CB1908, using the same genotype data as before. The phenotypes are located in CB1908_IC50.txt. Make a QQ plot and a Manhattan plot of your results. Do you have any genome-wide significant hits? Are they located in or near a gene? For the top GWAS hit, plot the phenotype stratified by genotype. (Use top_snp_hw.vcf to get the genotypes of the top hit.) Solution # perform association test with PLINK system(command = &quot;./plink --file genotypes --linear --allow-no-sex --pheno CB1908_IC50.txt --pheno-name CB1908_IC50&quot;) # read in gwas results results &lt;- read.table(file = &quot;plink.assoc.linear&quot;, header = TRUE) %&gt;% mutate(index = row_number()) %&gt;% arrange(P) # qq plot qq(results$P) # manhattan plot manhattan(results) On the Manhattan plot, there’s one hit that reaches genome-wide significance. # view top GWAS hit results[1, ] ## CHR SNP BP A1 TEST NMISS BETA STAT P ## 1 12 rs10876043 49190411 G ADD 161 1.779 7.18 2.518e-11 From looking it up in the UCSC Genome Browser, rs10876043 lies within an intron of the DIP2B gene. Finally, we plot this SNP’s genotype stratified by phenotype, using top_snp_hw.vcf. # extract top SNP and convert to tidy df top_snp &lt;- vcfR2tidy(read.vcfR(&quot;top_snp_hw.vcf&quot;)) ## Scanning file to determine attributes. ## File attributes: ## meta lines: 27 ## header_line: 28 ## variant count: 1 ## column count: 185 ## Meta line 27 read in. ## All meta lines processed. ## gt matrix initialized. ## Character matrix gt created. ## Character matrix gt rows: 1 ## Character matrix gt cols: 185 ## skip: 0 ## nrows: 1 ## row_num: 0 ## Processed variant: 1 ## All variants processed ## Extracting gt element GT # get genotype dataframe top_snp_gt &lt;- top_snp$gt %&gt;% drop_na() # read in phenotype dataframe phenotypes &lt;- read.table(&quot;CB1908_IC50.txt&quot;, header = TRUE) # merge genotype and phenotype info gwas_data &lt;- merge(top_snp_gt, phenotypes, by.x = &quot;Indiv&quot;, by.y = &quot;IID&quot;) # plot genotype by phenotype boxplots ggplot(data = gwas_data) + geom_boxplot(aes(x = gt_GT_alleles, y = CB1908_IC50)) ## Warning: Removed 2 rows containing non-finite outside the scale range ## (`stat_boxplot()`). "],["scans-for-selection.html", "9 Scans for selection", " 9 Scans for selection In this lab, we’ll explore three methods for identifying signatures of selection: FST, population branch statistic (PBS), and extended haplotype homozygosity (EHH). 9.0.0.1 Learning objectives After completing this chapter, you’ll be able to: Describe the genetic signatures of selection and what they reveal about the strength and timing of the selective sweep. Calculate and interpret population differentiation with FST. Understand why PBS provides additional information over two-population tests of selection. Explain how EHH and iHS leverage haplotype information to identify selection. "],["signatures-of-positive-selection.html", "9.1 Signatures of positive selection", " 9.1 Signatures of positive selection A central question in human evolutionary genetics is what genetic adaptations humans acquired as they migrated into diverse environments. Fig. 1 (source). The history of human migrations. The process of evolutionary adaptation leaves characteristic signatures on patterns of population genetic variation. By developing statistics to capture these signatures and applying them to human genetic data, we can uncover evidence of past episodes of positive selection. Statistics for identifying signatures of selection can be broadly classified into two categories: frequency-based and haplotype-based. "],["frequency-based-signatures.html", "9.2 Frequency-based signatures", " 9.2 Frequency-based signatures One signature of selection is an allele whose frequency is either smaller or larger than you would expect. Fig. 2. The allele frequencies of this variant shows large differences between population. How do we determine the expected AF? We can compare AFs between populations. On average, neutrally evolving variants should have similar frequencies across populations. We can enrich for potential targets of selection by asking which variants show the biggest population-specific frequency differences. If a variant shows large AF differences and the populations in question share common ancestry – as all populations do – then the allele frequency must have changed in one population. We can also supplement this with knowledge about when the populations diverged to determine when and how quickly this AF change must have happened. "],["haplotype-based-signatures.html", "9.3 Haplotype-based signatures", " 9.3 Haplotype-based signatures When a variant changes in frequency, it doesn’t change alone. The variants on the haplotype surrounding it will be pulled along to high frequency. This phenomenon, called hitchhiking, is similar to the haplotype blocks we observe in GWAS result (and both are caused by linkage between variants). What do you expect to happen to genetic diversity in the region of a selective sweep? If one haplotype is sweeping to high AF, we expect that genetic diversity in the region decreases because it’s being replaced by the selected haplotype. This is called a selective sweep because variation is being “swept” out of the region. This decreased diversity signature fades over time as new mutations arise on the haplotype. Fig. 3. (A) Selective sweeps reduce genetic diversity. (B)-(D) Summary of common signatures of selection. What can the size of the linked haplotype tell us about its evolutionary history? Because recombination breaks down haplotypes over time, a longer haplotype implies more recent selection. It can also provide information on the strength of selection – if most occurrences of the haplotype in the population are unbroken, selection was strong enough that it didn’t have time to recombine during the sweep. "],["setup-5.html", "9.4 Setup", " 9.4 Setup 9.4.1 R packages In addition to tidyverse and vcfR, we’ll also be using ggtree, an R package for visualizing trees associated with PBS outliers. library(tidyverse) library(vcfR) library(ggtree) "],["the-fst-statistic.html", "9.5 The FST statistic", " 9.5 The FST statistic \\(\\mathbf{F_{ST}}\\) is a statistic that quantifies differences in allele frequencies between populations at one variable site. The version of \\(\\mathrm{F_{ST}}\\) that we’ll calculate today compares genotypic variance within subpopulations (“S”) against the total population (“T”). One way to conceptualize this is the deficiency of heterozygotes observed across subpopulations, relative to the proportion that would be expected under random mating (i.e., no population structure). We calculate this by taking the difference between: \\(\\mathbf{H_T}\\): The expected frequency of heterozygotes when individuals across all subpopulations are pooled \\(\\mathbf{mean(H_S)}\\): The mean frequency of heterozygotes, calculated within each subpopulation and then averaged where \\(H = 2pq\\), and \\(p\\) and \\(q\\) are the frequencies of the two alleles at a site \\[ \\textrm{F}_{ST} = \\frac{H_T - \\textrm{mean}(H_S)}{H_T} \\] \\(\\mathrm{F_{ST}}\\) ranges from 0 to 1: \\(\\mathrm{F_{ST}} = 0\\): No population structure (separating the subpopulations doesn’t affect heterozygosity estimates) \\(\\mathrm{F_{ST}} = 1\\): Subopulations are very different (ex: one population only carries one allele, while the other population only carries the other) See this Nature Review Genetics article for a more thorough discussion on the use and interpretation of \\(\\mathrm{F_{ST}}\\) and related statistics. "],["data-for-fst.html", "9.6 Data (for FST)", " 9.6 Data (for FST) We’ll calculate \\(\\mathrm{F_{ST}}\\) using genotype data from the 1000 Genomes Project. Read in the VCF using thevcfR package: # read genotype data with vcfR vcf &lt;- read.vcfR(file = &quot;random_variable_sites.vcf.gz&quot;) ## Scanning file to determine attributes. ## File attributes: ## meta lines: 19 ## header_line: 20 ## variant count: 9748 ## column count: 2513 ## Meta line 19 read in. ## All meta lines processed. ## gt matrix initialized. ## Character matrix gt created. ## Character matrix gt rows: 9748 ## Character matrix gt cols: 2513 ## skip: 0 ## nrows: 9748 ## row_num: 0 ## Processed variant 1000Processed variant 2000Processed variant 3000Processed variant 4000Processed variant 5000Processed variant 6000Processed variant 7000Processed variant 8000Processed variant 9000Processed variant: 9748 ## All variants processed We’ll also read in a metadata table with information on which populations each sample is from. # read metadata metadata &lt;- read.table(&quot;integrated_call_samples.txt&quot;, header = TRUE) head(metadata) ## sample pop superpop sex ## 1 HG00096 GBR EUR male ## 2 HG00097 GBR EUR female ## 3 HG00099 GBR EUR female ## 4 HG00100 GBR EUR female ## 5 HG00101 GBR EUR male ## 6 HG00102 GBR EUR female "],["the-genetic_diff-function.html", "9.7 The genetic_diff function", " 9.7 The genetic_diff function We’ll compute \\(\\textrm{F}_{ST}\\) using vcfR’s genetic_diff function. (This function technically calculates \\(\\textrm{G}_{ST}\\), a version of \\(\\textrm{F}_{ST}\\) that considers when there are more than two alleles at a given locus. When a locus is biallelic, \\(\\textrm{F}_{ST} = \\textrm{G}_{ST}\\).) ?genetic_diff genetic_diff requires: vcfR object (in our case, vcf) Factor indicating populations “Factor indicating populations” The second object for genetic_diff needs to be a vector (i.e., a list) of population labels for the samples in the VCF. These labels must be factors, which is an R data type that limits a variable to a set of values. In our case, these values are the specific population labels in our dataset. We’ll be using the superpopulation groupings for this calculation. We can use our metadata table to generate a vector of superpopulation labels. Since the superpopulation IDs are in the superpop column of that dataframe, we can convert the column from character to factor values with the as.factor function. pop_labels &lt;- as.factor(metadata$superpop) head(pop_labels) ## [1] EUR EUR EUR EUR EUR EUR ## Levels: AFR AMR EAS EUR SAS Previewing pop_labels shows us that there are five “levels” in this vector, where each level is a superpopulation name. "],["calculating-fst.html", "9.8 Calculating FST", " 9.8 Calculating FST Run genetic_diff on the VCF: # calculate gst gst_results &lt;- genetic_diff(vcf, pop_labels) %&gt;% # order dataframe by descending gst value arrange(-Gst) # preview highest gst variants head(gst_results) ## CHROM POS Hs_AFR Hs_AMR Hs_EAS Hs_EUR Hs_SAS ## 1 chr21 17753762 0.3537087 0.20174987 0.1326531 0.029319019 0.040063399 ## 2 chr21 18668817 0.1477089 0.38831400 0.1377374 0.424382716 0.414679179 ## 3 chr21 15620159 0.4997750 0.09318240 0.0000000 0.007905014 0.000000000 ## 4 chr21 16235733 0.4994938 0.09318240 0.0000000 0.007905014 0.002042899 ## 5 chr21 22780904 0.4992826 0.09836474 0.0000000 0.001982159 0.000000000 ## 6 chr21 22786927 0.4991001 0.09318240 0.0000000 0.001982159 0.026231489 ## Ht n_AFR n_AMR n_EAS n_EUR n_SAS Gst Htmax Gstmax ## 1 0.3650242 1320 694 1008 1008 978 0.5572530 0.8286973 0.8049790 ## 2 0.4847713 1320 694 1008 1008 978 0.4082388 0.8484665 0.6618973 ## 3 0.2439190 1320 694 1008 1008 978 0.4004813 0.8289905 0.8235999 ## 4 0.2341095 1320 694 1008 1008 978 0.3739730 0.8290489 0.8232205 ## 5 0.2323592 1320 694 1008 1008 978 0.3732539 0.8288159 0.8242912 ## 6 0.2346916 1320 694 1008 1008 978 0.3609202 0.8297041 0.8192288 ## Gprimest ## 1 0.6922578 ## 2 0.6167706 ## 3 0.4862571 ## 4 0.4542805 ## 5 0.4528180 ## 6 0.4405610 # preview lowest gst variants tail(gst_results) ## CHROM POS Hs_AFR Hs_AMR Hs_EAS Hs_EUR Hs_SAS ## 9743 chr21 45527242 0.001514004 0.000000000 0.000000000 0.001982159 0.002042899 ## 9744 chr21 46135735 0.001514004 0.000000000 0.001982159 0.000000000 0.002042899 ## 9745 chr21 10718788 0.001514004 0.000000000 0.001982159 0.001982159 0.000000000 ## 9746 chr21 43949497 0.001514004 0.002877692 0.001982159 0.000000000 0.002042899 ## 9747 chr21 33087300 0.003025712 0.005747079 0.005934666 0.003960380 0.004081616 ## 9748 chr21 7948042 0.499885216 0.499995847 0.499968506 0.499992126 0.500000000 ## Ht n_AFR n_AMR n_EAS n_EUR n_SAS Gst Htmax Gstmax ## 9743 0.001197365 1320 694 1008 1008 978 3.251980e-04 0.7924231 0.9984895 ## 9744 0.001197365 1320 694 1008 1008 978 3.251980e-04 0.7924231 0.9984895 ## 9745 0.001197365 1320 694 1008 1008 978 3.150481e-04 0.7924255 0.9984895 ## 9746 0.001596168 1320 694 1008 1008 978 2.547455e-04 0.7924784 0.9979864 ## 9747 0.004383322 1320 694 1008 1008 978 1.475473e-04 0.7930368 0.9944736 ## 9748 0.499976954 1320 694 1008 1008 978 3.141686e-05 0.8960702 0.4420513 ## Gprimest ## 9743 3.256899e-04 ## 9744 3.256899e-04 ## 9745 3.155247e-04 ## 9746 2.552595e-04 ## 9747 1.483672e-04 ## 9748 7.107064e-05 genetic_diff outputs a table of \\(\\textrm{G}_{ST}\\) results, where every line corresponds to one variant from the input VCF. Our \\(\\textrm{G}_{ST}\\) values range from \\(0.0021\\) to \\(0.00033\\). "],["distribution-of-gst-across-the-genome.html", "9.9 Distribution of GST across the genome", " 9.9 Distribution of GST across the genome Plot the distribution of \\(\\textrm{G}_{ST}\\) values from genetic_diff ggplot(data = gst_results, aes(x = Gst)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. This is an exponentially decaying distribution, indicating that most common human variants don’t show strong differences in allele frequency between populations. "],["top-gst-hits.html", "9.10 Top GST hits", " 9.10 Top GST hits The variants with high \\(\\textrm{G}_{ST}\\) values should show differences in allele frequency between populations. Let’s examine the top-scoring variant: gst_results[1, ] ## CHROM POS Hs_AFR Hs_AMR Hs_EAS Hs_EUR Hs_SAS Ht ## 1 chr21 17753762 0.3537087 0.2017499 0.1326531 0.02931902 0.0400634 0.3650242 ## n_AFR n_AMR n_EAS n_EUR n_SAS Gst Htmax Gstmax Gprimest ## 1 1320 694 1008 1008 978 0.557253 0.8286973 0.804979 0.6922578 We can use the GGV browser to visualize this variant’s allele frequencies across the 1000 Genomes populations. One complicating factor is that the browser is based on the hg19 reference genome, while we’re working with a VCF on the more recent hg38 coordinate system. How do you compare variants between genome builds? There are many ways of converting from genome coordinate system to the other. One way is to look up the ID of the SNP in the UCSC Genome Browser, using its chromosome and position: Fig. 4. Identifying a SNP’s rsID in the UCSC Genome Browser. This SNP has the ID rs7276293, which should be consistent between reference builds. "],["viewing-gst-hits-in-ggv.html", "9.11 Viewing GST hits in GGV", " 9.11 Viewing GST hits in GGV Now we can navigate to the GGV browser and look up the distribution of allele frequencies for this variant. Note that the “position” has changed due to the new coordinate system, but we are looking at the same SNP. This variant has huge allele frequency differences across populations, consistent with the high GST value that we computed. Also note that two populations in the Americas also carry this variant at high frequency. These are both African American populations – African Caribbean in Barbados (ACB) and African Ancestry in SW USA (ASW). Fig. 5. Allele frequencies of our top GST hit. "],["population-branch-statistic.html", "9.12 Population branch statistic", " 9.12 Population branch statistic \\(\\textrm{F}_{ST}\\) and related statistics ask about allele frequency differences between two populations. If we compare sets of three populations instead of focusing on pairs, we can calculate a different statistic called the population branch statistic (PBS). What are the advantages of comparing three populations? Two-population comparisons tell us that an allele frequency change happened after the two populations diverged, but give us no information about when it occurred. Comparing between three populations lets us contrast allele frequencies among the populations to localize frequency changes to a particular branch of a tree. Fig. 6. A variant exists at different frequencies in populations A and B. By comparing to a third population, we can identify that selection likely occurred within population A. "],["calculating-pbs.html", "9.13 Calculating PBS", " 9.13 Calculating PBS PBS is based on calculating \\(\\textrm{F}_{ST}\\) for each pairwise comparison of the three populations. We then calculate the branch length (\\(\\mathbf{T}\\)) that separates each population pair: \\[ T = -\\mathrm{log}(1 - \\textrm{F}_{ST}) \\] PBS is then computed as: \\[ \\textrm{PBS} = \\frac{\\textrm{T}_{AB} + \\textrm{T}_{AC} - \\textrm{T}_{BC}}{2} \\] "],["data-for-pbs.html", "9.14 Data (for PBS)", " 9.14 Data (for PBS) We’ll calculate PBS using data from the paper: Tucci, S. et al. (2018). Evolutionary history and adaptation of a human pygmy population of Flores Island, Indonesia.. Flores Island was home to fossils of the archaic hominin species Homo floresiensis, also called “hobbits” because their skeletons are 3 ft. tall. It’s thought that H. floresiensis lived there until just 40k-30k years ago, overlapping with modern humans. This study collected samples from individuals who currently live on Flores Island and scanned their genomes for evidence of natural selection. They calculated PBS between: The Rampasasa (RPS) population from Flores A Han Chinese (CHB) population A Melanesian population from Papua New Guinea (PNG) Fig. 7. Distribution of populations used in Tucci et al. "],["reading-in-pbs-data.html", "9.15 Reading in PBS data", " 9.15 Reading in PBS data We’ve pre-calculated pairwise \\(\\textrm{F}_{ST}\\) between the Rampasasa, Han Chinese, and Papua New Guinea populations. Load the results for chromosome 11 into R: fst_results &lt;- read.table(&quot;fst_results.txt.gz&quot;, header = TRUE) head(fst_results) ## chr pos rps.af chb.af png.af fst.rps.chb fst.rps.png ## 1 11 100001950 0.1666670 0.0145631 0.0428571 0.32524800 0.0845486 ## 2 11 100003476 0.0555556 0.0339806 0.1000000 -0.01078610 -0.0118052 ## 3 11 100004351 0.1111110 0.0485437 0.1142860 0.05945300 -0.0322152 ## 4 11 100005864 0.6111110 0.6553400 0.4285710 -0.02752900 0.0520164 ## 5 11 100006486 0.8333330 0.7766990 0.7571430 0.00768713 -0.0119055 ## 6 11 100006861 0.5000000 0.3834950 0.2285710 0.05413630 0.1807550 ## fst.png.chb ## 1 0.00465910 ## 2 0.03640770 ## 3 0.02896550 ## 4 0.11842600 ## 5 -0.00951234 ## 6 0.06338550 Every row of this table is a SNP: Columns ending in .af contain the allele frequency for that population Columns starting with fst. contain the \\(\\textrm{F}_{ST}\\) between that population pair "],["calculating-pbs-1.html", "9.16 Calculating PBS", " 9.16 Calculating PBS Using these \\(\\textrm{F}_{ST}\\) values, we can calculate (for every SNP) the branch lengths (\\(\\mathbf{T}\\)) that separate each population pair, and then calculate PBS. The mutate() function tidyverse’s mutate function is an easy way to perform calculations on tables. Its syntax is: mutate(new_column = &lt;formula for calculating column values&gt;) For example, if I wanted to create a new column that average each SNP’s allele frequencies across the three populations: fst_results %&gt;% mutate(avg_af = (rps.af + chb.af + png.af) / 3) Filling in the gaps in the code block below, use mutate to calculate T and PBS on the FST values: pbs &lt;- fst_results %&gt;% # calculate branch lengths between populations mutate(T_rps_chb = _________, T_rps_png = _________, T_png_chb = _________,) %&gt;% # calculate pbs mutate(pbs = _________) %&gt;% # sort by descending pbs value arrange(-pbs) Solution pbs &lt;- fst_results %&gt;% # calculate branch lengths between populations mutate(T_rps_chb = -log(1 - fst.rps.chb), T_rps_png = -log(1 - fst.rps.png), T_png_chb = -log(1 - fst.png.chb)) %&gt;% # calculate pbs mutate(pbs = ((T_rps_png + T_rps_chb) - (T_png_chb)) / 2) %&gt;% # sort by descending pbs value arrange(-pbs) head(pbs) ## chr pos rps.af chb.af png.af fst.rps.chb fst.rps.png fst.png.chb ## 1 11 126880301 0.833333 0.296117 0.0571429 0.734021 0.823884 0.216269 ## 2 11 126883747 0.833333 0.296117 0.0571429 0.734021 0.823884 0.216269 ## 3 11 126893266 0.833333 0.300971 0.0571429 0.729450 0.823884 0.222408 ## 4 11 126883622 0.833333 0.300971 0.0571429 0.729227 0.823884 0.221887 ## 5 11 126888750 0.833333 0.305825 0.0571429 0.724490 0.823884 0.227770 ## 6 11 126885142 0.833333 0.320388 0.0571429 0.709721 0.823884 0.244928 ## T_rps_chb T_rps_png T_png_chb pbs ## 1 1.324338 1.736612 0.2436894 1.408630 ## 2 1.324338 1.736612 0.2436894 1.408630 ## 3 1.307298 1.736612 0.2515533 1.396179 ## 4 1.306474 1.736612 0.2508835 1.396102 ## 5 1.289131 1.736612 0.2584728 1.383635 ## 6 1.236913 1.736612 0.2809422 1.346291 "],["manhattan-plot-of-pbs-results.html", "9.17 Manhattan plot of PBS results", " 9.17 Manhattan plot of PBS results We can visualize our PBS results by generating a Manhattan plot where we plot PBS on the y-axis instead of p-values. Make this Manhattan plot using geom_point. ggplot(data = pbs, aes(x = pos, y = pbs)) + geom_point() As evidence of positive selection, we are interested in both the height of the peaks in the plot, as well as the number of SNPs that comprise each peak (which is a proxy for haplotype length). "],["top-pbs-hits.html", "9.18 Top PBS hits", " 9.18 Top PBS hits What are the top PBS hits we’ve identified? Click on the pbs table to scroll through the SNPs with the highest PBS values. Use the UCSC Genome Browser to look up the top two PBS peaks. (We’re using the hg19 browser here because this data was generated with the hg19 reference genome.) What genes (if any) do these top PBS peaks overlap with? The top chr11 peak doesn’t seem to overlap with any genes, but is closest to KIRREL3. The second chr11 peak overlaps with the fatty acid desaturase gene cluster (FADS1, FADS2, and FADS3), which have previously been implicated as targets of independent episodes of positive selection in human populations. Fig. 8. The FADS gene cluster around the second PBS peak. "],["plotting-pbs-trees.html", "9.19 Plotting PBS trees", " 9.19 Plotting PBS trees Another useful way to visualize PBS is by comparing trees for the top PBS outliers to the genome-wide average tree. Run the code blocks below to plot these trees: # create average tree tr_mean &lt;- rtree(n = 3, rooted = FALSE, br = c(mean(pbs$T_rps_png), mean(pbs$T_rps_chb), mean(pbs$T_png_chb))) # plot average tree ggtree(tr_mean, layout = &quot;daylight&quot;) + geom_treescale(width = 0.1) + geom_tiplab(label = c(&quot;RPS&quot;, &quot;PNG&quot;, &quot;CHB&quot;)) ## Average angle change [1] 0.333333333333333 ## Average angle change [2] 2.22044604925031e-16 # create tree for top snp tr_top &lt;- rtree(n = 3, rooted = FALSE, br = c(pbs[1,]$T_rps_png, pbs[1,]$T_rps_chb, pbs[1,]$T_png_chb)) # plot top snp tree ggtree(tr_top, layout = &quot;daylight&quot;) + geom_treescale(width = 0.1) + geom_tiplab(label = c(&quot;RPS&quot;, &quot;PNG&quot;, &quot;CHB&quot;)) ## Average angle change [1] 0.333333333333333 ## Average angle change [2] 2.22044604925031e-16 "],["extended-haplotype-homozygosity.html", "9.20 Extended haplotype homozygosity", " 9.20 Extended haplotype homozygosity The haplotype-based class of selection statistics quantifies long haplotypes that result from a selective sweep. Extended haplotype homozygosity (EHH) is defined as the probability that any two haplotypes in a population are homozygous at SNPs in specific genomic region. EHH should be elevated in regions under historical selection, because a sweep causes one haplotype to rise to high frequency, and decay as you move further from the site under selection. Fig. 9. EHH measures how likely two haplotypes are to carry the same variant at a given location – a signature that we expect recent selection to exaggerate. "],["plotting-ehh.html", "9.21 Plotting EHH", " 9.21 Plotting EHH EHH can be visualized with phylogeny-like plots like the one below. The width of the blue bar (the haplotype of interest) represents the haplotype’s frequency in a population, and the steps in the plot indicate historical recombination. The other branches of the phylogeny (in red) indicate other haplotypes in this region. An overrepresentation of one haplotype over the others creates the observation of extreme EHH. Fig. 10 (from David Reich). Overrepresentation of the blue haplotype indicates extreme EHH, a possible signature of selection. EHH plot for real data This plot shows EHH calculated for the CEU population of 1000 Genomes (Utah Residents [CEPH] with Northern and Western European Ancestry), zoomed in at the lactase (LCT) locus. A haplotype in this locus underwent a selective sweep in ancestor of European populations that allowed digestion of milk into adulthood, resulting in a present-day signature of EHH that stretches across megabases of sequence. In contrast, the ancestral haplotype (bottom) displays a much greater diversity and recombination. Fig. 11. EHH calculated for the lactase locus. "],["integrated-haplotype-statistic.html", "9.22 Integrated haplotype statistic", " 9.22 Integrated haplotype statistic If you calculate EHH for both the new and ancestral haplotypes at a locus, you can compare them to calculate the integrated haplotype statistic (iHS), which is the ratio of the area under the EHH curve for the derived and ancestral haplotypes. Fig. 12. Comparing the EHH of haplotypes carrying the derived and ancestral alleles to calculate iHS. "],["the-pophuman-browser.html", "9.23 The PopHuman browser", " 9.23 The PopHuman browser While some R packages exist to compute EHH and iHS (e.g., the rehh package), they require some tricky processing of VCF files. Moreover, these statistics have already been computed genome-wide for all of the populations in the 1000 Genomes dataset, available from the PopHuman browser. This browser lets you pull up results for several population genetic signatures. Look up the lactase (LCT) gene in the search bar, and then click Select tracks in the upper left-hand corner to choose: iHS for the CEU (European) population pi for the CEU population. This is a measure of nucleotide diversity, which we expect to be low in a region under historical selection Fig. 13. iHS and \\(\\pi\\) in the LCT region. Note that if we compare both of these statistics to the genome-wide mean (yellow lines), we can see how dramatically they deviate from expectations in this genomic region. "],["conclusion-7.html", "9.24 Conclusion", " 9.24 Conclusion In this lab, we used three approaches to identify selection in multi-population sequencing data. Using genotype data from the 1000 Genomes Project, we calculated FST, a measure of how different a variant’s allele frequency is between populations. We confirmed in the GGV Browser that the top FST variant shows strong population-specific AF differences. We then calculated the population branch statistic (PBS) to identify variants under selection in a human population on Flores Island, Indonesia. One of the top PBS hits was in the fatty acid desaturase gene cluster (FADS). Finally, we discussed extended haplotype homozygosity (EHH) and related statistics, which detect long haplotypes that result from a selective sweep. Using the PopHuman browser, we saw that the LCT locus – the most famous example of selection in humans – exhibits both elevated EHH and reduced genetic diversity (\\(\\pi\\)). "],["homework-7.html", "9.25 Homework", " 9.25 Homework 9.25.0.1 Learning Objectives Interpret multiple statistics for measuring selection Explain how specific statistics can give different results because they measure different genetic signatures 9.25.0.2 Assignment Read this review paper on genomic evidence of human local adaptation by Fan et al. Find examples of local adaptation (genes and populations) in the paper, and look up the relevant populations (or related populations) and tests of selection in the PopHuman browser. Are the signatures of selection apparent? Are the signature apparent based on all statistics? Why do certain statistics capture evidence of selection at certain loci but not others? "],["archaic-admixture.html", "10 Archaic admixture", " 10 Archaic admixture In this lab, we’ll discuss three common statistics, \\(D\\), \\(f_{4}\\), and the \\(f_{4}\\)-ratio, which are used for quantifying and testing hypotheses related to admixture (or “introgression”). 10.0.0.1 Learning objectives After completing this chapter, you’ll be able to: Explain how incomplete lineage sorting can create patterns of allele sharing that are discordant with species relationships. Describe how introgression is expected to affect patterns of allele sharing. Interpret the \\(D\\) and \\(f_4\\) statistics and their associated p-values. Interpret the \\(f_{4}\\)-ratio ratio statistic and whether it implies differences in archaic admixture between populations. "],["neanderthal-and-denisovan-introgression.html", "10.1 Neanderthal and Denisovan introgression", " 10.1 Neanderthal and Denisovan introgression As modern humans migrated out of Africa 50,000-70,000 years ago, they encountered and intebred with two groups of archaic hominins, the Neanderthals and Denisovans. Admixture with archaic hominins resulted in introgression of archaic DNA into these migrating populations. These Neanderthal and Denisovan sequences still persist in the genomes of their present-day descendents. Fig. 1. Ancient encounters between migrating human populations and archaic hominins. "],["inferring-introgression-from-phylogenetic-trees.html", "10.2 Inferring introgression from phylogenetic trees", " 10.2 Inferring introgression from phylogenetic trees One test for introgression – called the \\(\\textbf{D}\\) statistic, or ABBA-BABA test – compares the phylogenetic tree of species-level relationships with the tree for a specific genetic variant. We expect the species-level tree for Neanderthals and humans to look like the white bars of the tree in Fig. 2, where any two human populations are more similar to each other than they are to Neanderthals or chimpanzees (the outgroup). If a genetic variant differs between humans and Neanderthals, we generally expect it to segregate according to the species-level tree, in an AABB pattern (Fig. 2). Fig. 2. A variant concordant with the species-level tree for modern humans and Neanderthals. "],["incomplete-lineage-sorting.html", "10.3 Incomplete lineage sorting", " 10.3 Incomplete lineage sorting More rarely, the tree constructed for a specific SNP is discordant with the species tree. This is usually due to incomplete lineage sorting (ILS) – when genetic variation is present in the ancestor of two populations (e.g., the modern human–Neanderthal ancestor), then randomly fixes in a fashion that happens to conflict with the populations’ evolutionary relationships. ILS can create discordant ABBA or BABA trees for a given SNP. Under ILS, we would expect to see approximately equal numbers of ABBA and BABA trees. Fig. 3. ABBA and BABA allele patterns can be formed by incomplete lineage sorting. "],["evidence-of-introgression.html", "10.4 Evidence of introgression", " 10.4 Evidence of introgression Discordant trees can also be produced by introgression. In this case, the B allele arises on the Neanderthal lineage and is passed from Neanderthals into a human population, creating either an ABBA or BABA pattern (depending on which population receives Neanderthal gene flow). Fig. 4. ABBA and BABA allele patterns formed by Neanderthal introgression. "],["the-d-statistic.html", "10.5 The \\(D\\) statistic", " 10.5 The \\(D\\) statistic Introgression creates an imbalance in the number of ABBA or BABA trees if only one of the human populations has admixed with Neanderthals. The \\(\\textbf{D}\\) statistic quantifies this imbalance: \\[ D = \\frac{\\textrm{# BABA sites} - \\textrm{# ABBA sites}}{\\textrm{# BABA sites} + \\textrm{# ABBA sites}} \\] \\(D &gt; 0\\) is evidence for Neanderthal gene flow into the H2 population, while \\(D &lt; 0\\) is evidence for gene flow into H1. Choice of populations for the \\(D\\) statistic The choice of populations is very important when calculating the \\(D\\) statistic. When assessing archaic introgression, H2 is typicaly set as a human population without archaic admixture (e.g., a population from Africa). If H2 instead were a European population that did possess introgressed sequence, we would not expect a significant \\(D\\) statistic. "],["setup-6.html", "10.6 Setup", " 10.6 Setup In this lab, we’ll quantify evidence for introgression in human populations using \\(D\\) and related statistics. 10.6.1 R packages In addition to tidyverse, we’ll use the admixr package, which allows us to easily run the software package ADMIXTOOLS from within R to calculate \\(D\\) and related statistics. The exercises for class were adapted from the admixr tutorial, available here. library(tidyverse) library(admixr) "],["data-3.html", "10.7 Data", " 10.7 Data The admixr package provides real example data from 10 human individuals, which can be acquired by running its download_data() function: # download data into current directory prefix &lt;- download_data(dirname = &quot;.&quot;) We now have a directory called snps that contain four files: snps.geno: Genotype of each individual (column) at each SNP (row) Represented as counts of the alternative allele (0, 1, 2) snps.ind: Population IDs for each individual snps.snp: SNP IDs, positions, and alleles regions.bed: A file of genomic regions (not required for basic admixr analysis) EIGENSTRAT format Together, the three .geno, .ind, and .snp files constitute EIGENSTRAT format. This is just a way of representing genotype data, similar to a VCF – in fact, several software packages exist to convert between VCF and EIGENSTRAT. "],["reading-in-data.html", "10.8 Reading in data", " 10.8 Reading in data We can provide the location of the downloaded files to the eigenstrat() function, which then constructs an EIGENSTRAT object to be used for downstream analysis. # read in eigenstrat files snps &lt;- eigenstrat(&quot;./snps/snps&quot;) snps ## EIGENSTRAT object ## ================= ## components: ## ind file: ./snps/snps.ind ## snp file: ./snps/snps.snp ## geno file: ./snps/snps.geno "],["the-d-function.html", "10.9 The d() function", " 10.9 The d() function admixr computes the \\(D\\) statistic in a function called d(). ?d As input, d() asks for: Data object in EIGENSTRAT format Four population names (W, X, Y, Z) to calculate D between "],["computing-the-d-statistic.html", "10.10 Computing the D statistic", " 10.10 Computing the D statistic Let’s compute \\(D\\) for four of the individuals we have data for: French, Sardinian, Vindija (Neanderthal), and chimpanzee. d_result &lt;- d(data = snps, # provide population names to calculate D between W = &quot;French&quot;, X = &quot;Sardinian&quot;, Y = &quot;Vindija&quot;, Z = &quot;Chimp&quot;) d_result ## W X Y Z D stderr Zscore BABA ABBA nsnps ## 1 French Sardinian Vindija Chimp 0.0038 0.0074 0.511 10974 10891 487843 How do we interpret these results? The last three columns count the number of ABBA and BABA sites, as well as the total number of variants being analyzed. First, note that the ABBA/BABA sites are only a small fraction of the total number of variants – most variants conform to the species-level tree. The number of ABBA and BABA variants also looks similar, which implies that the discordant trees in these four populations primarily result from ILS rather than introgression. The middle columns give the actual value of \\(D\\) and its standard error, as well as the Z score (which is equal to \\(\\frac{D}{\\textrm{stderr}}\\)). "],["converting-to-p-values.html", "10.11 Converting to p-values", " 10.11 Converting to p-values How do we know whether the ABBA-BABA counts are significantly different? We can convert the Z score into a p-value: d_result &lt;- d_result %&gt;% # convert z score into pvalue mutate(p = 2 * pnorm(-abs(Zscore))) d_result ## W X Y Z D stderr Zscore BABA ABBA nsnps ## 1 French Sardinian Vindija Chimp 0.0038 0.0074 0.511 10974 10891 487843 ## p ## 1 0.6093511 Interpretation of this p-value The p-value does not look significant (no introgression into the ancestors of this French or Sardinian individual). This is in line with our observation that there doesn’t seem to be a disproportionate amount of ABBA or BABA sites. "],["computing-d-for-all-populations.html", "10.12 Computing D for all populations", " 10.12 Computing D for all populations We can give d() a list of populations to compute the \\(D\\) statistic for, where: W: A vector of our populations of interest X: An assumed unadmixed population (Yoruba) Y: The introgressing population (Vindija Neanderthal) Z: Outgroup (chimpanzee) # create vector of populations of interest pops &lt;- c(&quot;French&quot;, &quot;Sardinian&quot;, &quot;Han&quot;, &quot;Papuan&quot;, # including three African populations &quot;Khomani_San&quot;, &quot;Mbuti&quot;, &quot;Dinka&quot;) # calculate D d_result &lt;- d(data = snps, W = pops, X = &quot;Yoruba&quot;, Y = &quot;Vindija&quot;, Z = &quot;Chimp&quot;) %&gt;% # convert z score into pvalue mutate(p = 2 * pnorm(-abs(Zscore))) d_result ## W X Y Z D stderr Zscore BABA ABBA nsnps ## 1 French Yoruba Vindija Chimp 0.0313 0.006933 4.510 15802 14844 487753 ## 2 Sardinian Yoruba Vindija Chimp 0.0287 0.006792 4.222 15729 14852 487646 ## 3 Han Yoruba Vindija Chimp 0.0278 0.006609 4.199 15780 14928 487925 ## 4 Papuan Yoruba Vindija Chimp 0.0457 0.006571 6.953 16131 14721 487694 ## 5 Khomani_San Yoruba Vindija Chimp 0.0066 0.006292 1.051 16168 15955 487564 ## 6 Mbuti Yoruba Vindija Chimp -0.0005 0.006345 -0.074 15751 15766 487642 ## 7 Dinka Yoruba Vindija Chimp -0.0009 0.006124 -0.151 15131 15159 487667 ## p ## 1 6.482763e-06 ## 2 2.421441e-05 ## 3 2.680963e-05 ## 4 3.575987e-12 ## 5 2.932586e-01 ## 6 9.410104e-01 ## 7 8.799757e-01 Interpretation of \\(D\\) results This is the result that was published in Green et al. 2010, revealing evidence for gene flow from Neanderthals into the ancestors of non-African populations. We see significant evidence of Neanderthal introgression into the genomes of the non-African samples (French, Sardinian, Han, Papuan), but not the African samples (although we know from recent research that this is an oversimplification). "],["plotting-the-d-statistic.html", "10.13 Plotting the D statistic", " 10.13 Plotting the D statistic Use this code to plot the \\(D\\) statistic and standard error calculated for each population. This is a visual representation of the data in the d_result table: ggplot(data = d_result, aes(x = W, y = D, color = p &lt; 0.05)) + geom_point() + geom_hline(yintercept = 0, linetype = 2) + geom_errorbar(aes(ymin = D - 1.96 * stderr, ymax = D + 1.96 * stderr), width = 0.5) + xlab(&quot;Population&quot;) "],["f_4-statistic.html", "10.14 \\(f_{4}\\) statistic", " 10.14 \\(f_{4}\\) statistic The \\(\\mathbf{f_{4}}\\) statistic – not to be confused with the \\(\\mathrm{F_{ST}}\\) from the previous week – is very similar to the D statistic. Its main advantage is that it is proportional to the branch length separating two pairs of populations. Compute the \\(f_{4}\\) statistic for all populations using the code below: f4_result &lt;- f4(data = snps, W = pops, X = &quot;Yoruba&quot;, Y = &quot;Vindija&quot;, Z = &quot;Chimp&quot;) %&gt;% # convert z score into pvalue mutate(p = 2 * pnorm(-abs(Zscore))) f4_result ## W X Y Z f4 stderr Zscore BABA ABBA nsnps ## 1 French Yoruba Vindija Chimp 0.001965 0.000437 4.501 15802 14844 487753 ## 2 Sardinian Yoruba Vindija Chimp 0.001798 0.000427 4.209 15729 14852 487646 ## 3 Han Yoruba Vindija Chimp 0.001746 0.000418 4.178 15780 14928 487925 ## 4 Papuan Yoruba Vindija Chimp 0.002890 0.000417 6.924 16131 14721 487694 ## 5 Khomani_San Yoruba Vindija Chimp 0.000436 0.000415 1.051 16168 15955 487564 ## 6 Mbuti Yoruba Vindija Chimp -0.000030 0.000410 -0.074 15751 15766 487642 ## 7 Dinka Yoruba Vindija Chimp -0.000057 0.000380 -0.151 15131 15159 487667 ## p ## 1 6.763451e-06 ## 2 2.565034e-05 ## 3 2.940837e-05 ## 4 4.390659e-12 ## 5 2.932586e-01 ## 6 9.410104e-01 ## 7 8.799757e-01 Note that the p-values are the same as when we calculated the \\(D\\) statistic, but the actual \\(f_4\\) values are different. "],["f_4-ratio-statistic.html", "10.15 \\(f_{4}\\)-ratio statistic", " 10.15 \\(f_{4}\\)-ratio statistic The branch length proportionality of the \\(f_4\\) statistic is useful for deriving yet another statistic, called the \\(\\mathbf{f_{4}}\\)-ratio statistic. As implied by its name, this simply a ratio of two different \\(f_{4}\\) statistics. Unlike \\(D\\) and \\(f_{4}\\), the \\(f_{4}\\)-ratio tells us how much Neanderthal ancestry a given individual possesses. Calculate the \\(f_{4}\\)-ratio using the code block below: f4_ratio_result &lt;- f4ratio(data = snps, X = pops, A = &quot;Altai&quot;, B = &quot;Vindija&quot;, C = &quot;Yoruba&quot;, O = &quot;Chimp&quot;) %&gt;% # convert z score to pvalue mutate(p = 2 * pnorm(-abs(Zscore))) f4_ratio_result ## A B X C O alpha stderr Zscore p ## 1 Altai Vindija French Yoruba Chimp 0.023774 0.006176 3.850 1.181178e-04 ## 2 Altai Vindija Sardinian Yoruba Chimp 0.024468 0.006071 4.031 5.554004e-05 ## 3 Altai Vindija Han Yoruba Chimp 0.022117 0.005892 3.754 1.740349e-04 ## 4 Altai Vindija Papuan Yoruba Chimp 0.037311 0.005812 6.420 1.362743e-10 ## 5 Altai Vindija Khomani_San Yoruba Chimp 0.003909 0.005913 0.661 5.086123e-01 ## 6 Altai Vindija Mbuti Yoruba Chimp 0.000319 0.005717 0.056 9.553418e-01 ## 7 Altai Vindija Dinka Yoruba Chimp -0.001500 0.005394 -0.278 7.810124e-01 For this statistic, alpha represents the proportion of the genome whose ancestry traces to Neanderthal introgression. "],["plotting-f_4-ratio-results.html", "10.16 Plotting \\(f_{4}\\)-ratio results", " 10.16 Plotting \\(f_{4}\\)-ratio results Run the code below to plot the \\(f_{4}\\)-ratio values we computed: ggplot(data = f4_ratio_result, aes(x = X, y = alpha, color = p &lt; 0.05)) + geom_point() + geom_errorbar(aes(ymin = alpha - 2 * stderr, ymax = alpha + 2 * stderr), width = 0.5) + geom_hline(yintercept = 0, linetype = 2) + labs(y = &quot;Neanderthal ancestry proportion&quot;, x = &quot;Present-day individual&quot;) Based on what we know about Papuan populations, do you think the estimate of 4% Neanderthal introgressed DNA is accurate? We know that Oceanian populations also experienced introgression from Denisovans. Denisovans were more genetically similar to Neanderthals than to modern humans, so Denisovan ancestry is being counted as Neanderthal ancestry by this metric. "],["computing-statistics-in-genomic-intervals.html", "10.17 Computing statistics in genomic intervals", " 10.17 Computing statistics in genomic intervals We’ve so far computed the \\(D\\), \\(f_4\\), and \\(f_4\\)-ratio statistics across the entire genome, but we can also restrict computation to particular genomic intervals, such as genes, promoters, enhancers, etc. What would region-specific differences imply? Region-specific differences suggest that there are some regions of the genome that are particularly tolerant or intolerant to introgression. Fig. 5 (source). Proportion of introgressed Neanderthal ancestry within specific gene annotations. In the figure below, we see that the genome-wide average percentage of Neanderthal ancestry is ~2%, but there are some genomic regions (promoters, evolutionarily conserved sequences) where this percentage is lower. One theory explaining this pattern is that Neanderthals accumulated a genetic load of slightly deleterious mutations due to their small population sizes. Consequently, when Neanderthal sequences were introgressed into human populations, they were subjected to negative selection, which was stronger in more functionally important regions of the genome. "],["bed-files.html", "10.18 BED files", " 10.18 BED files Annotations of genomic intervals are commonly represented in a file format called BED. We can utilize these files in admixr’s filter_bed() function, which excludes or restricts analyses to genomic intervals within a BED file. Run the code below to re-calculate the \\(f_4\\)-ratio with promoters_hg19.bed – a bed file containing the coordiinates for promoters annotated in the Ensembl Regulatory Build. We can create a new snps data object that either keeps or excludes these regions from our analysis. # get the path to the `regions.bed` file bed &lt;- file.path(&quot;promoters_hg19.bed&quot;) # option 1: KEEP only these regions for analysis new_snps_keep &lt;- filter_bed(snps, bed) # option 2: REMOVE these regions from analysis new_snps_remove &lt;- filter_bed(snps, bed, remove = TRUE) "],["region-specific-f_4-ratio.html", "10.19 Region-specific \\(f_4\\) ratio", " 10.19 Region-specific \\(f_4\\) ratio Now we can re-calculate the \\(f_4\\)-ratio only within promoter regions. # f4-ratio with only promoters f4_filtered &lt;- f4ratio(data = new_snps_keep, X = pops, A = &quot;Altai&quot;, B = &quot;Vindija&quot;, C = &quot;Yoruba&quot;, O = &quot;Chimp&quot;) %&gt;% # convert z score to pvalue mutate(p = 2 * pnorm(-abs(Zscore))) f4_filtered ## A B X C O alpha stderr Zscore p ## 1 Altai Vindija French Yoruba Chimp -0.005541 0.028515 -0.194 0.84617588 ## 2 Altai Vindija Sardinian Yoruba Chimp 0.002263 0.031027 0.073 0.94180612 ## 3 Altai Vindija Han Yoruba Chimp 0.066668 0.029767 2.240 0.02509092 ## 4 Altai Vindija Papuan Yoruba Chimp 0.010940 0.030057 0.364 0.71585801 ## 5 Altai Vindija Khomani_San Yoruba Chimp 0.026367 0.031975 0.825 0.40937159 ## 6 Altai Vindija Mbuti Yoruba Chimp 0.005176 0.030194 0.171 0.86422377 ## 7 Altai Vindija Dinka Yoruba Chimp 0.008542 0.026768 0.319 0.74972651 Plot the region-excluded \\(f_4\\)-ratios ggplot(f4_filtered, aes(x = X, y = alpha, color = p &lt; 0.05)) + geom_point() + geom_errorbar(aes(ymin = alpha - 2 * stderr, ymax = alpha + 2 * stderr), width = 0.5) + geom_hline(yintercept = 0, linetype = 2) + labs(y = &quot;Neanderthal ancestry proportion&quot;, x = &quot;Present-day individual&quot;) Except for the Han population, we see almost no Neanderthal ancestry when we calculate the \\(f_4\\)-ratio within promoters – supporting the idea that functionally important genomic regions are depleted for Neanderthal introgression. "],["conclusion-8.html", "10.20 Conclusion", " 10.20 Conclusion In this lab, we assessed evidence for Neanderthal introgression into specific human populations. We reviewed the \\(\\mathbf{D}\\) statistic, which asks whether a variant shows an imbalance in the population inheritance patterns expected from incomplete lineage sorting (ILS). Such an imbalance implies historical introgression into one population. With admixr, we calculated the \\(D\\) statistic for one individual from each of seven modern human populations, identifying significant evidence for Neanderthal introgression into the ancestors of non-African – but not African – populations. We also calculated the \\(\\mathbf{f_4}\\) statistic, which is very similar to the \\(D\\) statistic but is proportional to the genetic distance between two populations. We computed the \\(\\mathbf{f_4}\\)-ratio, whose value indicates the proportion of introgressed ancestry in each population. Finally, we computed the \\(\\mathbf{f_4}\\)-ratio within just promoter regions, where we observed a depletion of Neanderthal ancestry. "],["homework-8.html", "10.21 Homework", " 10.21 Homework 10.21.0.1 Learning Objectives Practice calculating introgression statistics in admixr Interpret the biological significance of region-specific values of the \\(f_4\\)-ratio 10.21.0.2 Assignment Follow these steps to create your own genome stratifications for calculating the \\(f_4\\) ratio statistic. Go to the UCSC Table Browser, where you can find a wide selection of annotations for the human genome. Make sure you set the assembly: drop-down box to Feb. 2009 (GRCh37/hg19). Use the group: and track: menus to select any set of genomic regions. You can click the data format description button and scroll to the Description section to find out what each annotation represents. Under the Retrieve and display data section, set the output format: to BED. Enter an output filename: (ex: all_genes.bed). Click get output to download the file. In Posit Cloud, upload your file using the Upload button in the Files panel (bottom right). Run the code block below to reformat the BED file. The code matches the UCSC’s chromosome naming format with the format used in the snps data: # fill in blank with the name of your bed file system(command = &quot;sed -i &#39;s/chr//g&#39; ________&quot;) # get the path to your bed file bed &lt;- file.path(&quot;________&quot;) Compute the \\(f_4\\) ratio statistic within and outside of the genomic intervals. Repeat for another set of genome annotations to contrast Neanderthal ancestry in different genomic elements. Solution Download tracklist of haploinsufficient genes (Phenotype and Literature -&gt; Haploinsufficiency). # get the path to the `regions.bed` file bed &lt;- file.path(&quot;haploinsufficient.bed&quot;) # option 1: KEEP only these regions for analysis new_snps_keep &lt;- filter_bed(snps, bed) # option 2: REMOVE these regions from analysis new_snps_remove &lt;- filter_bed(snps, bed, remove = TRUE) Re-calculate the \\(f_4\\)-ratio: # f4-ratio with the regions kept f4_keep &lt;- f4ratio(data = new_snps_keep, X = pops, A = &quot;Altai&quot;, B = &quot;Vindija&quot;, C = &quot;Yoruba&quot;, O = &quot;Chimp&quot;) %&gt;% # convert z score to pvalue mutate(p = 2 * pnorm(-abs(Zscore))) f4_keep ## A B X C O alpha stderr Zscore p ## 1 Altai Vindija French Yoruba Chimp 0.030580 0.009385 3.258 1.122004e-03 ## 2 Altai Vindija Sardinian Yoruba Chimp 0.018057 0.009117 1.981 4.759127e-02 ## 3 Altai Vindija Han Yoruba Chimp 0.023127 0.009617 2.405 1.617247e-02 ## 4 Altai Vindija Papuan Yoruba Chimp 0.036462 0.008964 4.068 4.741838e-05 ## 5 Altai Vindija Khomani_San Yoruba Chimp -0.001223 0.008774 -0.139 8.894501e-01 ## 6 Altai Vindija Mbuti Yoruba Chimp -0.015781 0.009100 -1.734 8.291808e-02 ## 7 Altai Vindija Dinka Yoruba Chimp -0.004929 0.008235 -0.599 5.491729e-01 # f4-ratio with the regions removed f4_remove &lt;- f4ratio(data = new_snps_remove, X = pops, A = &quot;Altai&quot;, B = &quot;Vindija&quot;, C = &quot;Yoruba&quot;, O = &quot;Chimp&quot;) %&gt;% # convert z score to pvalue mutate(p = 2 * pnorm(-abs(Zscore))) f4_remove ## A B X C O alpha stderr Zscore p ## 1 Altai Vindija French Yoruba Chimp 0.016554 0.007929 2.088 3.679783e-02 ## 2 Altai Vindija Sardinian Yoruba Chimp 0.027980 0.007826 3.575 3.502279e-04 ## 3 Altai Vindija Han Yoruba Chimp 0.020285 0.007348 2.761 5.762468e-03 ## 4 Altai Vindija Papuan Yoruba Chimp 0.036136 0.007550 4.786 1.701381e-06 ## 5 Altai Vindija Khomani_San Yoruba Chimp 0.005713 0.007593 0.752 4.520511e-01 ## 6 Altai Vindija Mbuti Yoruba Chimp 0.009803 0.007233 1.355 1.754176e-01 ## 7 Altai Vindija Dinka Yoruba Chimp -0.000663 0.006798 -0.097 9.227264e-01 Some of the alpha values for each population change when excluding/restricting to haploinsufficient genes, but their standard error ranges still overlap between the two \\(f_4\\)-ratio calculations, so they likely aren’t truly different. "],["gene-expression.html", "11 Gene expression", " 11 Gene expression In this lab, we’ll use data from the Genotype-Tissue Expression (GTEx) Project to explore how genetic variation impacts gene expression. 11.0.0.1 Learning objectives After completing this chapter, you’ll be able to: Define expression and splicing quantitative trait loci. Explain the challenge of multiple testing in eQTL studies and how it is typically handled. Navigate the GTEx Portal to find expression data for genes of interest. "],["gene-expression-1.html", "11.1 Gene expression", " 11.1 Gene expression In this class, we’ve mostly discussed variation at the level of DNA sequence. However, variation in gene expression – and how it interacts with genotype data – is an equally important aspect of phenotype diversity. Measuring gene expression Sequencing mRNA molecules (RNA sequencing), aligning them to a reference genome, and counting the reads per gene provides us with a proxy for measuring expression level. Fig. 1 (source). Counting transcript expression from RNA-seq reads. "],["the-genotype-tissue-expression-project.html", "11.2 The Genotype-Tissue Expression project", " 11.2 The Genotype-Tissue Expression project In 2010, the NIH launched the first large-scale dataset of gene expression data, called the Genotype-Tissue Expression (GTEx) project. The final version of this dataset (v8) was released in 2020. GTEx is currently the most comprehensive gene expression dataset in existence. It involved the sequencing of whole genomes (DNA-seq) as well as transcriptomes (RNA-seq) from 948 recently-deceased individuals, with up to 54 tissues sampled throughout their bodies. One of the main motivations of GTEx was to better understand the genetic control of gene expression. How does genetic variation contribute to variation in amount, splicing, and tissue specificity of expressed RNA? Fig. 2 (source). Summary of individuals sequenced by GTEx. "],["gtex-portal.html", "11.3 GTEx portal", " 11.3 GTEx portal The GTEx Portal provides an interface to summarize and visualize these data. In the search bar, we can look up a gene of interest and see: Violin plots depicting inter-individual variation in gene expression across all tissues Variants that impact expression or splicing of that gene Fig. 3 (source). Distributions of gene expression across tissues for the DNMT3A gene. "],["genetic-effects-on-gene-expression.html", "11.4 Genetic effects on gene expression", " 11.4 Genetic effects on gene expression Why does expression for the same gene vary across individuals? There are many factors that can contribute to variability in gene expression in a population: Environment (ex: diet, climate, disease) Stochasticity/noise Epigenetics (methylation, repressive/activating histone marks) Genetics (genetic variants in promoter, enhancer, etc. sequences) How do we discover genetic variants that influence gene expression? We can perform a genome-wide association study, similar to what we would do for an organismal phenotype like height. This time, our phenotype is the expression of a specific gene, and we can search for genetic variants that impact this expression. "],["expression-qtls.html", "11.5 Expression QTLs", " 11.5 Expression QTLs The variants we identify with this GWAS approach are called expression quantitative trait loci (eQTLs). Notably, because the number of phenotypes we have is equal to the number of genes we’re testing, we would have to perform ~20,000 GWASs (the number of gemes) for every eQTL study in humans, and test ~5 million SNPs per GWAS. Multiple testing in eQTL studies When we’re performing this many repeated tests, you run the risk that any hits you find are just due to chance. In a GWAS, we would use multiple testing correction to account for this. However, because of the overwhelming number of tests we need to perform to identify eQTLs, our significance threshold would be so low that we likely wouldn’t discover anything. Reducing the number of tests In order to reduce the number of tests, we typically focus on eQTL mapping just in in the region around the gene body, which dramatically decreases the number of SNPs we’re testing. The rationale for this approach is that nearby regulatory regions (promoters, enhancers, etc.) are more likely to influence expression. Fig. 4. eQTL studies typically restrict their QTL search space to variants within 1 Mb of the gene. "],["eqtls-in-the-gtex-portal.html", "11.6 eQTLs in the GTEx Portal", " 11.6 eQTLs in the GTEx Portal The GTEx Portal includes an option to view all significant eQTLs for a gene, below the plots of tissue expression. Note that these eQTLs are labeled by tissue – they may not impact transcription outside of that tissue. Fig. 5. Significant eQTLs for DNMT3A in the GTEx Portal. eQTL violin plots The Actions column provides quick access to several visualizations of each eQTL, including a violin plot that shows how it impacts expression: Fig. 6. The T allele at the chr2_25264228_C_T_b38 SNP decreases DNMT3A expression. "],["splicing-qtls.html", "11.7 Splicing QTLs", " 11.7 Splicing QTLs In addition to variants that impact gene expression, there are splicing quantitative trait loci (sQTLs) that alter how a gene is spliced. Some sQTL mechanisms include: Create or destroying a splicing donor/acceptor site Changing the binding site for a protein that regulates splicing Altering a splicing factor protein itself Fig. 7. sQTLs may alter splice donor/acceptor sites, or binding sites for transcription factors that regulate splicing. sQTLs in GTEx The GTEx Portal also provides a list of sQTLs for each gene. Note that the violin plots for these QTLs refer to a specific intron of DNMT3A whose inclusion rate is affected by each SNP. Fig. 8. The A allele at the chr2_25530386_G_A_b38 SNP reduces excision of the chr2:25246776:25247051:clu_42604 intron of DNMT3A. "],["setup-7.html", "11.8 Setup", " 11.8 Setup Now we’ll look at the GTEx data ourselves to perform our own gene expression analyses. 11.8.1 R packages In addition to tidyverse, we’ll also load the MASS package, which is useful for various statistical functions. library(tidyverse) library(MASS) "],["data-4.html", "11.9 Data", " 11.9 Data The GTEx Portal provides links for downloading curated and summarized forms of its data, including giant matrices that encode the expression of every gene across all samples and tissues. For ease of manipulation in R, we’ve subset this data to 150 samples, highly expressed genes, and only data from liver and lung tissue. gtex &lt;- read.table(&quot;gtex_subset.txt.gz&quot;, header = TRUE) head(gtex) ## Sample Age Sex Death_Hardy Tissue Gene_ID Gene_Name Counts ## 1 GTEX-111YS 60-69 M 0 Lung ENSG00000187634.11 SAMD11 59 ## 2 GTEX-111YS 60-69 M 0 Lung ENSG00000188976.10 NOC2L 2789 ## 3 GTEX-111YS 60-69 M 0 Lung ENSG00000187961.13 KLHL17 716 ## 4 GTEX-111YS 60-69 M 0 Lung ENSG00000187583.10 PLEKHN1 47 ## 5 GTEX-111YS 60-69 M 0 Lung ENSG00000187642.9 PERM1 23 ## 6 GTEX-111YS 60-69 M 0 Lung ENSG00000188290.10 HES4 534 The columns of this dataframe are: Sample: Individual sequenced Age: Individual’s age range Sex: Individual’s sex Death_Hardy: Individual’s cause of death, measured on the Hardy Scale Tissue: Tissue measured Gene_ID: Ensembl gene ID Gene_Name: The common gene name Counts: Expression level for the gene Ex: GTEX-111YS has 59 sequencing reads that mapped to the SAMD11 gene Data normalization The expression levels in this table have been normalized to account for factors such as sequencing variation between samples – i.e., if we collected more sequencing data from one individual than another. "],["differential-gene-expression.html", "11.10 Differential gene expression", " 11.10 Differential gene expression Using this dataset, we can fit regression models to ask about differences in gene expression between conditions. For example, let’s say we’re interested in whether the ACE2 gene – the receptor bound by the SARS-CoV-2 virus – exhibits differences in expression between males and females. First we subset the data to the relevant gene and tissue (ACE2 and lung) for our test: subset &lt;- gtex %&gt;% # filter for tissue and gene of interest filter(Tissue == &quot;Lung&quot; &amp; Gene_Name == &quot;ACE2&quot;) head(subset) ## Sample Age Sex Death_Hardy Tissue Gene_ID Gene_Name Counts ## 1 GTEX-111YS 60-69 M 0 Lung ENSG00000130234.10 ACE2 640 ## 2 GTEX-1128S 60-69 F 2 Lung ENSG00000130234.10 ACE2 64 ## 3 GTEX-11DXX 60-69 F 0 Lung ENSG00000130234.10 ACE2 236 ## 4 GTEX-11DXZ 50-59 M 0 Lung ENSG00000130234.10 ACE2 174 ## 5 GTEX-11EMC 60-69 F 2 Lung ENSG00000130234.10 ACE2 162 ## 6 GTEX-11EQ9 30-39 M 2 Lung ENSG00000130234.10 ACE2 85 Then we can fit a model to our data. Note that we’re using the glm.nb function, which uses a negative binomial distribution – good for modeling discrete (i.e., non-continuous) data, such as sequencing read counts. # fit model and print summary model &lt;- glm.nb(formula = Counts ~ factor(Sex), data = subset) summary(model) ## ## Call: ## glm.nb(formula = Counts ~ factor(Sex), data = subset, init.theta = 0.9820746913, ## link = log) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 5.5530 0.1709 32.494 &lt; 2e-16 *** ## factor(Sex)M -0.7907 0.2121 -3.727 0.000194 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for Negative Binomial(0.9821) family taken to be 1) ## ## Null deviance: 129.67 on 99 degrees of freedom ## Residual deviance: 115.01 on 98 degrees of freedom ## AIC: 1214.5 ## ## Number of Fisher Scoring iterations: 1 ## ## ## Theta: 0.982 ## Std. Err.: 0.123 ## ## 2 x log-likelihood: -1208.475 Does sex impact ACE2 expression? The p-value is significant (p = 0.000194), suggesting that sex does affect ACE2 expression. Based on the coefficient of -0.7907, it looks like males tend to have ~0.8 fewer ACE2 transcripts in lung tissue. "],["conclusion-9.html", "11.11 Conclusion", " 11.11 Conclusion In this lab, we explored the GTEx dataset to understand how genetic variation impacts gene expression. We can treat gene expression as a phenotype to search for expression and splicing QTLs, the same way we would look for variants associated with an organismal trait. Due to the multiple testing burden of testing millions of variants across thousands of genes, eQTL studies typically limit themselves to variants close to the gene body. The GTEx Portal provides a convenient interface for browsing QTL and gene expression information across tissues. "],["homework-9.html", "11.12 Homework", " 11.12 Homework 11.12.0.1 Learning Objectives Become familiar with the data available in the GTEx dataset Interpret linear models in the context of gene expression 11.12.0.2 Assignment Fit a regression model (or multiple!) to the GTEx data we downloaded in class and test for differential expression between two (or more) conditions. For example, you could look at another gene, compare between tissues, age groups, or Hardy classifications, etc. Based on the results, does the condition affect expression of your gene? Solution As an example, we’ll test for differences in ACE2 expression between liver and lung tissue. First we subset the GTEx data to just the ACE2 gene: subset &lt;- gtex %&gt;% # filter gene of interest filter(Gene_Name == &quot;ACE2&quot;) head(subset) ## Sample Age Sex Death_Hardy Tissue Gene_ID Gene_Name Counts ## 1 GTEX-111YS 60-69 M 0 Lung ENSG00000130234.10 ACE2 640 ## 2 GTEX-1128S 60-69 F 2 Lung ENSG00000130234.10 ACE2 64 ## 3 GTEX-11DXX 60-69 F 0 Lung ENSG00000130234.10 ACE2 236 ## 4 GTEX-11DXZ 50-59 M 0 Liver ENSG00000130234.10 ACE2 211 ## 5 GTEX-11DXZ 50-59 M 0 Lung ENSG00000130234.10 ACE2 174 ## 6 GTEX-11EMC 60-69 F 2 Lung ENSG00000130234.10 ACE2 162 Then we fit a model with glm.nb: # fit model and print summary model &lt;- glm.nb(formula = Counts ~ factor(Tissue), data = subset) summary(model) ## ## Call: ## glm.nb(formula = Counts ~ factor(Tissue), data = subset, init.theta = 1.034483188, ## link = log) ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 4.6651 0.1370 34.05 &lt; 2e-16 *** ## factor(Tissue)Lung 0.4491 0.1688 2.66 0.00781 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for Negative Binomial(1.0345) family taken to be 1) ## ## Null deviance: 180.46 on 151 degrees of freedom ## Residual deviance: 173.75 on 150 degrees of freedom ## AIC: 1819 ## ## Number of Fisher Scoring iterations: 1 ## ## ## Theta: 1.034 ## Std. Err.: 0.106 ## ## 2 x log-likelihood: -1812.977 The p-value is significant (p = 0.00781), suggesting that ACE2 expression does differ between liver and lung. The coefficient estimate, 0.4491, indicates that RNA-seq counts for ACE2 are \\(0.45\\) transcripts higher in lung than in liver. "],["coronavirus-phylogenetics.html", "12 Coronavirus phylogenetics", " 12 Coronavirus phylogenetics In this lab, we’ll use Nextstrain to explore the evolution of SARS-CoV-2 and then build our own coronavirus phylogenies within R. 12.0.0.1 Learning objectives After completing this chapter, you’ll be able to: Interpret viral phylogenies and associated data on Nextstrain. Explain how incomplete sampling affects phylogenies. Describe how phylogenetic trees are built through neighbor joining. "],["phylogenetic-trees.html", "12.1 Phylogenetic trees", " 12.1 Phylogenetic trees Phylogenetic trees represent the evolutionary relationships between samples. When comparing genetic sequences, we construct trees based on shared mutations between sequences – with the caveat that sometimes the same mutation can arise independently on different lineages. Human vs. viral phylogenies Constructing a phylogeny for human sequences is complicated by recombination (as well as diploidy and sex chromosomes), which means that every non-recombined segment of the genome has its own phylogenetic history. Viral phylogenies are simpler to construct because they recombine less frequently than human chromosomes do. While the frequency of recombination varies by virus, ~3% of SARS-CoV-2 lineages show evidence of recombination (as opposed to 100% of human lineages, since recombination is an essential component of human meiosis). Similar to the human Y chromosome, viral genomes typically accumulate mutations without recombination to split up haplotypes. "],["nextstrain.html", "12.2 Nextstrain", " 12.2 Nextstrain We’ll be visualizing the evolutionary history of SARS-CoV-2 with a web application called Nextstrain, developed by Trevor Bedford and colleagues at the Fred Hutch Cancer Center. Reading a phylogenetic tree Nextstrain provides a guide on how to interpret their phylogenetic trees. The figure below shows a “transmission tree” of viruses, where every dot is individual who was infected. Some of these individuals infect others, and some are dead ends (no transmission). After a mutation (diamonds) occurs on a branch, any sample to the right of the mutation will also carry it. Fig. 1. The “true” tree of virus transmission through a population (source). "],["incomplete-sampling.html", "12.3 Incomplete sampling", " 12.3 Incomplete sampling The tree we just saw is the complete, “full” tree of transmission, but we are almost never able to sample all the individuals we need to reconstruct it. Incomplete sampling can result in inaccurate interpretations of a phylogenetic tree (ex: inferring fewer introductions of the virus from a source population into a new population). Fig. 2. Incomplete sampling complicates interpretations of a phylogeny (source). "],["tracking-sars-cov-2-with-phylogenetics.html", "12.4 Tracking SARS-CoV-2 with phylogenetics", " 12.4 Tracking SARS-CoV-2 with phylogenetics Go to the Nextstrain browser to explore the phylogeny of SARS-CoV-2 sequences. Note that you can use the PLAY button on the left sidebar to watch its progression over time. Hovering over a specific node tells you the ID of the virus that was sequenced. It also tells you the divergence, which is the number of mutations it carries with respect to the root of the tree. Fig. 3. SARS-CoV-2 phylogeny from Nextstrain (source). One example of the public health value of this phylogenetic analysis was the observation that the second reported case of novel coronavirus in Washington state (WA2) was genetically similar to the first reported case (WA1) six weeks earlier, suggesting ongoing community transmission. Click the tweet expand the full thread. (kevin_purcell?) Please feel free to try (click the menu Embed Tweet here) and let me know if it does not work. — Yihui Xie ((xieyihui?)) July 28, 2016 "],["sars-cov-2-mutation-landscape.html", "12.5 SARS-CoV-2 mutation landscape", " 12.5 SARS-CoV-2 mutation landscape The phylogeny page also has a “diversity” section, where it plots the number of mutations observed in different regions of the SARS-CoV-2 genome sequence. Fig. 4. Genomic distribution of mutations across SARS-CoV-2 strains (source). Does this plot imply that specific regions of the SARS-CoV-2 genome are more susceptible to mutation? No – this plot can be interpreted as showing where mutations persist in the SARS-CoV-2 genome, not where they occur. Although mutation occurrence is mostly random, the genomic distribution we see in this plot has been filtered by natural selection. Beneficial mutations are selected for, causing them to appear more frequently in pathogenically important regions like the spike protein (S). We sometimes see recurring independent mutations where the same amino acid is changed across different SARS-CoV-2 strains, which is extremely strong evidence of selection. "],["setup-8.html", "12.6 Setup", " 12.6 Setup In the rest of this module we’ll place SARS-CoV-2 on a phylogeny of 24 distantly related coronavirus sequences (SARS, MERS, etc.) from both human and animal hosts. 12.6.1 R packages We’ll use ape for phylogenetics, ggtree for plotting trees, and harrietr for data transformation. library(tidyverse) library(ape) library(ggtree) library(harrietr) "],["data-5.html", "12.7 Data", " 12.7 Data 12.7.0.1 Metadata The accessions dataframe contains the GenBank IDs and full names of the coronavirus sequences we’re using: accessions &lt;- read.table(&quot;accessions.txt&quot;, header = TRUE, sep = &quot;\\t&quot;) head(accessions) ## id name ## 1 DQ022305 DQ022305.2 Bat SARS coronavirus HKU3-1 ## 2 DQ071615 DQ071615.1 Bat SARS coronavirus Rp3 ## 3 DQ412043 DQ412043.1 Bat SARS coronavirus Rm1 ## 4 JX993988 JX993988.1 Bat coronavirus Cp/Yunnan2011 ## 5 FJ588686 FJ588686.1 Bat SARS CoV Rs672/2006 ## 6 JX993987 JX993987.1 Bat coronavirus Rp/Shaanxi2011 # make vectors of the GenBank IDs and full names # these will be used as input to functions later ids &lt;- accessions$id names &lt;- accessions$name The SARS-CoV-2 sequence we’re using is MT093631 (MT093631.2 Severe acute respiratory syndrome coronavirus 2 isolate SARS-CoV-2/human/CHN/WH-09/2020). 12.7.0.2 DNA sequences We’ve downloaded and aligned the genome sequences of these coronaviruses in the aligned.fa FASTA file. Click on the file to preview the sequence of the first coronavirus: &gt;DQ022305 ----------------------------------------GTTAGGTTTTTACCTACCCAGGAAA--AGCCAACCAACC- TTGATCTCTTGTAGATCTGTTCTCTAAACGAACTTTAAAA------TCTGTGTGGCTGTCGCTCGGCTGCATGCCTAGCG CACCTACGCAGTATAAATATTAAT-AACTTTACTGTCGTTGACAAGAAACGAGTAACTCGTCCCTCTTCTGCAGACTGCT FASTA format .fa indicates a FASTA file, which is a text-based format for representing DNA (or protein) sequences. In a file that contains multiple sequences (like ours), the &gt; character indicates the start of a new sequence and is usually followed by the sequence name. Why do the sequences have to be aligned? To construct a phylogeny, we compare how a site in the genome has changed in different coronavirus strains. Sequences need to be aligned so that we know we’re comparing the same site across sequences. "],["neighbor-joining-trees.html", "12.8 Neighbor joining trees", " 12.8 Neighbor joining trees One approach to building a phylogeny of sequences is neighbor joining, which clusters sequences based on their pairwise genetic distance. In this approach, we: Start with a star phylogeny that assumes all samples are equally related (Fig. 5A) Compute a pairwise distance matrix between sequences, and look for the pair of sequences that are most similar to each other We join these two sequences to form a new node (Fig. 5B) The distance matrix is re-computed and this process repeats until all nodes are joined (Fig. 5C) Fig. 5. Steps for constructing a neighbor joining tree (source). "],["computing-pairwise-distance.html", "12.9 Computing pairwise distance", " 12.9 Computing pairwise distance Read in the FASTA file of aligned sequences with the read.dna function from ape: dna &lt;- read.dna(&quot;aligned.fa&quot;, format = &quot;fasta&quot;, as.matrix = TRUE) We then compute the pairwise distance matrix: D &lt;- dist.dna(dna, model = &quot;TN93&quot;, as.matrix = TRUE) We can plot this matrix to visualize it: # use the &quot;melt_dist&quot; function from harrietr package to convert # the distance matrix to &quot;long&quot; format for ggplot D_melted &lt;- rbind(melt_dist(D, order = ids), melt_dist(t(D), order = rev(ids))) ## Warning: `gather_()` was deprecated in tidyr 1.2.0. ## ℹ Please use `gather()` instead. ## ℹ The deprecated feature was likely used in the harrietr package. ## Please report the issue at &lt;https://github.com/andersgs/harrietr/issues&gt;. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. # plot distance matrix ggplot(data = D_melted) + geom_tile(aes(x = iso1, y = iso2, fill = (dist + 1e-5))) + theme_classic() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + scale_fill_viridis_c(name = &quot;distance&quot;) + xlab(&quot;sample&quot;) + ylab(&quot;sample&quot;) Interpreting the distance matrix Most of these coronaviruses seem to be fairly similar – i.e., there’s no clear clustering of sequences – besides HQ166910, which looks genetically distinct from the other sequences. "],["building-a-phylogenetic-tree.html", "12.10 Building a phylogenetic tree", " 12.10 Building a phylogenetic tree Using the distance matrix, we can now: Build a neighbor joining tree using the nj() function Use HQ166910 as the outgroup to root the tree (with the root() function) Use the ladderize() function to re-orient the tree into a tidier format for plotting # build a neighbor joining tree tree &lt;- nj(D) # manually &quot;root&quot; the tree by setting HQ166910 as an outgroup tree &lt;- root(tree, which(ids == &quot;HQ166910&quot;)) # rotate tree at nodes to make it look tidier (i.e., &quot;ladderized&quot;) tree &lt;- ladderize(tree) # plot the tree ggtree(tree) + theme_tree2() + geom_tiplab(label = names, size = 4) + xlim(0, 1.2) On the tree, we can see that the 2019-nCov sample (MT093631.2 Severe acute respiratory syndrome coronavirus 2) groups most closely with Bat coronavirus RaTG13. Do you think this similarity is sufficient to confirm a bat origin of SARS-CoV-2? Although the distance between SARS-CoV-2 and RaTG13 in the phylogeny looks small, it’s a large distance in phylogenetic space. Without sampling more deeply within intermediate strains between RaTG13 and SARS-CoV-2, we don’t know whether it passed through other mammalian species before being transmitted to humans. yper ## Assess bootstrap support A useful tool for evaluating confidence in a phylogenetic tree (or any other metric) is bootstrapping. This statistical method is based on resampling data with replacement from the original dataset. In our case, we resample aligned sites (i.e., bases) from the original alignment, then build a new tree with the resampled data. By repeating this procedure many times, we can evaluate confidence in various parts of the original tree by asking how often the trees from resampled data contain these features. Run the code below to implement bootstrapping in the boot.phylo() function. The output is a vector of bootstrap support values, which we can overlay onto the tree. # set random seed set.seed(123) # bootstrap and build new trees to evaluate uncertainty myBoots &lt;- boot.phylo(tree, dna, function(x) ladderize(root(nj(dist.dna(x, model = &quot;TN93&quot;)), which(ids == &quot;HQ166910&quot;))), rooted = TRUE) ## Running bootstraps: 100 / 100 ## Calculating bootstrap values... done. # replace &quot;NA&quot; with zero in bootstrap results; do not label terminal nodes myBoots[is.na(myBoots)] &lt;- 0 myBoots &lt;- c(rep(NA, 25), myBoots) # re-plot tree with bootstrap values ggtree(tree, branch.length = &quot;none&quot;) + theme_tree2() + geom_tiplab(label = names) + geom_label(aes(label = myBoots), size = 3) + xlim(0, 15) ## Warning: Removed 25 rows containing missing values or values outside the scale range ## (`geom_label()`). "],["conclusion-10.html", "12.11 Conclusion", " 12.11 Conclusion In this module, we visualized evolutionary relationships between coronavirus strains using Nextstrain and by constructing our own phylogenies in R. We first explored Nextstrain, a browser that summarizes historical sequencing data from SARS-CoV-2 strains around the world. We observed independent recurrent mutations in pathogenically relevant regions of the SARS-CoV-2 genome, suggesting that such mutations confer a fitness benefit and are under positive selection. Using the sequences of other coronavirus strains from GenBank, we placed SARS-CoV-2 onto a neighbor joining phylogeny of closely related viruses. We used bootstrapping to provide confidence estimates for branches on our neighbor joining tree. "],["homework-10.html", "12.12 Homework", " 12.12 Homework 12.12.0.1 Learning Objectives Practice building and interpreting phylogenies in R 12.12.0.2 Assignment hw_accessions.txt and hw_aligned.fa provide the alignments and metadata for 24 human SARS-CoV-2 sequences, plus the bat RaTG13 coronavirus strain. Use this data to repeat the analysis we did in class (compute distance matrix, construct neighbor joining tree, perform bootstrapping for confidence values) to build a phylogeny of SARS-CoV-2 strains. You should use RaTG13 (accession: MN996532) as an outgroup. Solution Read in accession data: accessions &lt;- read.table(&quot;hw_accessions.txt&quot;, sep = &quot;\\t&quot;, header = TRUE) # make vectors of accessions IDs and full names ids &lt;- accessions$id names &lt;- accessions$name Construct distance matrix: # read fasta file dna &lt;- read.dna(&quot;hw_aligned.fa&quot;, format = &quot;fasta&quot;, as.matrix = TRUE) # compute pairwise distance matrix D &lt;- dist.dna(dna, model = &quot;TN93&quot;, as.matrix = TRUE) Build neighbor joining tree: # make the tree tree &lt;- nj(D) # manually root tree at RaTG13 coronavirus tree &lt;- root(tree, which(ids == &quot;MN996532&quot;)) # ladderize tree tree &lt;- ladderize(tree) Bootstrap to determine tree uncertainty: set.seed(123) myBoots &lt;- boot.phylo(tree, dna, function(x) ladderize(root(nj(dist.dna(x, model = &quot;TN93&quot;)), which(ids == &quot;MN996532&quot;))), rooted = TRUE) ## Running bootstraps: 100 / 100 ## Calculating bootstrap values... done. # replace &quot;NA&quot; with zero myBoots[is.na(myBoots)] &lt;- 0 Plot the bootstrapped tree: ggtree(tree, branch.length = &quot;none&quot;) + theme_tree2() + geom_tiplab(label = names) + geom_nodelab(label = myBoots, geom = &quot;label&quot;, fill = &quot;#deebf7&quot;) + xlim(0, 25) "],["authors.html", "Authors", " Authors     Credits Names Pedagogy Instructor Rajiv McCoy Content Author Stephanie Yan Content Author Kate Weaver Website Template Jeff Leek &amp; The Johns Hopkins Data Science Lab Design Inspiration Ali Madooei &amp; JHU Data Structures Funding JHU Center for Educational Resources Techology Fellowship Grant   ## ─ Session info ─────────────────────────────────────────────────────────────── ## setting value ## version R version 4.3.2 (2023-10-31) ## os Ubuntu 22.04.4 LTS ## system x86_64, linux-gnu ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Etc/UTC ## date 2024-07-31 ## pandoc 3.1.1 @ /usr/local/bin/ (via rmarkdown) ## ## ─ Packages ─────────────────────────────────────────────────────────────────── ## package * version date (UTC) lib source ## admixr * 0.9.1 2020-07-03 [1] RSPM (R 4.3.0) ## ape * 5.7-1 2023-03-13 [1] RSPM (R 4.3.0) ## aplot 0.2.2 2023-10-06 [1] RSPM (R 4.3.0) ## askpass 1.2.0 2023-09-03 [1] RSPM (R 4.3.0) ## BiocManager 1.30.22 2023-08-08 [1] RSPM (R 4.3.0) ## bookdown 0.39.1 2024-06-11 [1] Github (rstudio/bookdown@f244cf1) ## bslib 0.6.1 2023-11-28 [1] RSPM (R 4.3.0) ## cachem 1.0.8 2023-05-01 [1] RSPM (R 4.3.0) ## calibrate 1.7.7 2020-06-19 [1] RSPM (R 4.3.0) ## cli 3.6.2 2023-12-11 [1] RSPM (R 4.3.0) ## cluster 2.1.4 2022-08-22 [2] CRAN (R 4.3.2) ## colorspace 2.1-0 2023-01-23 [1] RSPM (R 4.3.0) ## crayon 1.5.2 2022-09-29 [1] RSPM (R 4.3.0) ## devtools 2.4.5 2022-10-11 [1] RSPM (R 4.3.0) ## digest 0.6.34 2024-01-11 [1] RSPM (R 4.3.0) ## dplyr * 1.1.4 2023-11-17 [1] RSPM (R 4.3.0) ## ellipsis 0.3.2 2021-04-29 [1] RSPM (R 4.3.0) ## evaluate 0.23 2023-11-01 [1] RSPM (R 4.3.0) ## fansi 1.0.6 2023-12-08 [1] RSPM (R 4.3.0) ## farver 2.1.1 2022-07-06 [1] RSPM (R 4.3.0) ## fastmap 1.1.1 2023-02-24 [1] RSPM (R 4.3.0) ## forcats * 1.0.0 2023-01-29 [1] RSPM (R 4.3.0) ## fs 1.6.3 2023-07-20 [1] RSPM (R 4.3.0) ## generics 0.1.3 2022-07-05 [1] RSPM (R 4.3.0) ## ggfun 0.1.4 2024-01-19 [1] RSPM (R 4.3.0) ## ggplot2 * 3.5.0 2024-02-23 [1] RSPM (R 4.3.0) ## ggplotify 0.1.2 2023-08-09 [1] RSPM (R 4.3.0) ## ggtree * 3.10.1 2024-02-25 [1] Bioconductor 3.18 (R 4.3.2) ## glue 1.7.0 2024-01-09 [1] RSPM (R 4.3.0) ## gridGraphics 0.5-1 2020-12-13 [1] RSPM (R 4.3.0) ## gtable 0.3.4 2023-08-21 [1] RSPM (R 4.3.0) ## harrietr * 0.2.3 2017-12-01 [1] RSPM (R 4.3.2) ## highr 0.10 2022-12-22 [1] RSPM (R 4.3.0) ## hms 1.1.3 2023-03-21 [1] RSPM (R 4.3.0) ## htmltools 0.5.7 2023-11-03 [1] RSPM (R 4.3.0) ## htmlwidgets 1.6.4 2023-12-06 [1] RSPM (R 4.3.0) ## httpuv 1.6.14 2024-01-26 [1] RSPM (R 4.3.0) ## httr 1.4.7 2023-08-15 [1] RSPM (R 4.3.0) ## jquerylib 0.1.4 2021-04-26 [1] RSPM (R 4.3.0) ## jsonlite 1.8.8 2023-12-04 [1] RSPM (R 4.3.0) ## knitr 1.47.3 2024-06-11 [1] Github (yihui/knitr@e1edd34) ## labeling 0.4.3 2023-08-29 [1] RSPM (R 4.3.0) ## later 1.3.2 2023-12-06 [1] RSPM (R 4.3.0) ## lattice 0.21-9 2023-10-01 [2] CRAN (R 4.3.2) ## lazyeval 0.2.2 2019-03-15 [1] RSPM (R 4.3.0) ## lifecycle 1.0.4 2023-11-07 [1] RSPM (R 4.3.0) ## lubridate * 1.9.3 2023-09-27 [1] RSPM (R 4.3.0) ## magrittr 2.0.3 2022-03-30 [1] RSPM (R 4.3.0) ## MASS * 7.3-60 2023-05-04 [2] CRAN (R 4.3.2) ## Matrix 1.6-1.1 2023-09-18 [2] CRAN (R 4.3.2) ## memoise 2.0.1 2021-11-26 [1] RSPM (R 4.3.0) ## memuse 4.2-3 2023-01-24 [1] RSPM (R 4.3.0) ## mgcv 1.9-0 2023-07-11 [2] CRAN (R 4.3.2) ## mime 0.12 2021-09-28 [1] RSPM (R 4.3.0) ## miniUI 0.1.1.1 2018-05-18 [1] RSPM (R 4.3.0) ## munsell 0.5.0 2018-06-12 [1] RSPM (R 4.3.0) ## nlme 3.1-163 2023-08-09 [2] CRAN (R 4.3.2) ## openssl 2.1.1 2023-09-25 [1] RSPM (R 4.3.0) ## ottrpal 1.2.1 2024-06-11 [1] Github (jhudsl/ottrpal@828539f) ## patchwork 1.2.0 2024-01-08 [1] RSPM (R 4.3.0) ## permute 0.9-7 2022-01-27 [1] RSPM (R 4.3.0) ## pillar 1.9.0 2023-03-22 [1] RSPM (R 4.3.0) ## pinfsc50 1.3.0 2023-12-05 [1] RSPM (R 4.3.0) ## pkgbuild 1.4.3 2023-12-10 [1] RSPM (R 4.3.0) ## pkgconfig 2.0.3 2019-09-22 [1] RSPM (R 4.3.0) ## pkgload 1.3.4 2024-01-16 [1] RSPM (R 4.3.0) ## profvis 0.3.8 2023-05-02 [1] RSPM (R 4.3.0) ## promises 1.2.1 2023-08-10 [1] RSPM (R 4.3.0) ## purrr * 1.0.2 2023-08-10 [1] RSPM (R 4.3.0) ## qqman * 0.1.9 2023-08-23 [1] RSPM (R 4.3.0) ## R6 2.5.1 2021-08-19 [1] RSPM (R 4.3.0) ## Rcpp 1.0.12 2024-01-09 [1] RSPM (R 4.3.0) ## readr * 2.1.5 2024-01-10 [1] RSPM (R 4.3.0) ## remotes 2.4.2.1 2023-07-18 [1] RSPM (R 4.3.0) ## rlang 1.1.4 2024-06-04 [1] CRAN (R 4.3.2) ## rmarkdown 2.27.1 2024-06-11 [1] Github (rstudio/rmarkdown@e1c93a9) ## rstudioapi 0.15.0 2023-07-07 [1] RSPM (R 4.3.0) ## sass 0.4.8 2023-12-06 [1] RSPM (R 4.3.0) ## scales 1.3.0 2023-11-28 [1] RSPM (R 4.3.0) ## sessioninfo 1.2.2 2021-12-06 [1] RSPM (R 4.3.0) ## shiny 1.8.0 2023-11-17 [1] RSPM (R 4.3.0) ## stringi 1.8.3 2023-12-11 [1] RSPM (R 4.3.0) ## stringr * 1.5.1 2023-11-14 [1] RSPM (R 4.3.0) ## tibble * 3.2.1 2023-03-20 [1] CRAN (R 4.3.2) ## tidyr * 1.3.1 2024-01-24 [1] RSPM (R 4.3.0) ## tidyselect 1.2.0 2022-10-10 [1] RSPM (R 4.3.0) ## tidytree 0.4.6 2023-12-12 [1] RSPM (R 4.3.0) ## tidyverse * 2.0.0 2023-02-22 [1] RSPM (R 4.3.0) ## timechange 0.3.0 2024-01-18 [1] RSPM (R 4.3.0) ## treeio 1.26.0 2023-10-24 [1] Bioconductor ## tzdb 0.4.0 2023-05-12 [1] RSPM (R 4.3.0) ## urlchecker 1.0.1 2021-11-30 [1] RSPM (R 4.3.0) ## usethis 2.2.3 2024-02-19 [1] RSPM (R 4.3.0) ## utf8 1.2.4 2023-10-22 [1] RSPM (R 4.3.0) ## vcfR * 1.15.0 2023-12-08 [1] RSPM (R 4.3.0) ## vctrs 0.6.5 2023-12-01 [1] RSPM (R 4.3.0) ## vegan 2.6-4 2022-10-11 [1] RSPM (R 4.3.0) ## viridisLite 0.4.2 2023-05-02 [1] RSPM (R 4.3.0) ## withr 3.0.0 2024-01-16 [1] RSPM (R 4.3.0) ## xfun 0.44.4 2024-06-11 [1] Github (yihui/xfun@9da62cc) ## xml2 1.3.6 2023-12-04 [1] RSPM (R 4.3.0) ## xtable 1.8-4 2019-04-21 [1] RSPM (R 4.3.0) ## yaml 2.3.8 2023-12-11 [1] RSPM (R 4.3.0) ## yulab.utils 0.1.4 2024-01-28 [1] RSPM (R 4.3.0) ## ## [1] /usr/local/lib/R/site-library ## [2] /usr/local/lib/R/library ## ## ────────────────────────────────────────────────────────────────────────────── "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
